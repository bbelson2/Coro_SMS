@INPROCEEDINGS{5558636, 
author={S. Andalam and P. Roop and A. Girault}, 
booktitle={Eighth ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE 2010)}, 
title={Predictable multithreading of embedded applications using PRET-C}, 
year={2010}, 
pages={159-168}, 
abstract={We propose a new language called Precision Timed C (PRET-C), for predictable and lightweight multi-threading in C. PRET-C supports synchronous concurrency, preemption, and a high-level construct for logical time. In contrast to existing synchronous languages, PRET-C offers C-based shared memory communications between concurrent threads that is guaranteed to be thread safe. Due to the proposed synchronous semantics, the mapping of logical time to physical time can be achieved much more easily than with plain C, thanks to a Worst Case Reaction Time (WCRT) analyzer (not presented here). Associated to the PRET-C programming language, we present a dedicated target architecture, called ARPRET, which combines a hardware accelerator associated to an existing softcore processor. This allows us to improve the throughput while preserving the predictability. With extensive benchmarking, we then demonstrate that ARPRET not only achieves completely predictable execution of PRET-C programs, but also improves the throughput when compared to the pure software execution of PRET-C. The PRET-C software approach is also significantly more efficient in comparison to two other light-weight concurrent C variants (namely SC and Protothreads), as well as the well-known Esterel synchronous programming language.}, 
keywords={C language;embedded systems;multi-threading;shared memory systems;ARPRET;Esterel synchronous programming language;PRET-C programming language;embedded applications;precision timed C;predictable multithreading;shared memory communications;worst case reaction time analyzer;Assembly;Concurrent computing;Hardware;Instruction sets;Semantics;Timing}, 
doi={10.1109/MEMCOD.2010.5558636}, 
month={July},}
@INPROCEEDINGS{4400379, 
author={A. Krystosik}, 
booktitle={EUROCON 2007 - The International Conference on "Computer as a Tool"}, 
title={Model Checking in Concurrent Programming Teaching}, 
year={2007}, 
pages={2390-2396}, 
abstract={The paper presents an application of model checking in teaching a concurrent programming. The success of this approach is based on features of DT-CSM automata and EMLAN modeling language. EMLAN is a C-like, high level language for modeling and model checking of embedded systems. The language is equipped with a lot of synchronization mechanisms (semaphores, mutexes, monitors). This allows easy modeling and verification of concurrent, cooperating tasks, which is very useful for educational purposes. As an example, a typical student exercise: a producer-consumer is given.}, 
keywords={computer science education;distributed programming;embedded systems;finite state machines;program verification;specification languages;synchronisation;DT-CSM automata;EMLAN C-like high level language;EMLAN modeling language;concurrent programming teaching;embedded system model checking;synchronization mechanisms;Automata;Computer science;Concurrent computing;Education;Embedded system;Error correction;Information technology;Logic;Paper technology;Programming profession;Modeling;Software verification and validation;Teaching}, 
doi={10.1109/EURCON.2007.4400379}, 
month={Sept},}
@INPROCEEDINGS{4394196, 
author={M. Koutsoubelias and S. Lalis}, 
booktitle={2007 IEEE 18th International Symposium on Personal, Indoor and Mobile Radio Communications}, 
title={Design and Implementation of an Extensible Architecture for the Efficient Remote Access of Simple RFID-Readers}, 
year={2007}, 
pages={1-5}, 
abstract={This paper describes a software architecture for the remote monitoring of warehouses equipped with simple RFID reader devices. Its main design objective is to enable a flexible and efficient integration of resource constrained readers that may be implemented as low-cost embedded systems, while allowing higher-level middleware components to access them in a transparent way. The proposed design has been implemented in a Linux-based environment and is currently being tested in conjunction with early prototypes of simple RFID readers that are accessed over low-bandwidth.}, 
keywords={embedded systems;radiofrequency identification;software architecture;telecontrol;warehouse automation;efficient remote access;extensible architecture;higher-level middleware components;low-cost embedded systems;simple RFID-readers;software architecture;Computer architecture;Hardware;Information filtering;Information filters;Middleware;Mobile communication;Protocols;Radiofrequency identification;Remote monitoring;Testing}, 
doi={10.1109/PIMRC.2007.4394196}, 
ISSN={2166-9570}, 
month={Sept},}
@INPROCEEDINGS{4686688, 
author={M. C. Jadud and C. L. Jacobsen and C. G. Ritson and J. Simpson}, 
booktitle={2008 IEEE International Conference on Technologies for Practical Robot Applications}, 
title={Safe parallelism for robotic control}, 
year={2008}, 
pages={137-142}, 
abstract={During the Spring 2008 semester at Olin College, we introduced the programming language occam-pi to undergraduates as part of their first course in robotics. Students were able to explore image processing and autonomous behavioral control in a parallel programming language on a small mobile robotics platform with just two weeks of tutorial instruction. Our experiences to date suggest that the language and tools we have developed allow the concise expression of complex robotic control systems, and enable the integration of events from the environment in a consistent and safe model for parallel control that is directly expressed in software.}, 
keywords={control engineering education;educational courses;image processing;mobile robots;parallel languages;parallel programming;robot programming;autonomous behavioral control;complex robotic control system;image processing;mobile robotics;occam-pi programming language;parallel programming language;robotic course;safe parallelism;tutorial instruction;Computer languages;Control system synthesis;Educational institutions;Educational robots;Image processing;Mobile robots;Parallel programming;Parallel robots;Robot control;Springs}, 
doi={10.1109/TEPRA.2008.4686688}, 
ISSN={2325-0526}, 
month={Nov},}
@INPROCEEDINGS{5090916, 
author={E. Vecchie and J. P. Talpin and K. Schneider}, 
booktitle={2009 Design, Automation Test in Europe Conference Exhibition}, 
title={Separate compilation and execution of imperative synchronous modules}, 
year={2009}, 
pages={1580-1583}, 
abstract={The compilation of imperative synchronous languages like Esterel has been widely studied, the separate compilation of synchronous modules has not, and remains a challenge. We propose a new compilation method inspired by traditional sequential code generation techniques to produce coroutines whose hierarchical structure reflects the control flow of the original source code. A minimalistic runtime system executes separately compiled modules.}, 
keywords={data flow analysis;program compilers;Esterel language;imperative synchronous language;imperative synchronous modules;minimalistic runtime system;module compilation;module execution;sequential code generation;source code control flow;Automata;Computational modeling;Computer languages;Domain specific languages;Embedded system;Flow graphs;Intellectual property;Real time systems;Virtual prototyping;Yarn}, 
doi={10.1109/DATE.2009.5090916}, 
ISSN={1530-1591}, 
month={April},}
@INPROCEEDINGS{5456987, 
author={R. S. Khaligh and M. Radetzki}, 
booktitle={2010 Design, Automation Test in Europe Conference Exhibition (DATE 2010)}, 
title={Modeling constructs and kernel for parallel simulation of accuracy adaptive TLMs}, 
year={2010}, 
pages={1183-1188}, 
abstract={We present a set of modeling constructs accompanied by a high performance simulation kernel for accuracy adaptive transaction level models. In contrast to traditional, fixed accuracy TLMs, accuracy of adaptive TLMs can be changed during simulation to the level which is most suitable for a given use case and scenario. Ad-hoc development of adaptive models can result in complex models, and the implementation detail of adaptivity mechanisms can obscure the actual logic of a model. To simplify and enable systematic development of adaptive models, we have identified several mechanisms which are applicable to a wide variety of models. The proposed constructs relieve the modeler from low level implementation details of those mechanisms. We have developed an efficient, light-weight simulation kernel optimized for the proposed constructs, which enables parallel simulation of large models on widely available, low-cost multi-core simulation hosts. The modeling constructs and the kernel have been evaluated using industrial benchmark applications.}, 
keywords={operating system kernels;transaction processing;accuracy adaptive transaction level model;ad-hoc development;adaptive TLM;adaptive models systematic development;adaptivity mechanisms;high performance simulation kernel;light weight simulation kernel;low cost multicore simulation hosts;parallel simulation;Adaptive systems;Computational modeling;Concurrent computing;Context modeling;Discrete event simulation;Embedded system;Kernel;Logic;Natural languages;Performance loss}, 
doi={10.1109/DATE.2010.5456987}, 
ISSN={1530-1591}, 
month={March},}
@INPROCEEDINGS{6690509, 
author={A. V. Brito and A. V. Negreiros and C. Roth and O. Sander and J. Becker}, 
booktitle={2013 IEEE/ACM 17th International Symposium on Distributed Simulation and Real Time Applications}, 
title={Development and Evaluation of Distributed Simulation of Embedded Systems Using Ptolemy and HLA}, 
year={2013}, 
pages={189-196}, 
abstract={Nowadays, embedded systems have a huge amount of computational power and consequently, high complexity. It is quite usual to find different applications being executed in embedded systems. Embedded system design demands for method and tools that allow the simulation and verification in an efficient and practical way. This paper proposes the development and evaluation of a solution for embedded modeling and simulation of heterogeneous Models of Computation (MoCs) in a distributed way by the integration of Ptolemy II and the High Level Architecture (HLA), a middleware for distributed discrete event simulation, in order to create an environment with high-performance execution of large-scale heterogeneous models. Experimental results demonstrate, that the use of a non distributed simulation for some situations can be infeasible, as well as the use of distributed simulation with few machines, like one, two or three computers. It was demonstrated that a speedup of factor 4 was acquired when a model with 4,000 thousands actors were distributed in 8 different machines.}, 
keywords={discrete event simulation;embedded systems;middleware;HLA;MoC;Ptolemy II;computational power;distributed discrete event simulation;embedded modeling and simulation;embedded systems;heterogeneous models of computation;high level architecture;high-performance execution;large-scale heterogeneous models;middleware;nondistributed simulation;Computational modeling;Computer architecture;Embedded systems;Ports (Computers);Sensors;Unified modeling language;Wireless sensor networks;Distributed Simulation;Embedded Systems;Heterogeneous Simulation}, 
doi={10.1109/DS-RT.2013.28}, 
ISSN={1550-6525}, 
month={Oct},}
@INPROCEEDINGS{5665620, 
author={R. Fritzsche and C. Siemers}, 
booktitle={2010 World Automation Congress}, 
title={Scheduling of time enhanced c (TEC)}, 
year={2010}, 
pages={1-6}, 
abstract={Real-time systems mainly consist of time or event-triggered tasks that must satisfy deadline-constraints and other limitations to the execution time. Scheduling of them is a common problem especially if no operating system can be used because of limited resources like code-size and CPU power. Previous approaches deal with multi-frame models to split tasks into smaller subtask that may be arranged at compile-time in a static way to cope with given deadlines. Handling of non-periodic events and context-switching problems demand a more dynamic scheduling. This paper presents an approach of using manually given information for timing constraints in order to rearrange the code to satisfy the deadlines automatically. The presented design is still able to handle events and to force the given functions to cooperate. Supporting hardware for producing timing-events may further help the system to organize the program-flow.}, 
keywords={dynamic scheduling;multiprogramming;real-time systems;software engineering;CPU power;context switching problem;deadline constraint;dynamic scheduling;event triggered task;multiframe model;nonperiodic event;program flow;real time system;split task;time enhanced C;timing constraint;Context;Switches;application-internal scheduler;forced cooperative design;multi-frame tasks;semi-dynamic scheduling;time-enhanced language}, 
ISSN={2154-4824}, 
month={Sept},}
@INPROCEEDINGS{5314042, 
author={D. L. Clark}, 
booktitle={2009 IEEE AUTOTESTCON}, 
title={Powering intelligent instruments with Lua scripting}, 
year={2009}, 
pages={101-106}, 
abstract={As the power of the integrated processors that control today's instruments continues to climb, instrument vendors will increasingly add features that allow users to utilize the added intelligence by embedding custom applications directly onboard the instrument. For the test, measurement and automation industries, this paradigm is a complement to, among other things, the advent of synthetic instruments that can ldquobe anything you want,rdquo the frequent use of mezzanine type hardware and the rise of the LXI specification in which instrument to instrument messaging allows one instrument to control and communicate with another without the necessity of a host PC. There are various approaches the instrument vendor can take to permit users to develop embedded applications to be run on the instrument processor. Arguably the most advantageous approach, to both the vendor and customer, is to embed a high level scripting language allowing the user to easily develop scripts to perform instrument based operations. The Lua scripting language is a compact, full featured scripting language that is easily portable and seamlessly integrates into embedded designs. Written in pure ISO ANSI-C, the Lua interpreter and Lua libraries have been successfully ported to a large number of platforms, big and small, and with and without advanced operating systems such as Windows and Linux. Lua contains an API for interfacing directly to and from the instrument's embedded firmware and includes a full suite of libraries. Further, Lua is extendable. Thus, in addition to embedding the language interpreter and libraries, the vendor can implement custom libraries and various other custom utilities to increase the flexibility of the system and enhance the capabilities of the user developed scripts. This paper studies the use of Lua in intelligent instrumentation. It discusses features that provide flexibility and power to users embedding applications onboard instruments and it presents some real wo- rld applications of the technology.}, 
keywords={Linux;application program interfaces;authoring languages;automatic test equipment;embedded systems;API;ATE system;ISO ANSI-C;LXI specification;Linux;Lua scripting language;Windows;automated test equipment;automation industries;custom libraries;custom utilities;embedded applications;full featured scripting language;high level scripting language;instrument based operation;instrument to instrument messaging;integrated processor;intelligent instrumentation;language interpreter;mezzanine type hardware;onboard instruments;Automatic control;Automatic testing;Automation;Communication industry;Hardware;ISO;Industrial control;Instruments;Libraries;Process control}, 
doi={10.1109/AUTEST.2009.5314042}, 
ISSN={1088-7725}, 
month={Sept},}
@INPROCEEDINGS{7336328, 
author={D. Yunge and P. Kindt and M. Balszun and S. Chakraborty}, 
booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
title={Hybrid Apps: Apps for the Internet of Things}, 
year={2015}, 
pages={1175-1180}, 
abstract={Smartphones have become popular mainly because of the large variety of applications they can run. In contrast, most devices in the phone's environment - e.g., household appliances or environmental sensors - are much less flexible because their functionality is hardcoded at the design time. In order to realize the vision of the Internet of Things (IoT), where all devices communicate with each other to realize joint tasks, it is necessary that these devices are able to extend and adapt their functionalities on-the-fly based on their surrounding. To realize smart functionalities for IoT devices, we propose "hybrid Apps", the concept of Smartphone "Apps" applied to small embedded systems. In contrast with current packaged "smart home" solutions, where all appliances have to be changed to their smart counterparts at the same time, hybrid Apps permit an incremental and hence feasible deployment of the IoT vision. In this paper we discuss the challenges and opportunities associated with this approach. We argue code interpretation as a candidate reprogramming method for IoT devices and analyzed its feasibility with real-world measurements of key parameters such as computational and energy overhead. While in general, code interpretation incurs a large energy-overhead, we show that for typical IoT applications executed every few seconds, it is as low as 1%.}, 
keywords={Internet of Things;embedded systems;home computing;smart phones;Internet of Things;IoT applications;IoT devices;candidate reprogramming method;code interpretation;embedded systems;energy-overhead;hybrid apps;packaged smart home solutions;smartphone apps;Hardware;Java;Middleware;Protocols;Random access memory;Temperature sensors;Apps;Code Interpreter;Reprogrammability;Virtual Machines;Wireless Sensor Networks}, 
doi={10.1109/HPCC-CSS-ICESS.2015.292}, 
month={Aug},}
@INPROCEEDINGS{6473629, 
author={Â. L. V. d. Negreiros and A. V. Brito}, 
booktitle={2012 Brazilian Symposium on Computing System Engineering}, 
title={The Development of a Methodology with a Tool Support to the Distributed Simulation of Heterogeneous and Complexes Embedded Systems}, 
year={2012}, 
pages={37-42}, 
abstract={Nowadays, embedded systems contains a big computational power and consequently a big complexity. It is very common to find different kinds of applications being executed in embedded systems. With this scenario, it is necessary some method and/or tool that allows the simulation of those systems in an efficient and practice way. The goal of this paper is to expose the integration between Ptolemy II and HLA in order to enable the elaboration of one methodology, with a tool support, to model and simulate large scale heterogeneous embedded systems.}, 
keywords={computational complexity;digital simulation;embedded systems;HLA;Ptolemy II;big complexity;complexes embedded systems;computational power;distributed simulation;large scale heterogeneous embedded systems;tool support;Computational modeling;Computer architecture;Embedded systems;Hardware;Integrated circuit modeling;Mathematical model;Unified modeling language;Distributed Simulation;HLA;Heterogeneous Systems;High Level Architecture;Ptolemy}, 
doi={10.1109/SBESC.2012.16}, 
ISSN={2324-7886}, 
month={Nov},}
@INPROCEEDINGS{6926617, 
author={Ye Jihua and W. Wang}, 
booktitle={2014 9th International Conference on Computer Science Education}, 
title={Research and design of solar photovoltaic power generation monitoring system based on TinyOS}, 
year={2014}, 
pages={1020-1023}, 
abstract={In this paper, in order to solve management problems and field maintenance difficult issues existing in the process of PV power generation, we have designed a remote intelligent monitoring system based on TinyOS for monitoring and management. This system had implemented remote monitoring and reverse control by host computer, ARM gateways, wireless sensor networks and other components.}, 
keywords={microcontrollers;photovoltaic power systems;power system measurement;wireless sensor networks;ARM gateways;PV power generation;TinyOS;field maintenance;host computer;management problems;remote intelligent monitoring system;remote monitoring;reverse control;wireless sensor networks;Computers;Data analysis;Logic gates;Monitoring;Routing;Wireless communication;Wireless sensor networks;IOT;TinyOS;node;remote monitoring}, 
doi={10.1109/ICCSE.2014.6926617}, 
month={Aug},}
@INPROCEEDINGS{6825342, 
author={A. V. Brito and A. V. Negreiros}, 
booktitle={2013 III Brazilian Symposium on Computing Systems Engineering}, 
title={Allowing Large-Scale Systems Evaluation with Ptolemy through Distributed Simulation}, 
year={2013}, 
pages={53-58}, 
abstract={Nowadays, embedded systems have a huge amount of computational power and consequently, high complexity. It is quite usual to find different applications being executed in embedded systems. Embedded system design demands for method and tools that allow the simulation and verification in an efficient and practical way. This paper proposes the development and evaluation of a solution for embedded modeling and simulation of embedded systems in a distributed way by the integration of Ptolemy II and the High Level Architecture (HLA), in order to create an environment with high-performance execution of large-scale models. Experimental results demonstrated that the use of a non distributed simulation for some situations can be infeasible. It was demonstrated that a speedup of factor 4 was acquired when a model with 4,000 thousands actors were distributed in 8 different machines. It also presented a model of execution of each CPU core during the simulation.}, 
keywords={digital simulation;embedded systems;telecommunication computing;wireless sensor networks;CPU core;HLA;Ptolemy II;embedded modeling;embedded simulation;embedded system design;high level architecture;high-performance execution;large-scale models;large-scale systems evaluation;nondistributed simulation;wireless sensor network;Computational modeling;Computer architecture;Embedded systems;Graphics;Unified modeling language;Wireless sensor networks;Distributed Simulation;Embedded Systems;Heterogeneous Simulation}, 
doi={10.1109/SBESC.2013.19}, 
ISSN={2324-7886}, 
month={Dec},}
@ARTICLE{5710575, 
author={W. Liu and J. Xu and J. K. Muppala and W. Zhang and X. Wu and Y. Ye}, 
journal={IEEE Embedded Systems Letters}, 
title={Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models}, 
year={2011}, 
volume={3}, 
number={1}, 
pages={46-49}, 
abstract={SystemC is a widely used electronic system-level (ESL) design language that can be used to model both hardware and software at different stages of system design. There has been a lot of research on behavior synthesis of hardware from SystemC, but relatively little work on synthesizing embedded software for SystemC designs. In this letter, we present an approach to automatic software synthesis from SystemC-based on coroutines instead of the traditional approaches based on real-time operating system (RTOS) threads. Performance evaluation results on some realistic applications show that our approach results in impressive reduction of runtime overheads compared to the thread-based approaches.}, 
keywords={C++ language;embedded systems;operating systems (computers);SystemC models;coroutine-based synthesis;electronic system-level design language;embedded software synthesis;real-time operating system threads;Context;Instruction sets;Kernel;Prototypes;Switches;Synchronization;Performance;SystemC;software synthesis}, 
doi={10.1109/LES.2011.2112634}, 
ISSN={1943-0663}, 
month={March},}
@INPROCEEDINGS{6064506, 
author={E. A. Lee}, 
booktitle={2011 Proceedings of the Ninth ACM International Conference on Embedded Software (EMSOFT)}, 
title={Heterogeneous actor modeling}, 
year={2011}, 
pages={3-12}, 
abstract={Complex systems demand diversity in the modeling mechanisms. This “roadmap” paper prescribes an approach to modeling based on concurrent communicating components (called actors), where a diversity of orchestration strategies govern the execution and interaction of the components. The prescribed approach has been extensively explored in the Ptolemy Project, but as yet is not widely deployed in engineering practice. The approach achieves interaction between diverse models using an abstract semantics, which is a deliberately incomplete semantics that cannot by itself define a useful modeling framework. It instead focuses on the interactions between diverse models, reducing the nature of those interactions to a minimum that achieves a well-defined composition. The actor semantics is an abstract semantics that can handle many heterogeneous models that are built today, and some that are not common today. The actor abstract semantics and many concrete semantics are implemented in Ptolemy II, an open-source software framework.}, 
keywords={large-scale systems;multiprocessing programs;public domain software;Ptolemy project;abstract semantics;actor semantics;complex systems;concurrent communicating components;heterogeneous actor modeling;modeling mechanisms;open-source software;orchestration strategies;roadmap;Adaptation models;Computational modeling;Mathematical model;Object oriented modeling;Semantics;Syntactics;Unified modeling language;Ptolemy;heterogeneity;models of computation}, 
doi={10.1145/2038642.2038646}, 
month={Oct},}
@INPROCEEDINGS{4725258, 
author={M. Khezri and M. A. Sarram and F. Adibniya}, 
booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
title={Simplifying Concurrent Programming of Networked Embedded Systems}, 
year={2008}, 
pages={993-998}, 
abstract={TinyOS is the current state of the art in operating systems for sensor network research. Event- based programming model of TinyOS presents concept of Task to allow postponing processing. For little processing and memory overhead and to avoid race conditions, tasks are non-preemptive. This causes executing long running task reduce system responsiveness. In general two approaches suggested for solving this problem: cooperative and multithreaded multitasking. In this paper we propose a new TinyOS task scheduler to integrate these approaches with new type of tasks. We argue that this approach improves the overall system responsiveness without concerning about data races or complicate programming for developers.}, 
keywords={multi-threading;operating systems (computers);processor scheduling;telecommunication computing;wireless sensor networks;TinyOS;concurrent programming;cooperative multitasking;event-based programming model;memory overhead;multithreaded multitasking;networked embedded systems;operating systems;postponing processing;sensor network;task scheduler;Delay;Embedded system;Job shop scheduling;Multitasking;Operating systems;Programming profession;Sensor systems;Sensor systems and applications;Wireless sensor networks;Yarn;Cooperative;Embedded System;Multitasking;Scheduler;TinyOS;Yield}, 
doi={10.1109/ISPA.2008.138}, 
ISSN={2158-9178}, 
month={Dec},}
@INPROCEEDINGS{7363616, 
author={S. Park and H. Kim and S. Y. Kang and C. H. Koo and H. Joe}, 
booktitle={2015 IEEE 13th International Conference on Embedded and Ubiquitous Computing}, 
title={Lua-Based Virtual Machine Platform for Spacecraft On-Board Control Software}, 
year={2015}, 
pages={44-51}, 
abstract={Mission critical embedded software for autonomous operation requires high development cost due to its long development cycle. One of the potential solutions for reducing the cost is to reuse the software developed at previous missions. Virtual machine platform such as JVM is a good example to provide code portability across various missions. Flight software in aerospace field is adopting this concept to improve reusability and eventually to reduce development cost. In this paper, we propose a Lua-based virtualization environment for spacecraft flight software. Flight software for spacecraft control consists of a few tasks that are highly autonomous. Lua is chosen as the script language for programming the control tasks. Though Lua was designed with simplicity and portability, it only supports multithreading with collaborative coroutines. To support preemptive multitasking, we implement time slicing coroutines as spacecraft control processes. New coroutine scheduler is devised and time slicing functionality is added into the scheduler. Scheduler locking and message passing with external flight software are also implemented. Instead of modifying the Lua interpreter, we have exploited the debug support APIs for our implementation. For evaluation, we have implemented the flight software virtualization environment on the flight computer. Accuracy of the time slicing scheduler is also analyzed.}, 
keywords={aerospace control;application program interfaces;authoring languages;control engineering computing;message passing;multi-threading;program debugging;scheduling;software portability;software reusability;space vehicles;spacecraft computers;virtual machines;virtualisation;JVM;Lua interpreter;Lua script language;Lua-based virtual machine platform;Lua-based virtualization environment;aerospace field;autonomous operation;code portability;collaborative coroutines;control task programming;coroutine scheduler;debug support API;development cost reduction;flight computer;flight software virtualization environment;highly autonomous task;message passing;mission critical embedded software;multithreading;preemptive multitasking;scheduler locking;software reuse;spacecraft control;spacecraft flight software;spacecraft on-board control software;time slicing coroutines;time slicing scheduler;Computers;Engines;Runtime;Software;Space vehicles;Virtual machining;Virtualization;Lua;OBCP;mission critical embedded software;reusability;spacecraft;virtual machine}, 
doi={10.1109/EUC.2015.21}, 
month={Oct},}
@INPROCEEDINGS{6913222, 
author={C. Motika and R. von Hanxleden and M. Heinold}, 
booktitle={16th IEEE International Symposium on Object/component/service-oriented Real-time distributed Computing (ISORC 2013)}, 
title={Programming deterministic reactive systems with Synchronous Java}, 
year={2013}, 
pages={1-8}, 
abstract={A key issue in the development of reliable embedded software is the proper handling of reactive control-flow, which typically involves concurrency. Java and its thread concept have only limited provisions for implementing deterministic concurrency. Thus, as has been observed in the past, it is challenging to develop concurrent Java programs without any deadlocks or race conditions. To alleviate this situation, the Synchronous Java (SJ) approach presented here adopts the key concepts that have been established in the world of synchronous programming for handling reactive control-flow. Thus SJ not only provides deterministic concurrency, but also different variants of deterministic preemption. Furthermore SJ allows concurrent threads to communicate with Esterel-style signals. As a case study for an embedded system usage, we also report on how the SJ concepts have been ported to the ARM-based Lego Mindstorms NXT system.}, 
keywords={Java;concurrency control;embedded systems;object-oriented programming;ARM-based Lego Mindstorms NXT system;Esterel-style signals;Synchronous Java;concurrent Java programs;deterministic concurrency;deterministic preemption;deterministic reactive systems programming;embedded software development;embedded system usage;reactive control-flow handling;synchronous programming;Concurrent computing;Instruction sets;Java;Monitoring;Real-time systems;Switches;Synchronization}, 
doi={10.1109/ISORC.2013.6913222}, 
ISSN={1555-0885}, 
month={June},}
@INPROCEEDINGS{6513574, 
author={R. von Hanxleden and M. Mendler and J. Aguado and B. Duderstadt and I. Fuhrmann and C. Motika and S. Mercer and O. O'Brien}, 
booktitle={2013 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={Sequentially constructive concurrency A conservative extension of the synchronous model of computation}, 
year={2013}, 
pages={581-586}, 
abstract={Synchronous languages ensure deterministic concurrency, but at the price of heavy restrictions on what programs are considered valid, or constructive. Meanwhile, sequential languages such as C and Java offer an intuitive, familiar programming paradigm but provide no guarantees with regard to deterministic concurrency. The sequentially constructive model of computation (SC MoC) presented here harnesses the synchronous execution model to achieve deterministic concurrency while addressing concerns that synchronous languages are unnecessarily restrictive and difficult to adopt. In essence, the SC MoC extends the classical synchronous MoC by allowing variables to be read and written in any order as long as sequentiality expressed in the program provides sufficient scheduling information to rule out race conditions. The SC MoC is a conservative extension in that programs considered constructive in the common synchronous MoC are also SC and retain the same semantics. In this paper, we identify classes of variable accesses, define sequential constructiveness based on the concept of SC-admissible scheduling, and present a priority-based scheduling algorithm for analyzing and compiling SC programs.}, 
keywords={Computational modeling;Concurrent computing;Electronic mail;Instruction sets;Java;Programming;Schedules}, 
doi={10.7873/DATE.2013.128}, 
ISSN={1530-1591}, 
month={March},}
@INPROCEEDINGS{4340471, 
author={M. Yao and X. Zhu}, 
booktitle={2007 International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={Study and Transplant of Operating System for Wireless Sensor Network Node}, 
year={2007}, 
pages={2803-2807}, 
abstract={This paper studies the embedded operating system TinyOS, including its event-driven mechanism, schedule strategy mechanics, power management mechanism, and etc. Then, the component-based architecture of TinyOS is analyzed. Based on these, the transplant scheme, the design principle of the layer of hardware description and the selection principle of processor are provided. Finally, this paper gives some conclusions and foresight.}, 
keywords={embedded systems;network operating systems;power aware computing;scheduling;wireless sensor networks;TinyOS embedded operating system transplant scheme;component-based architecture;event-driven mechanism;hardware description layer design principle;power management mechanism;processor selection principle;schedule strategy mechanics;wireless sensor network node;Application software;Batteries;Communication system control;Data processing;Energy management;Hardware;Operating systems;Power supplies;Power system management;Wireless sensor networks}, 
doi={10.1109/WICOM.2007.696}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{5751491, 
author={M. Geilen and S. Stuijk}, 
booktitle={2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)}, 
title={Worst-case performance analysis of Synchronous Dataflow scenarios}, 
year={2010}, 
pages={125-134}, 
abstract={Synchronous Dataflow (SDF) is a powerful analysis tool for regular, cyclic, parallel task graphs. The behaviour of SDF graphs however is static and therefore not always able to accurately capture the behaviour of modern, dynamic dataflow applications, such as embedded multimedia codecs. An approach to tackle this limitation is by means of scenarios. In this paper we introduce a technique and a tool to automatically analyse a scenario-aware dataflow model for its worst-case performance. A system is specified as a collection of SDF graphs representing individual scenarios of behaviour and a finite state machine that specifies the possible orders of scenario occurrences. This combination accurately captures more dynamic applications and this way provides tighter results than an existing analysis based on a conservative static dataflow model, which is too pessimistic, while looking only at the `worst-case' individual scenario, without considering scenario transitions, can be too optimistic. We introduce a formal semantics of the model, in terms of (max; +) linear system-theory and in particular (max; +) automata. Leveraging existing results and algorithms from this domain, we give throughput analysis and state space generation algorithms for worst-case performance analysis. The method is implemented in a tool and the effectiveness of the approach is experimentally evaluated.}, 
keywords={computational complexity;data analysis;data flow analysis;data flow graphs;finite state machines;SDF graph;embedded multimedia codecs;finite state machine;formal semantics;linear system theory;parallel task graph;scenario-aware dataflow model;state space generation algorithm;synchronous dataflow scenario;worst case performance analysis;(max; +) algebra;Synchronous Data Flow;worst-case performance analysis}, 
doi={10.1145/1878961.1878985}, 
month={Oct},}
@ARTICLE{4135373, 
author={H. D. Patel and S. K. Shukla and R. A. Bergamaschi}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={Heterogeneous Behavioral Hierarchy Extensions for SystemC}, 
year={2007}, 
volume={26}, 
number={4}, 
pages={765-780}, 
abstract={System level design methodology and language support for high-level modeling enhances productivity for designing complex embedded systems. For an effective methodology, efficiency of simulation and a sound refinement-based implementation path are also necessary. Although some of the recent system level design languages (SLDLs) such as SystemC, SystemVerilog, or SpecC have features for system level abstractions, several essential ingredients are missing from these. We consider: 1) explicit support for multiple models of computation (MoCs) or heterogeneity so that distributed reactive embedded systems with hardware and software components can be easily modeled; 2) the ability to build complex behaviors by hierarchically composing simpler behaviors and the ability to distinguish between structural and heterogeneous behavioral hierarchy; and 3) hierarchical composition of behaviors that belong to distinct MoCs, as essential for successful SLDLs. One important requirement for such an SLDL should be that the simulation semantics are compositional, and hence no flattening of hierarchically composed behaviors are needed for simulation. In this paper, we show how we designed SystemC extensions to facilitates for heterogeneous behavioral hierarchy, compositional simulation semantics, and a simulation kernel that shows up to 40% more efficient than standard SystemC simulation}, 
keywords={circuit simulation;embedded systems;high level synthesis;logic design;specification languages;SystemC;behavioral decomposition;compositional simulation semantics;distributed reactive embedded systems;heterogeneous behavioral hierarchy;hierarchical finite state machine;hierarchical synchronous data flow;high-level modeling;language support;multiple models of computation;simulation kernel;structural modeling;system level abstractions;system level design;Circuit simulation;Computational modeling;Design methodology;Embedded computing;Embedded software;Embedded system;Hardware design languages;Productivity;Software systems;System-level design;Behavioral decomposition;SystemC;behavioral modeling;embedded system design;heterogeneous behavioral hierarchy;hierarchical finite state machine (HFSM);hierarchical synchronous data flow (SDF);models of computation (MoCs);simulation efficiency;structural modeling;system level designs}, 
doi={10.1109/TCAD.2006.884859}, 
ISSN={0278-0070}, 
month={April},}
@INPROCEEDINGS{6047305, 
author={H. Nguyen and D. Abramson and B. Bethwaite and M. N. Dinh and C. Enticott and S. Garic and A. B. M. Russel and S. Firth and I. Harper and M. Lackmann and M. Vail and S. Schek}, 
booktitle={2011 40th International Conference on Parallel Processing Workshops}, 
title={Integrating Scientific Workflows and Large Tiled Display Walls: Bridging the Visualization Divide}, 
year={2011}, 
pages={308-316}, 
abstract={Modern in-silico science (or e-Science) is a complex process, often involving multiple steps conducted across different computing environments. Scientific workflow tools help scientists automate, manage and execute these steps, providing a robust and repeatable research environment. Increasingly workflows generate data sets that require scientific visualization, using a range of display devices such as local workstations, immersive 3D caves and large display walls. Traditionally, this display step handled outside the workflow, and output files are manually copied to a suitable visualization engine for display. This inhibits the scientific discovery process disconnecting the workflow that generated the data from the display and interpretation processes. In this paper we present a solution that links scientific workflows with a variety of display devises, including large tiled display walls. We demonstrate the feasibility of the system by a prototype implementation that leverages the Kepler workflow engine and the SAGE display software. We illustrate the use of the system with a case study in workflow driven microscopy.}, 
keywords={data visualisation;display devices;file organisation;scientific information systems;workflow management software;Kepler workflow engine;SAGE display software;data sets;display device;e-science;file copying;in-silico science;interpretation processes;large tiled display walls;scientific discovery process;scientific visualization;scientific workflow tool;visualization divide;visualization engine;Data visualization;Educational institutions;Engines;Middleware;Rendering (computer graphics);Streaming media;E-Science;Kepler;Optiportal;Scientific Workflows;Tiled Display Wall;Visualization}, 
doi={10.1109/ICPPW.2011.30}, 
ISSN={0190-3918}, 
month={Sept},}
@INPROCEEDINGS{7336309, 
author={W. B. Gardner and A. Gumtie and J. D. Carter}, 
booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
title={Supporting Selective Formalism in CSP++ with Process-Specific Storage}, 
year={2015}, 
pages={1057-1065}, 
abstract={Communicating Sequential Processes (CSP) is a formal language whose primary purpose is to model and verify concurrent systems. The CSP++ toolset was created to realize the concept of selective formalism by making machine-readable CSPm specifications both executable (through automatic C++ code generation) and extensible (by allowing integration of C++ user-coded functions, UCFs). However, UCFs were limited by their inability to share data with each other, thus their application was constrained to solving simple problems in isolation. We extend CSP++ by providing UCFs in the same CSP process with safe access to a shared storage area, similar in concept and API to Pthreads' thread-local storage, enabling cooperation between them and granting them the ability to undertake more complex tasks without breaking the formalism of the underlying specification. Process-specific storage is demonstrated with a line-following robot case study, applying CSP++ in a soft real-time system. Also described is the Eclipse plug-in that supports the CSPm design flow.}, 
keywords={C++ language;application program interfaces;communicating sequential processes;concurrency (computers);control engineering computing;formal languages;formal specification;formal verification;program compilers;real-time systems;robots;storage management;API;C++ user-coded function;CSP++;CSPm design flow;Eclipse plug-in;Pthread thread-local storage;UCF;automatic C++ code generation;concurrent system modelling;concurrent system verification;formal language;line-following robot case study;machine-readable CSPm specification;process-specific storage;selective formalism;soft real-time system;Libraries;Real-time systems;Robot sensing systems;Switches;System recovery;Writing;C++;CSPm;Eclipse;Timed CSP;code generation;embedded systems;formal methods;model-based design;selective formalism;soft real-time;software synthesis}, 
doi={10.1109/HPCC-CSS-ICESS.2015.265}, 
month={Aug},}
@INPROCEEDINGS{4570792, 
author={P. K. Huang and M. Hashemi and S. Ghiasi}, 
booktitle={2008 Symposium on Application Specific Processors}, 
title={System-Level Performance Estimation for Application-Specific MPSoC Interconnect Synthesis}, 
year={2008}, 
pages={95-100}, 
abstract={We present a framework for development of streaming applications as concurrent software modules running on multi-processors system-on-chips (MPSoC). We propose an iterative design space exploration mechanism to customize MPSoC architecture for given applications. Central to the exploration engine is our system-level performance estimation methodology, that both quickly and accurately determine quality of candidate architectures. We implemented a number of streaming applications on candidate architectures that were emulated on an FPGA. Hardware measurements show that our system-level performance estimation method incurs only 15% error in predicting application throughput. More importantly, it always correctly guides design space exploration by achieving 100% fidelity in quality-ranking candidate architectures. Compared to behavioral simulation of compiled code, our system-level estimator runs more than 12 times faster, and requires 7 times less memory.}, 
keywords={field programmable gate arrays;multiprocessing systems;parallel architectures;system-on-chip;FPGA;MPSoC interconnect synthesis;design space exploration;system-level performance estimation;Application software;Computational modeling;Computer architecture;Field programmable gate arrays;Hardware;Network synthesis;Software performance;Space exploration;System-on-a-chip;Throughput}, 
doi={10.1109/SASP.2008.4570792}, 
month={June},}
@ARTICLE{4100760, 
author={S. Pasricha and N. D. Dutt}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={A Framework for Cosynthesis of Memory and Communication Architectures for MPSoC}, 
year={2007}, 
volume={26}, 
number={3}, 
pages={408-420}, 
abstract={Memory and communication architectures have a significant impact on the cost, performance, and time-to-market of complex multiprocessor system-on-chip (MPSoC) designs. The memory architecture dictates most of the data traffic flow in a design, which in turn influences the design of the communication architecture. Thus, there is a need to cosynthesize the memory and communication architectures to avoid making suboptimal design decisions. This is in contrast to traditional platform-based design approaches where memory and communication architectures are synthesized separately. In this paper, the authors propose an automated application-specific cosynthesis framework for memory and communication architecture (COSMECA) in MPSoC designs. The primary objective is to design a communication architecture having the least number of buses, which satisfies performance and memory-area constraints, while the secondary objective is to reduce the memory-area cost. Results of applying COSMECA to several industrial strength MPSoC applications from the networking domain indicate a saving of as much as 40% in number of buses and 29% in memory area compared to the traditional approach}, 
keywords={high level synthesis;integrated circuit design;integrated memory circuits;memory architecture;multiprocessing systems;system buses;system-on-chip;COSMECA;automated application-specific cosynthesis framework;communication architectures;complex multiprocessor system-on-chip designs;data traffic flow;memory architectures;Bandwidth;Costs;Digital systems;High level synthesis;Libraries;Memory architecture;Multiprocessing systems;Network synthesis;System performance;Time to market;Communication system performance;digital systems;high-level synthesis;memory architecture}, 
doi={10.1109/TCAD.2006.884487}, 
ISSN={0278-0070}, 
month={March},}
@INPROCEEDINGS{7460722, 
author={M. P. Andersen and G. Fierro and D. E. Culler}, 
booktitle={2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
title={System Design for a Synergistic, Low Power Mote/BLE Embedded Platform}, 
year={2016}, 
pages={1-12}, 
abstract={Modern IoT prototyping platforms fall short in terms of energy efficiency, connectivity and software programming practices. We present the design of a new hardware and software platform that addresses these shortcomings by bringing together Mobile, Wearable, Maker and Wireless Sensor Network technologies to enable rapid prototyping with a high degree of synergy and energy efficiency. This is achieved in part by leveraging the Memory Protection Unit on modern microcontrollers along with a novel syscall interface to provide kernel / user isolation and a clean concurrency model. Such a design allows a wide range of languages to be used for application development without significant adaptation. We demonstrate how careful choice of application language allows the naturally asynchronous nature of embedded programming to be expressed cleanly and powerfully. Finally we evaluate the platform in several integrated use cases, providing examples of the capabilities introduced by Synergy.}, 
keywords={concurrency (computers);embedded systems;microcontrollers;clean concurrency model;embedded programming;low power mote-BLE embedded platform;memory protection unit;microcontrollers;mobile network technologies;rapid prototyping;syscall interface;wearable technologies;wireless sensor network technologies;Hardware;IEEE 802.15 Standard;Microcontrollers;Software;Storms;Technological innovation;Wireless sensor networks}, 
doi={10.1109/IPSN.2016.7460722}, 
month={April},}
@INPROCEEDINGS{4724900, 
author={J. Chase and B. Nelson and J. Bodily and Z. Wei and D. J. Lee}, 
booktitle={2008 16th International Symposium on Field-Programmable Custom Computing Machines}, 
title={Real-Time Optical Flow Calculations on FPGA and GPU Architectures: A Comparison Study}, 
year={2008}, 
pages={173-182}, 
abstract={FPGA devices have often found use as higher-performance alternatives to programmable processors for implementing a variety of computations. Applications successfully implemented on FPGAs have typically contained high levels of parallelism and have often used simple statically-scheduled control and modest arithmetic. Recently introduced computing devices such as coarse grain reconfigurable arrays, multi-core processors, and graphical processing units (GPUs) promise to significantly change the computational landscape for the implementation of high-speed real-time computing tasks. One reason for this is that these architectures take advantage of many of the same application characteristics that fit well on FPGAs. One real-time computing task, optical flow, is difficult to apply in robotic vision applications in practice because of its high computational and data rate requirements, and so is a good candidate for implementation on FPGAs and other custom computing architectures. In this paper, a tensor-based optical flow algorithm is implemented on both an FPGA and a GPU and the two implementations discussed. The two implementations had similar performance, but with the FPGA implementation requiring 12Ã more development time. Other comparison data for these two technologies is then given for three additional applications taken from a MIMO digital communication system design, providing additional examples of the relative capabilities of these two technologies.}, 
keywords={MIMO systems;field programmable gate arrays;optical computing;program processors;FPGA devices;MIMO digital communication system design;computing architectures;graphical processing units;multicore processors;statically-scheduled control;tensor-based optical flow algorithm;Arithmetic;Computer architecture;Computer vision;Data flow computing;Field programmable gate arrays;High speed optical techniques;Image motion analysis;Multicore processing;Optical computing;Parallel processing}, 
doi={10.1109/FCCM.2008.24}, 
month={April},}
@INPROCEEDINGS{4228186, 
author={M. Cohen and T. Ponte and S. Rossetto and N. Rodriguez}, 
booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
title={Using Coroutines for RPC in Sensor Networks}, 
year={2007}, 
pages={1-8}, 
abstract={This paper proposes a concurrency model which integrates the asynchronous and event-driven nature of wireless sensor networks with higher-level abstractions that provide a more familiar programming style for the developer. As a basis for this proposal, we designed and implemented a cooperative multitasking scheduler, based on coroutines, for the TinyOS operating system. We then used this scheduler to implement RPC-like interfaces that capture different communication patterns common in wireless sensor networks. This allows the programmer to work, when appropriate, with a synchronous style, while maintaining an asynchronous model at the message exchange level.}, 
keywords={concurrency control;network operating systems;remote procedure calls;scheduling;wireless sensor networks;RPC coroutine;RPC-like interface;TinyOS operating system;concurrency model;cooperative multitasking scheduler;event-driven wireless sensor network;Computer languages;Concurrent computing;Embedded system;Multitasking;Operating systems;Programming profession;Proposals;Sensor phenomena and characterization;Testing;Wireless sensor networks}, 
doi={10.1109/IPDPS.2007.370458}, 
ISSN={1530-2075}, 
month={March},}
@ARTICLE{5492692, 
author={A. Bergel and W. Harrison and V. Cahill and S. Clarke}, 
journal={IEEE Transactions on Software Engineering}, 
title={FlowTalk: Language Support for Long-Latency Operations in Embedded Devices}, 
year={2011}, 
volume={37}, 
number={4}, 
pages={526-543}, 
abstract={Wireless sensor networks necessitate a programming model different from those used to develop desktop applications. Typically, resources in terms of power and memory are constrained. C is the most common programming language used to develop applications on very small embedded sensor devices. We claim that C does not provide efficient mechanisms to address the implicit asynchronous nature of sensor sampling. C applications for these devices suffer from a disruption in their control flow. In this paper, we present FlowTalk, a new object-oriented programming language aimed at making software development for wireless embedded sensor devices easier. FlowTalk is an object-oriented programming language in which dynamicity (e.g., object creation) has been traded for a reduction in memory consumption. The event model that traditionally comes from using sensors is adapted in FlowTalk with controlled disruption, a light-weight continuation mechanism. The essence of our model is to turn asynchronous long-latency operations into synchronous and blocking method calls. FlowTalk is built for TinyOS and can be used to develop applications that can fit in 4 KB of memory for a large number of wireless sensor devices.}, 
keywords={C language;embedded systems;intelligent sensors;object-oriented languages;object-oriented programming;software engineering;wireless sensor networks;C language;FlowTalk;TinyOS;asynchronous long-latency operations;embedded sensor devices;language support;light-weight continuation mechanism;memory consumption;memory size 4 KByte;object-oriented programming language;programming language;sensor sampling;wireless sensor networks;Application software;Automotive engineering;Biosensors;Computer languages;Embedded software;Java;Object oriented modeling;Object oriented programming;Sampling methods;Wireless sensor networks;Embedded systems;object-based programming.}, 
doi={10.1109/TSE.2010.66}, 
ISSN={0098-5589}, 
month={July},}
@INPROCEEDINGS{6820867, 
author={O. Baldellon and J. C. Fabre and M. Roy}, 
booktitle={2013 IEEE 19th Pacific Rim International Symposium on Dependable Computing}, 
title={Minotor: Monitoring Timing and Behavioral Properties for Dependable Distributed Systems}, 
year={2013}, 
pages={206-215}, 
abstract={Assessing the correct behavior of a given system at run-time can be achieved by monitoring its execution, and is complementary to off-line analysis such as static verification. In this work, we focus on run-time monitoring of system properties that include both causality and timing constraints, in distributed and time-constrained systems. Based on a description of a property that includes events and temporal constraints, expressed as a timed-arc Petri net, we show how to automatically transform it into a an executable and distributed monitoring engine. To that aim, we introduce a modification of the semantics of Petri nets to be able to execute it online on partial executions and distributed observation environments. We show how to use this formal framework to provide MINOTOR, a model-driven distributed monitoring system, describe its implementation and show its applicability on a transportation use-case.}, 
keywords={Petri nets;formal specification;program diagnostics;program verification;rail traffic;system monitoring;transportation;MINOTOR;Petri net semantics modification;behavioral property monitoring;causality;dependable distributed systems;distributed monitoring engine;distributed observation environment;executable monitoring engine;execution monitoring;model-driven distributed monitoring system;off-line analysis;partial execution;railway transportation;run-time monitoring;run-time system behavior assessment;static verification;temporal constraint;time-constrained system;timed-arc Petri net;timing constraint;timing property monitoring;Delays;Message systems;Monitoring;Petri nets;Real-time systems;Semantics;Ditributed Systems;Fault-tolerant Systems;Online Monitoring;Petri nets;Time-constrained Systems}, 
doi={10.1109/PRDC.2013.41}, 
month={Dec},}
@INPROCEEDINGS{4292873, 
author={M. Karpinski and V. Cahill}, 
booktitle={2007 4th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks}, 
title={High-Level Application Development is Realistic for Wireless Sensor Networks}, 
year={2007}, 
pages={610-619}, 
abstract={Programming wireless sensor network (WSN) applications is known to be a difficult task. Part of the problem is that the resource limitations of typical WSN nodes force programmers to use relatively low-level techniques to deal with the logical concurrency and asynchronous event handling inherent in these applications. In addition, existing general-purpose, node-level programming tools only support the networked nature of WSN applications in a limited way and result in application code that is hardly portable across different software platforms. All of this makes programming a single device a tedious and error-prone task. To address these issues we propose a high-level programming model that allows programmers to express applications as hierarchical state machines and to handle events and application concurrency in a way similar to imperative synchronous languages. Our program execution model is based on static scheduling what allows for standalone application analysis and testing. For deployment, the resulting programs are translated into efficient sequential C code. A prototype compiler for TinyOS has been implemented and its evaluation in described in this paper.}, 
keywords={C++ language;wireless sensor networks;TinyOS;asynchronous event handling;hierarchical state machines;high-level application development;high-level programming model;logical concurrency;node-level programming tools;nodes force programmers;resource limitations;sequential C code;software platforms;synchronous languages;wireless sensor networks;Application software;Computer languages;Computer science;Concurrent computing;Hardware;Operating systems;Peer to peer computing;Programming profession;Prototypes;Wireless sensor networks}, 
doi={10.1109/SAHCN.2007.4292873}, 
ISSN={2155-5486}, 
month={June},}