% Encoding: UTF-8

@Article{Andersen201796,
  author   = {Michael P. Andersen and Gabe Fierro and David E. Culler},
  title    = {Enabling synergy in IoT: Platform to service and beyond},
  journal  = {Journal of Network and Computer Applications},
  year     = {2017},
  volume   = {81},
  pages    = {96 - 110},
  issn     = {1084-8045},
  abstract = {Abstract To enable a prosperous Internet of Things (IoT), devices and services must be extensible and adapt to changes in the environment or user interaction patterns. These requirements manifest as a set of design principles for each of the layers in an IoT ecosystem, from hardware to cloud services. This paper gives concrete guidelines learned from implementing and deploying a full-stack synergistic IoT platform. We address hardware design concerns and present a reference platform, Firestorm. Upon this platform, we demonstrate firmware and personal-area networking concerns and solutions. Moving out towards larger scales we address local service discovery and syndication, and show how these principles carry through to global operation where security concerns dominate. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jnca.2016.10.017},
  keywords = {Internet of Things, Wireless sensor networks, Sensor motes, Middleware, Security, Trust, Embedded operating systems, Publish-subscribe },
  url      = {http://www.sciencedirect.com/science/article/pii/S1084804516302521},
}

@Article{Susilo200949,
  author   = {E. Susilo and P. Valdastri and A. Menciassi and P. Dario},
  title    = {A miniaturized wireless control platform for robotic capsular endoscopy using advanced pseudokernel approach},
  journal  = {Sensors and Actuators A: Physical},
  year     = {2009},
  volume   = {156},
  number   = {1},
  pages    = {49 - 58},
  issn     = {0924-4247},
  note     = {\{EUROSENSORS\} XXII, 2008},
  abstract = {A ZigBee compliant wireless controller which manages multiple tasks, such as acquiring data from sensors and driving actuators, has been purposely developed for robotic capsular endoscopy applications. Preemptive priority pseudokernel, consisting of state-driven code, coroutine, and pooled-loop algorithm, has been implemented to perform hard, firm and soft real time applications. All the components have been placed on a miniaturized board ready to be integrated in a robotic capsule (max volume of 2 cm3). },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sna.2009.03.036},
  keywords = {Pseudokernel, Real time embedded system, Robotic capsular endoscopy, Wireless miniaturized control board },
  url      = {http://www.sciencedirect.com/science/article/pii/S0924424709001642},
}

@InCollection{Walls2012229,
  author    = {Colin Walls},
  title     = {Chapter 6 - Real Time},
  booktitle = {Embedded Software (Second Edition)},
  publisher = {Newnes},
  year      = {2012},
  editor    = {Walls, Colin},
  pages     = {229 - 241},
  address   = {Oxford},
  edition   = {Second Edition},
  isbn      = {978-0-12-415822-1},
  abstract  = {This chapter focuses on the core features of real time systems. Four ways to implement a real time system have been described. Visualizing program models and event handling in embedded systems are presented in “question and answer” format. The importance of interrupts in a real-time program is also discussed. It was concluded that programming to accommodate interrupts is being readily accomplished in C using modern development tools. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-415822-1.00006-4},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124158221000064},
}

@InCollection{Larsen201467,
  author    = {Steen Larsen and Ben Lee},
  title     = {Chapter Two - Survey on System I/O Hardware Transactions and Impact on Latency, Throughput, and Other Factors},
  publisher = {Elsevier},
  year      = {2014},
  editor    = {Ali Hurson},
  volume    = {92},
  series    = {Advances in Computers},
  pages     = {67 - 104},
  abstract  = {Abstract Computer system input/output (I/O) has evolved with processor and memory technologies in terms of reducing latency, increasing bandwidth, and other factors. As requirements increase for I/O, such as networking, storage, and video, descriptor-based direct memory access (DMA) transactions have become more important in high-performance systems to move data between I/O adapters and system memory buffers. \{DMA\} transactions are done with hardware engines below the software protocol abstraction layers in all systems other than rudimentary embedded controllers. Central processing unit (CPUs) can switch to other tasks by offloading hardware \{DMA\} transfers to the I/O adapters. Each I/O interface has one or more separately instantiated descriptor-based \{DMA\} engines optimized for a given I/O port. I/O transactions are optimized by accelerator functions to reduce latency, improve throughput, and reduce \{CPU\} overhead. This chapter surveys the current state of high-performance I/O architecture advances and explores benefits and limitations. With the proliferation of \{CPU\} multicores within a system, multi-GB/s ports, and on-die integration of system functions, changes beyond the techniques surveyed may be needed for optimal I/O architecture performance. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-420232-0.00002-7},
  issn      = {0065-2458},
  keywords  = {Input/output, Processors, Controllers, Memory, DMA, Latency, Throughput, Power },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124202320000027},
}

@InCollection{Wolf2014201,
  author    = {Marilyn Wolf},
  title     = {Chapter 4 - Processes and Operating Systems},
  booktitle = {High-Performance Embedded Computing (Second Edition)},
  publisher = {Morgan Kaufmann},
  year      = {2014},
  editor    = {Wolf, Marilyn},
  pages     = {201 - 241},
  address   = {Boston},
  edition   = {Second Edition},
  isbn      = {978-0-12-410511-9},
  abstract  = {Abstract This chapter covers multiple-process systems. It compares scheduling algorithms, including the interaction between language design and scheduling mechanisms. It evaluates operating system architectures and the overhead incurred by the operating system and also considers methods for verifying the behavior of multiple process systems. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-410511-9.00004-6},
  keywords  = {processes and scheduling, processes versus tasks, static versus dynamic, constructive versus iterative improvement, priority schedulers, real-time versus general-purpose, hard versus soft, deadline definitions, process specifications, utilization, static scheduling algorithms, data dependencies and scheduling, resource dependencies, implementation, list scheduler, interval scheduling, dynamic and priority-driven scheduling, static versus dynamic priorities, Liu and Layland, RMS priority assignment, RMS utilization, earliest deadline first, least-laxity first scheduling, response time, priority inversion, priority inheritance protocols, priority ceiling protocol, hot swapping, mixed-criticality schedulability, load-based schedulability, PLRS, CBEDF, ductility, scheduling for dynamic voltage scaling, discrete voltages and frequencies, slack-based scheduling, checkpoint-driven scheduling, leakage minimization, leakage and temperature, multitasking and caches, program placement for caches, simplified process caching models, caches and scheduling, multitasking and scratch pads, CFSMs, Petri-net scheduling, software thread integration, Giotto, SHIM, general-purpose versus real-time, interrupts and scheduling, ISRs and ISTs, OS simulation, overhead study, RTU, Spring scheduler, RTM, IPC in general-purpose systems, streaming and large transfers, ACPI, embedded file systems, flash-based file challenges, wear leveling, virtual mapping, block cleaning costs, log-structured file systems, NAND versus \{NOR\} flash, NAND-oriented file systems, block-device emulation, properties, deadlock, property specification, product machines, debugging },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124105119000046},
}

@InCollection{Samek2009255,
  author    = {Miro Samek},
  title     = {Chapter 6 - Real-Time Framework Concepts},
  booktitle = {Practical \{UML\} Statecharts in C/C++ (2nd Edition)},
  publisher = {Newnes},
  year      = {2009},
  editor    = {Samek, Miro},
  pages     = {255 - 306},
  address   = {Burlington},
  edition   = {2nd Edition},
  isbn      = {978-0-7506-8706-5},
  abstract  = {Publisher Summary This chapter introduces the concepts associated with event-driven, real-time application frameworks. A real-time framework can employ a number of various \{CPU\} management policies, so it is important to understand the basic real-time concepts, starting from simple foreground/background systems through cooperative multitasking to fully preemptive multitasking. Traditionally, these execution models have been used with the blocking paradigm. Blocking is that the program which frequently waits for events, either hanging in tight polling loops or getting efficiently blocked by a multitasking kernel. The blocking model is not compatible with the event-driven paradigm, but it can be adapted. The general strategy is to centralize and encapsulate all the blocking code inside the event-driven infrastructure (the framework) so that the application code never blocks. The active object computing model combines multiple traditional event loops with a multitasking environment. In this model, applications are divided into multiple autonomous active objects, each encapsulating an execution thread (event loop), an event queue, and a state machine. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-7506-8706-5.00006-4},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780750687065000064},
}

@Article{Bowles2014190,
  author   = {Marcus Bowles and Jianjun Lu},
  title    = {Removing the blinders: A literature review on the potential of nanoscale technologies for the management of supply chains},
  journal  = {Technological Forecasting and Social Change},
  year     = {2014},
  volume   = {82},
  pages    = {190 - 198},
  issn     = {0040-1625},
  abstract = {Abstract Supply chain management requires more intelligent technology in the future; however, the current sensor technology is causing a bottleneck in the development of an intelligent supply chain. The emergence and development of nanosensors provide a good opportunity to improve the complex technical issues that supply chains need and may bring revolutionary changes to supply chains in the future. This paper reviews the current and potential application of nanosensors to every aspect of supply chains, including the \{SCM\} system, packaging, storage and distribution, supply chain safety, tracking and tracing. The particular focus will be on removing the blinders to the true potential technologies on the nanoscale for the future, not just for the management of supply chains but for firms seeking to become more competitive. This review will shed light on the profound impact nanotechnologies could have in augmenting or replacing the existing radiofrequency identification (RFID) tags or bar-code technologies. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.techfore.2013.10.017},
  keywords = {Supply chain management, Smart supply chain, Nanotechnology, Nanosensor, Smartsensor },
  url      = {http://www.sciencedirect.com/science/article/pii/S0040162513002758},
}

@InCollection{Wolf2007223,
  author    = {Wayne Wolf},
  title     = {Chapter 4 - Processes and Operating Systems},
  booktitle = {High-Performance Embedded Computing},
  publisher = {Morgan Kaufmann},
  year      = {2007},
  editor    = {Wolf, Wayne},
  pages     = {223 - 265},
  address   = {San Francisco},
  isbn      = {978-0-12-369485-0},
  abstract  = {Publisher Summary Multiple processes may be executed on a single computer processing unit (CPU) to save hardware and, to some extent, to save energy; however, it is important to be careful to share the \{CPU\} so as to meet all the real-time deadlines. A large body of literature has been written on real-time scheduling, taking into account various conditions on execution and assumptions. Real-time operating systems must be designed to efficiently implement basic operations such as scheduling, interrupt handling, and interprocess communication. Several scheduling protocols can be used to guarantee basic real-time behavior. However, it may not be possible to use 100% of the \{CPU\} if it has to be guaranteed that all the deadlines will be met. Scheduling for dynamic voltage scaling tries to stretch the execution time of processes just to meet their deadline to take advantage of the lower operating voltages allowed by slower execution. Context switching and interrupt overhead may be important in heavily utilized systems. File systems implemented in flash memory must use specialized techniques to avoid wearing out the flash memory. Concurrent system verification builds and searches state machine models to determine whether desired properties are satisfied. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-012369485-0/50005-1},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780123694850500051},
}

@Article{Lu2013115,
  author   = {Weiyun Lu and Martin Radetzki},
  title    = {Concurrent and comparative fault simulation in SystemC and its application in robustness evaluation},
  journal  = {Microprocessors and Microsystems},
  year     = {2013},
  volume   = {37},
  number   = {2},
  pages    = {115 - 128},
  issn     = {0141-9331},
  note     = {Digital System Safety and Security},
  abstract = {In this work, we present extensions to the SystemC library and automatable model transformations that enable efficient system-level fault simulation in SystemC. The method is based on extended data types which represent variables or signals as lists of values (instead of one value) consisting of a fault free reference value and any number of faulty values each of which corresponds to one fault. We inject faults (variable level faults as well as bit level faults) into objects declared with the extended data types. These faults are then propagated to other objects during SystemC simulation, until either they are classified and dropped or the simulation ends. The extended SystemC simulator is intended for robustness evaluation of digital and embedded designs, for which we propose a condition-oriented quantitative fault model. Speedups of up to 1905 and 10 are achieved for transient faults in digital circuit simulation and for a custom fault model in software algorithm robustness evaluation, respectively. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.micpro.2012.09.005},
  keywords = {SystemC, Fault simulation, Concurrent comparative simulation, Robustness evaluation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0141933112001676},
}

@Article{Venkatesan2017311,
  author   = {Varun Venkatesan and Swamy D. Ponpandi and Akhilesh Tyagi},
  title    = {Shaping data for application performance and energy optimization in dynamic data view framework},
  journal  = {Integration, the \{VLSI\} Journal},
  year     = {2017},
  volume   = {58},
  pages    = {311 - 319},
  issn     = {0167-9260},
  abstract = {Abstract Memory access bottlenecks are often due to the result of mismatch between the processor hardware's view of data and the algorithmic/logical view of data. This variation in data views is especially more pronounced in applications involving large datasets, leading to significantly increased latency and user response times. Previous attempts to tackle this problem were primarily targeted at execution time optimization. We present a dynamic technique piggybacked on the classical dynamic binary optimization (DBO) to shape the data view for each program phase differently resulting in program execution time reduction along with reductions in access energy. Our implementation rearranges non-adjacent data into a contiguous dataview. It uses wrappers to replace irregular data access patterns with spatially local dataview. \{DDV\} (Dynamic data view), a runtime dynamic binary translation and optimization framework has been used to perform runtime instrumentation and dynamic data optimization to achieve this goal. This scheme not only ensures a reduced program execution time, but also results in lower cache access energy. Some of the commonly used benchmarks from the \{SPEC\} 2006 and SPLASH-2 suite were profiled to determine irregular data accesses from procedures which contributed heavily to the overall execution time. Wrappers built to replace these accesses with spatially adjacent data led to a significant improvement in the total execution time. On average, 20% reduction in time was achieved along with a 5% reduction in energy for \{SPEC\} 2006 and 11% reduction in time was achieved along with a 6% reduction in energy for SPLASH-2. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.vlsi.2016.12.001},
  keywords = {Dynamic binary optimization, Data shapers, Spatial locality, Performance optimization, Time and energy },
  url      = {http://www.sciencedirect.com/science/article/pii/S016792601630178X},
}

@Article{Skyrme20142266,
  author   = {Alexandre Skyrme and Noemi Rodriguez and Roberto Ierusalimschy},
  title    = {A survey of support for structured communication in concurrency control models},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2014},
  volume   = {74},
  number   = {4},
  pages    = {2266 - 2285},
  issn     = {0743-7315},
  abstract = {Abstract The two standard models used for communication in concurrent programs, shared memory and message passing, have been the focus of much debate for a long time. Still, we believe the main issue at stake should not be the choice between these models, but rather how to ensure that communication is structured, i.e., it occurs only in syntactically restricted code regions. In this survey, we explore concurrency control models and evaluate how their characteristics contribute positively or negatively to the support for structured communication. We focus the evaluation on three properties: reasonability, which is the main property we are interested in and determines how easily programmers can reason about a concurrent program’s execution; performance, which determines whether there are any distinct features which can prevent or facilitate efficient implementations; and composability, which determines whether a model offers constructs that can be used as building blocks for coarser-grained, or higher-level, concurrency abstractions. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jpdc.2013.11.005},
  keywords = {Concurrency, Communication, Survey, Model, Structured },
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731513002323},
}

@Article{Chang201544,
  author   = {Jen-Chieh Chang and Chia-Jung Chen and Rong-Guey Chang},
  title    = {A virtualization approach to develop middleware for ubiquitous high performance computing},
  journal  = {Computers \& Electrical Engineering},
  year     = {2015},
  volume   = {48},
  pages    = {44 - 59},
  issn     = {0045-7906},
  abstract = {Abstract In ubiquitous high-performance computing (UHPC), performing concurrent services is an important task of middleware. Because a major development effort is not easily achieved, isolating a virtual machine (VM) may be a helpful solution but will likely suffer from additional overhead costs. This challenge can also be resolved by reusing the device driver. However, these solutions are difficult to implement without the \{VM\} technique. In this study, we present an alternative approach to minimizing overhead and develop a middleware called userspace virtualized middleware (Uware). Instead of bypassing the VM, the proposed approach depends on userspace transparency and contention management to shift the \{VM\} concept into middleware. We introduce two strategies to enhance the system adaptively: comprehensive restructuring by simplifying the \{VM\} memory mechanism and implementing zero-copy buffers to reuse devices. The result demonstrates that Uware is feasible and could be applied in a broad variety of UHPC. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.compeleceng.2015.09.008},
  keywords = {Middleware, Ubiquitous high performance computing, Virtualization, Concurrency control },
  url      = {http://www.sciencedirect.com/science/article/pii/S0045790615003158},
}

@Article{Chouliaras2016466,
  author   = {V.A. Chouliaras and D. Stevens and V.M. Dwyer},
  title    = {VThreads: A novel \{VLIW\} chip multiprocessor with hardware-assisted \{PThreads\}},
  journal  = {Microprocessors and Microsystems},
  year     = {2016},
  volume   = {47, Part B},
  pages    = {466 - 485},
  issn     = {0141-9331},
  abstract = {Abstract We discuss VThreads, a novel \{VLIW\} \{CMP\} with hardware-assisted shared-memory Thread support. \{VThreads\} supports Instruction Level Parallelism via static multiple-issue and Thread Level Parallelism via hardware-assisted \{POSIX\} Threads along with extensive customization. It allows the instantiation of tightly-coupled streaming accelerators and supports up to 7-address Multiple-Input, Multiple-Output instruction extensions. \{VThreads\} is designed in technology-independent Register-Transfer-Level \{VHDL\} and prototyped on 40  nm and 28  nm Field-Programmable gate arrays. It was evaluated against a PThreads-based multiprocessor based on the Sparc-V8 ISA. On a 65  nm \{ASIC\} implementation \{VThreads\} achieves up to x7.2 performance increase on synthetic benchmarks, x5 on a parallel Mandelbrot implementation, 66% better on a threaded \{JPEG\} implementation, 79% better on an edge-detection benchmark and ∼13% improvement on \{DES\} compared to the Leon3MP CMP. In the range of 2 to 8 cores, \{VThreads\} demonstrates a post-route (statistical) power reduction between 65% and 57% at an area increase of 1.2%–10% for 1–8 cores, compared to a similarly-configured Leon3MP CMP. This combination of micro-architectural features, scalability, extensibility, hardware support for low-latency PThreads, power efficiency and area make the processor an attractive proposition for low-power, deeply-embedded applications requiring minimum \{OS\} support. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.micpro.2016.07.010},
  keywords = {\{RTL\} implementation, Embedded microprocessors, Hardware/software interface, Configurable \{VLIW\} architectures, Field-programmable gate array design, Standard-cell design },
  url      = {http://www.sciencedirect.com/science/article/pii/S014193311630093X},
}

@InCollection{Tratt2009149,
  author    = {Laurence Tratt},
  title     = {Chapter 5 Dynamically Typed Languages},
  publisher = {Elsevier},
  year      = {2009},
  volume    = {77},
  series    = {Advances in Computers},
  pages     = {149 - 184},
  abstract  = {Abstract Dynamically typed languages such as Python and Ruby have experienced a rapid grown in popularity in recent times. However, there is much confusion as to what makes these languages interesting relative to statically typed languages, and little knowledge of their rich history. In this chapter, I explore the general topic of dynamically typed languages, how they differ from statically typed languages, their history, and their defining features. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/S0065-2458(09)01205-4},
  issn      = {0065-2458},
  url       = {http://www.sciencedirect.com/science/article/pii/S0065245809012054},
}

@Article{Suri20101780,
  author   = {Neeraj Suri and Arshad Jhumka and Martin Hiller and András Pataricza and Shariful Islam and Constantin Sârbu},
  title    = {A software integration approach for designing and assessing dependable embedded systems},
  journal  = {Journal of Systems and Software},
  year     = {2010},
  volume   = {83},
  number   = {10},
  pages    = {1780 - 1800},
  issn     = {0164-1212},
  abstract = {Embedded systems increasingly entail complex issues of hardware–software (HW–SW) co-design. As the number and range of \{SW\} functional components typically exceed the finite \{HW\} resources, a common approach is that of resource sharing (i.e., the deployment of diverse \{SW\} functionalities onto the same \{HW\} resources). Consequently, to result in a meaningful co-design solution, one needs to factor the issues of processing capability, power, communication bandwidth, precedence relations, real-time deadlines, space, and cost. As \{SW\} functions of diverse criticality (e.g. brake control and infotainment functions) get integrated, an explicit integration requirement need is to carefully plan resource sharing such that faults in low-criticality functions do not affect higher-criticality functions. On this background, the main contribution of this paper is a dependability-driven framework that helps to conduct the integration of \{SW\} components onto \{HW\} resources such that the maintenance of system dependability over integration of diverse criticality components is assured by design. We first develop a clustering strategy for \{SW\} components into Fault Containment Modules (FCMs) such that error propagation via interaction is minimized. Subsequently, the rules of composition for \{FCMs\} with respect to error propagation are developed. To allocate the resulting \{FCMs\} to the existing \{HW\} resources we provide several heuristics, each optimizing particular attributes thereof. Further, a framework for assessing the goodness of the achieved HW–SW composition as a dependable embedded system is presented. Two new techniques for quantifying the goodness of the proposed mappings are introduced by examples, both based on a multi-criteria decision theoretic approach. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jss.2010.04.063},
  keywords = {Embedded systems, Dependability, Software integration, Assessment, Decision theory },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121210001305},
}

@InCollection{Douglass2014225,
  author    = {Bruce Powel Douglass},
  title     = {Chapter 9 - Concurrency and Resource Architecture},
  booktitle = {Real-Time \{UML\} Workshop for Embedded Systems (Second Edition)},
  publisher = {Newnes},
  year      = {2014},
  editor    = {Douglass, Bruce Powel},
  pages     = {225 - 241},
  address   = {Oxford},
  edition   = {Second Edition},
  isbn      = {978-0-12-407781-2},
  abstract  = {Abstract The concurrency architecture identifies the threads of execution, the allocation of software elements to those threads, specifies how the threads will be scheduled, and defines how resources will be shared among them. Concurrency is a key aspect of almost any real-time and embedded system because it so directly influences its performance. This chapter discusses the definition of concurrency architecture in some detail, and provides a workflow for its full specification. Several design patterns are provided to address different issues that arise in multitasking systems. Exercises are provided for modeling the concurrency and resource architecture for the Roadrunner Traffic Light Control System and the Coyote Unmanned Air Vehicle. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-407781-2.00009-X},
  keywords  = {Concurrency, task, process, resource, thread, utility function, scheduling patterns, cyclic executive, round robin, priority-based preemption, rate monotonic scheduling (RMS), deadline, period, jitter, blocking, execution time, priority, urgency, criticality, mutual exclusion, resource sharing patterns, critical regions, guarded call, message queuing, priority inversion, priority inheritance, race condition, timeliness, schedulability, synchronization patterns, interrupt },
  url       = {http://www.sciencedirect.com/science/article/pii/B978012407781200009X},
}

@InCollection{Douglass2007141,
  author    = {Bruce Powel Douglass},
  title     = {6 - Architectural Design},
  booktitle = {Real Time \{UML\} Workshop for Embedded Systems},
  publisher = {Newnes},
  year      = {2007},
  editor    = {Douglass, Bruce Powel},
  series    = {Embedded Technology},
  pages     = {141 - 177},
  address   = {Burlington},
  isbn      = {978-0-7506-7906-0},
  abstract  = {Publisher Summary In the Harmony process, architecture is defined to be the set of strategic design decisions that specify how the elements in the system are organized and interact. The key terms in the definition are “strategic” and “design.” In the Harmony process, design is all about optimization. The analysis model is driven primarily by the functional requirements of the system, and design is driven by the quality of service requirements and other optimality characteristics collectively known as “design criteria.” An analysis model may be optimized in almost infinitely different ways to achieve different optimization goals. For example, memory usage can be optimized at the expense of worst-case performance, or reusability can be optimized at the expense of development time. The analysis model specifies what must be present for the solution to be correct; design specifies a solution that is optimal against the criticality-weighted set of design criteria. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-075067906-0/50009-6},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780750679060500096},
}

@Article{Zhang2017,
  author   = {Yangyang Zhang and Jianxin Li and Chenggen Sun and Md Zakirul Alam Bhuiyan and Weiren Yu and Richong Zhang},
  title    = {HotML: A DSM-based Machine Learning System for Social Networks},
  journal  = {Journal of Computational Science},
  year     = {2017},
  pages    = {-},
  issn     = {1877-7503},
  abstract = {Abstract In big data era, social networks, such as Twitter, Weibo, Facebook, are becoming more and more popular worldwide. To help social networks analysis, many machine learning (ML) algorithms have been adopted, e.g. user classification, link prediction, sentiment analysis, recommendations, etc. However, the dataset could be so large that it might take even days to train a model on a machine learning system. Performance issues should be considered to boost the training process. In this paper, we proposed HotML, a general machine learning system. HotML is designed in the parameter server (PS) architecture where the servers manage the globally shared parameters organized in tabular structure, and the workers compute the dataset in parallel and update the global parameters. HotML is based on our prior work \{DPS\} that provides high-level data abstraction, lightweight task scheduling system, and \{SSP\} consistency. HotML improved the \{DPS\} design by decoupling \{PS\} server and \{PS\} worker physically, and provides flexible consistency models including SSPPush, \{SSPDrop\} besides SSP, fault tolerance including consistent server-side checkpoint and flexible worker-side checkpoint, and workload balancing. To demonstrate the performance and scalability of the proposed system, a series of experiments are conducted and the results show that HotML can reduce networking time by about 74%, and achieve up to 1.9x performance compared to the popular \{ML\} system, Petuum. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jocs.2017.09.006},
  keywords = {Big data, Parameter server, Distributed machine learning, Fault tolerance },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877750317303459},
}

@Article{Oz2012160,
  author   = {Isil Oz and Haluk Rahmi Topcuoglu and Mahmut Kandemir and Oguz Tosun},
  title    = {Reliability-aware core partitioning in chip multiprocessors},
  journal  = {Journal of Systems Architecture},
  year     = {2012},
  volume   = {58},
  number   = {3–4},
  pages    = {160 - 176},
  issn     = {1383-7621},
  abstract = {Executing multiple applications concurrently is an important way of utilizing the computational power provided by emerging chip multiprocessor (CMP) architectures. However, this multiprogramming brings a resource management and partitioning problem, for which one can find numerous examples in the literature. Most of the resource partitioning schemes proposed to date focus on performance or energy centric strategies. In contrast, this paper explores reliability-aware core partitioning strategies targeting CMPs. One of our schemes considers both performance and reliability objectives by maximizing a novel combined metric called the vulnerability-delay product (VDP). The vulnerability component in this metric is represented with Thread Vulnerability Factor (TVF), a recently proposed metric for quantifying thread vulnerability for multicores. Execution time of the given application represents the delay component of the \{VDP\} metric. As part of our experimental analysis, proposed core partitioning schemes are compared with respect to normalized weighted speedup, normalized weighted reliability loss and normalized weighted vulnerability delay product gain metrics for various workloads of benchmark applications. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sysarc.2012.02.005},
  keywords = {Reliability, Thread vulnerability, Multicores, Core partitioning, Reliability-aware computing },
  url      = {http://www.sciencedirect.com/science/article/pii/S1383762112000070},
}

@Article{Cicirelli20071817,
  author   = {Franco Cicirelli and Angelo Furfaro and Libero Nigro},
  title    = {Exploiting agents for modelling and simulation of coverage control protocols in large sensor networks},
  journal  = {Journal of Systems and Software},
  year     = {2007},
  volume   = {80},
  number   = {11},
  pages    = {1817 - 1832},
  issn     = {0164-1212},
  abstract = {A sensor network is composed of low-cost, low-power nodes densely deployable over a (possibly in-hospitable) territory in order to monitor the state of the environment, e.g. temperature, sound, radiation and so forth. Sensors have the ability to self-organize into an interconnected network and to cooperate for collecting, aggregating and disseminating information to end users. Major challenges in dealing with sensor networks are the strong limitations imposed by finite onboard power capacity. This paper proposes a lightweight actor infrastructure that is well-suited to modelling and simulation of complex sensor networks and, more in general, of multi-agent systems. This infrastructure is exploited for designing and implementing an efficient actor-based distributed simulation model for studying specific aspects of large wireless sensor networks. The paper proposes and compares the performances of two protocols for the coverage control problem that achieve their objective as an emergent property. In particular, one of the two protocols adopts a novel approach based on an evolutionary game. Distributed simulation of the achieved actor-based models is characterized by good execution performances witnessed by reported experimental results. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jss.2007.02.015},
  keywords = {Multi-agent systems, Actors, Wireless sensor networks, Evolutionary games, Distributed simulation, Java },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121207000647},
}

@Article{Ritson2012727,
  author   = {Carl G. Ritson and Adam T. Sampson and Frederick R.M. Barnes},
  title    = {Multicore scheduling for lightweight communicating processes},
  journal  = {Science of Computer Programming},
  year     = {2012},
  volume   = {77},
  number   = {6},
  pages    = {727 - 740},
  issn     = {0167-6423},
  note     = {(1) Coordination 2009 (2) \{WCRE\} 2009},
  abstract = {Process-oriented programming is a design methodology in which software applications are constructed from communicating concurrent processes. A typical process-oriented design involves the composition of a large number of small isolated component processes. These concurrent components allow for the scalable parallel execution of the resulting application on both shared-memory and distributed-memory architectures. In this paper we present a runtime designed to support process-oriented programming by providing lightweight processes and communication primitives. The runtime’s scheduler, implemented using lock-free algorithms, automatically executes concurrent components in parallel on multicore systems. Heuristics dynamically group processes into cache-affine work units based on communication patterns. Work units are then distributed via wait-free work-stealing. Initial performance analysis shows that, using the algorithms presented in this paper, process-oriented software can execute with an efficiency approaching that of optimised sequential and coarse-grain threaded designs. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.scico.2011.04.006},
  keywords = {Concurrency, Multicore, Process-oriented, Scheduling },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642311001286},
}

@Article{Uddin2014529,
  author   = {Irfan Uddin and Raphael Poss and Chris Jesshope},
  title    = {Cache-based high-level simulation of microthreaded many-core architectures},
  journal  = {Journal of Systems Architecture},
  year     = {2014},
  volume   = {60},
  number   = {7},
  pages    = {529 - 552},
  issn     = {1383-7621},
  abstract = {Abstract The accuracy of simulated cycles in high-level simulators is generally less than the accuracy in detailed simulators for a single-core systems, because high-level simulators simulate the behaviour of components rather than the components themselves as in detailed simulators. The simulation problem becomes more challenging when simulating many-core systems, where many cores are executing instructions concurrently. In these systems data may be accessed from multiple caches and the abstraction of the instruction execution has to consider the dynamic resource sharing on the whole chip. The problem becomes even more challenging in microthreaded many-core systems, because there may exist concurrent hardware threads. Which means that the latency of long latency operations can be tolerated from many cycles to just few cycles. We have previously presented a simulation technique to improve the accuracy in high-level simulation of microthreaded many-core systems, known as Signature-based high- level simulator, which adapts the throughput of the program based on the type of instructions, number of instructions and number of active threads in the pipeline. However, it disregards the access to different levels of the caches on the many-core system. Accessing L1-cache has far less latency than accessing off-chip memory and if the core is not able to tolerate latency, different levels of caches can not be treated equally. The distributed cache network along with the synchronization-aware coherency protocol in the Microgrid is a complicated memory architecture and it is difficult to simulate its behaviour at a high-level. In this article we present a high-level cache model, which aims to improve the accuracy in high-level simulators for general-purpose many-core systems by adding little complexity to the simulator and without affecting the simulation speed. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sysarc.2014.05.003},
  keywords = {Distributed cache network, High-level cache modelling, High-level simulation, Many-core systems },
  url      = {http://www.sciencedirect.com/science/article/pii/S1383762114000812},
}

@Comment{jabref-meta: databaseType:bibtex;}
