% Encoding: UTF-8

@Article{Schimpf:2012:MPE:2379703.2379738,
  author     = {Schimpf, Paul H.},
  title      = {Modified Protothreads for Embedded Systems},
  journal    = {J. Comput. Sci. Coll.},
  year       = {2012},
  volume     = {28},
  number     = {1},
  pages      = {177--184},
  month      = oct,
  issn       = {1937-4771},
  abstract   = {Protothreads are stackless lightweight threads that provide a mechanism for concurrent programming with very low overhead in any environment that supports an ANSI-C compiler. No processor-specific task switching code is required to implement them. In their published form they are not quite adequate for a priority-based based scheduler and thus are of questionable utility in an embedded system with real-time requirements. This article discusses the protothread library along with modifications and an example priority-based scheduler that may be of some utility in embedded systems environments lacking an RTOS. },
  acmid      = {2379738},
  address    = {USA},
  db         = {ACM},
  issue_date = {October 2012},
  numpages   = {8},
  publisher  = {Consortium for Computing Sciences in Colleges},
  url        = {http://dl.acm.org/citation.cfm?id=2379703.2379738},
}

@Article{Saeedloei:2016:MMV:2930957.2930963,
  author     = {Saeedloei, Neda and Gupta, Gopal},
  title      = {A Methodology for Modeling and Verification of Cyber-physical Systems Based on Logic Programming},
  journal    = {SIGBED Rev.},
  year       = {2016},
  volume     = {13},
  number     = {2},
  pages      = {34--42},
  month      = apr,
  issn       = {1551-3688},
  abstract   = {Model-based design and development has been applied successfully to design and development of complex systems, including safety critical systems. It is also a promising approach for designing cyber-physical systems (CPSs). In this paper we propose a methodology for model-based design of CPSs where, logic programming extended with coinduction, constraints over reals, and coroutining is used for modeling CPSs. This logic programming realization can be used for verifying interesting properties as well as generating implementations of CPSs. We use the reactor temperature control system as a running example to illustrate the various steps of our methodology. We present a model of the system using our framework and verify the safety property of the system. We also show how parametric analysis can be performed in our framework.},
  acmid      = {2930963},
  address    = {New York, NY, USA},
  db         = {ACM},
  doi        = {10.1145/2930957.2930963},
  issue_date = {April 2016},
  numpages   = {9},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2930957.2930963},
}

@Article{Saeedloei:2011:LMV:2000367.2000374,
  author     = {Saeedloei, Neda and Gupta, Gopal},
  title      = {A Logic-based Modeling and Verification of CPS},
  journal    = {SIGBED Rev.},
  year       = {2011},
  volume     = {8},
  number     = {2},
  pages      = {31--34},
  month      = jun,
  issn       = {1551-3688},
  abstract   = {Cyber-physical systems (CPS) consist of perpetually and concurrently executing physical and computational components. The presence of physical components require the computational components to deal with continuous quantities. A formalism that can model discrete and continuous quantities together with concurrent, perpetual execution is lacking. In this paper we report on the development of a formalism based on logic programming extended with co-induction, constraints over reals, and coroutining that allows CPS to be elegantly modeled. This logic programming realization can be used for verifying interesting properties as well as generating implementations of CPS. We illustrate this formalism by applying it to elegant modeling of the reactor temperature control system. Interesting properties of the system can be verified merely by posing appropriate queries to this model. Precise parametric analysis can also be performed.  },
  acmid      = {2000374},
  address    = {New York, NY, USA},
  db         = {ACM},
  doi        = {10.1145/2000367.2000374},
  issue_date = {June 2011},
  numpages   = {4},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2000367.2000374},
}

@Article{Kumar:2007:ESI:1210268.1210270,
  author     = {Kumar, Nagendra J. and Asokan, Vasanth and Shivshankar, Siddhartha and Dean, Alexander G.},
  title      = {Efficient Software Implementation of Embedded Communication Protocol Controllers Using Asynchronous Software Thread Integration with Time- and Space-efficient Procedure Calls},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  year       = {2007},
  volume     = {6},
  number     = {1},
  month      = feb,
  issn       = {1539-9087},
  abstract   = {The overhead of context switching limits efficient scheduling of multiple concurrent threads on a uniprocessor when real-time requirements exist. A software-implemented protocol controller may be crippled by this problem. The available idle time may be too short to recover through context switching, so only the primary thread can execute during message activity, slowing the secondary threads and potentially missing deadlines. Asynchronous software thread integration (ASTI) uses coroutine calls and integration, letting threads make independent progress efficiently, and reducing the needed context switches. We demonstrate the methods with a software implementation of an automotive communication protocol (J1850) and several secondary threads.},
  acmid      = {1210270},
  address    = {New York, NY, USA},
  articleno  = {2},
  db         = {ACM},
  doi        = {10.1145/1210268.1210270},
  issue_date = {February 2007},
  keywords   = {Asynchronous software thread integration, J1850, fine-grain concurrency, hardware to software migration, software-implemented communication protocol controllers},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1210268.1210270},
}

@InProceedings{Jahier:2016:RRP:2906363.2906372,
  author    = {Jahier, Erwan},
  title     = {RDBG: A Reactive Programs Extensible Debugger},
  booktitle = {Proceedings of the 19th International Workshop on Software and Compilers for Embedded Systems},
  year      = {2016},
  series    = {SCOPES '16},
  pages     = {116--125},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Debugging reactive programs requires to provide a lot of inputs -- at each reaction step. Moreover, because a reactive system reacts to an environment it tries to control, providing realistic inputs can be hard. The same considerations apply for automatic testing. This work take advantage on previous work on automated testing of reactive programs that close this feedback loop.  This article demonstrates how to implement opportunistically such a debugging commands interpreter by taking advantage of an existing (ocaml) toplevel Read-Eval-Print Loop (REPL). Then it shows how a small kernel is enough to build a full-featured debugger with little effort. The given examples provide a tutorial for end-users that wish to write their own debugging primitives, fitting to their needs, or to tune existing ones.  An orthogonal contribution of this article is to present an efficient way to implement the debugger coroutining using continuations.  The Reactive programs DeBuGger (RDBG) prototype aims at being versatile and general enough to be able to deal with any reactive languages. We have experimented it on 2 synchronous programming: Lustre and Lutin.},
  acmid     = {2906372},
  db        = {ACM},
  doi       = {10.1145/2906363.2906372},
  isbn      = {978-1-4503-4320-6},
  keywords  = {Code Instrumentation, Compiler, Continuations, Dynamic Analysis, Interpreter, Monitor, Programmable Debuggers, Reactive systems, Synchronous languages},
  location  = {Sankt Goar, Germany},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2906363.2906372},
}

@InProceedings{vonHanxleden:2009:SCP:1629335.1629366,
  author    = {von Hanxleden, Reinhard},
  title     = {SyncCharts in C: A Proposal for Light-weight, Deterministic Concurrency},
  booktitle = {Proceedings of the Seventh ACM International Conference on Embedded Software},
  year      = {2009},
  series    = {EMSOFT '09},
  pages     = {225--234},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {SyncCharts in C (SC) extends C with control flow operators for deterministic, light-weight concurrency and preemption. SC is based on SyncCharts, a synchronous variant of Statecharts with a sound formal basis. SC implements concurrency via a simulation of multi-threading, inspired by reactive processing. This approach permits very fast context switches and allows to express SC operators with regular, sequential C code. Thus a concurrent SC program requires neither a special compiler nor OS support for concurrency.  A reference implementation of SC, based on C macros, is available as open source code. SC can be used in a number of scenarios: 1) as a regular programming language, requiring just a C compiler; 2) as an intermediate target language for synthesizing graphical SyncChart models into executable code, in a traceable manner; 3) as instruction set architecture for programming precision timed (PRET) or reactive architectures, abstracting functionality from physical timing; or 4) as a virtual machine instruction set, with a very dense encoding.},
  acmid     = {1629366},
  db        = {ACM},
  doi       = {10.1145/1629335.1629366},
  isbn      = {978-1-60558-627-4},
  keywords  = {SyncCharts, esterel, model-based design, multi-threading, reactive processing, statecharts, synchronous programming},
  location  = {Grenoble, France},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1629335.1629366},
}

@InProceedings{Hannig:2011:RPS:1988932.1988941,
  author    = {Hannig, Frank and Roloff, Sascha and Snelting, Gregor and Teich, J\"{u}rgen and Zwinkau, Andreas},
  title     = {Resource-aware Programming and Simulation of MPSoC Architectures Through Extension of X10},
  booktitle = {Proceedings of the 14th International Workshop on Software and Compilers for Embedded Systems},
  year      = {2011},
  series    = {SCOPES '11},
  pages     = {48--55},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The efficient use of future MPSoCs with 1000 or more processor cores requires new means of resource-aware programming to deal with increasing imperfections such as process variation, fault rates, aging effects, and power as well as thermal problems. In this paper, we apply a new approach called invasive computing that enables an application programmer to spread computations to processors deliberately and on purpose at certain points of the program. Such decisions can be made depending on the degree of application parallelism and the state of the underlying resources such as utilization, load, and temperature. The introduced programming constructs for resource-aware programming are embedded into the parallel computing language X10 as developed by IBM using a library-based approach. Moreover, we show how individual heterogeneous MPSoC architectures may be modeled for subsequent functional simulation by defining compute resources such as processors themselves by lightweight threads that are executed in parallel together with the application threads by the X10 run-time system. Thus, the state changes of each hardware resource may be simulated including temperature, aging, and other useful monitor functionality to provide a first high-level programming test-bed for invasive computing.},
  acmid     = {1988941},
  db        = {ACM},
  doi       = {10.1145/1988932.1988941},
  isbn      = {978-1-4503-0763-5},
  keywords  = {MPSoC, X10, resource-aware programming, simulation},
  location  = {St. Goar, Germany},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1988932.1988941},
}

@Article{Ali:2011:PPM:2070336.2070350,
  author     = {Ali, Hazem Ismail and Pinho, Lu\'{\i}s Miguel},
  title      = {A Parallel Programming Model for Ada},
  journal    = {Ada Lett.},
  year       = {2011},
  volume     = {31},
  number     = {3},
  pages      = {19--26},
  month      = nov,
  issn       = {1094-3641},
  abstract   = {Over the last three decades, computer architects have been able to achieve an increase in performance for single processors by, e.g., increasing clock speed, introducing cache memories and using instruction level parallelism. However, because of power consumption and heat dissipation constraints, this trend is going to cease. In recent times, hardware engineers have instead moved to new chip architectures with multiple processor cores on a single chip. With multi-core processors, applications can complete more total work than with one core alone. To take advantage of multi-core processors, parallel programming models are proposed as promising solutions for more effectively using multi-core processors. This paper discusses some of the existent models and frameworks for parallel programming, leading to outline a draft parallel programming model for Ada.  },
  acmid      = {2070350},
  address    = {New York, NY, USA},
  db         = {ACM},
  doi        = {10.1145/2070336.2070350},
  issue_date = {December 2011},
  keywords   = {ada, lightweight threads model, many-core systems, parallel programming},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2070336.2070350},
}

@InProceedings{Ali:2011:PPM:2070337.2070350,
  author    = {Ali, Hazem Ismail and Pinho, Lu\'{\i}s Miguel},
  title     = {A Parallel Programming Model for Ada},
  booktitle = {Proceedings of the 2011 ACM Annual International Conference on Special Interest Group on the Ada Programming Language},
  year      = {2011},
  series    = {SIGAda '11},
  pages     = {19--26},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Over the last three decades, computer architects have been able to achieve an increase in performance for single processors by, e.g., increasing clock speed, introducing cache memories and using instruction level parallelism. However, because of power consumption and heat dissipation constraints, this trend is going to cease. In recent times, hardware engineers have instead moved to new chip architectures with multiple processor cores on a single chip. With multi-core processors, applications can complete more total work than with one core alone. To take advantage of multi-core processors, parallel programming models are proposed as promising solutions for more effectively using multi-core processors. This paper discusses some of the existent models and frameworks for parallel programming, leading to outline a draft parallel programming model for Ada.  },
  acmid     = {2070350},
  db        = {ACM},
  doi       = {10.1145/2070337.2070350},
  isbn      = {978-1-4503-1028-4},
  keywords  = {ada, lightweight threads model, many-core systems, parallel programming},
  location  = {Denver, Colorado, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2070337.2070350},
}

@Article{6393004,
  title   = {CEDA Currents [IEEE News]},
  journal = {IEEE Solid-State Circuits Magazine},
  year    = {2012},
  volume  = {4},
  number  = {4},
  pages   = {62-63},
  month   = {Dec},
  issn    = {1943-0582},
  db      = {IEEE},
  doi     = {10.1109/MSSC.2012.2214295},
}

@InProceedings{4417219,
  author    = {Jiri Zdenek},
  title     = {Efficient scheduler-dispatcher software architecture of the spacepower facility distributed control computer},
  booktitle = {2007 European Conference on Power Electronics and Applications},
  year      = {2007},
  pages     = {1-10},
  month     = {Sept},
  abstract  = {The system software architecture of the distributed control computer (computer network) of the mechatronic scientific facility (crystallizer) for automatic high temperature material processing in a orbital space station in micro-gravitation environment is presented in this paper. The scientific facility consists of the multi-zone high temperature furnace with heating system, PWM controlled heating converters, the precise extra low speed vibration-less electric drives to make possible to manipulate the processed material samples during experiments, very precise temperature measurement module, telemetric channel, crew interface computer, free programmable central controller and several further units. Facility computer network nodes have many user tasks (processes) divided into many threads running in real time environment. Using preemptive real time operating system tends to have unacceptable high overhead therefore the system of table driven coroutines with low system resource requirement (overhead, stack space) was designed. Emphasis is given on the design of efficient, reliable and self documented scheduler-dispatcher of the user tasks with minimized overhead and easily extensible descriptors of table driven user finite state automata. Presented scheduler architecture is used in the distributed network control computer of newly designed facility (Advanced TITUS) intended to be placed in the ISS space station. It is advanced version of the proved software utilized in the distributed control computer of the TITUS scientific equipment which was successfully operated several years in the MIR orbital station especially during ESA missions EUROMIR.},
  db        = {IEEE},
  doi       = {10.1109/EPE.2007.4417219},
  keywords  = {aerospace computing;aerospace control;aerospace instrumentation;computer networks;crystallisers;distributed control;electric furnaces;finite state machines;mechatronics;PWM controlled heating converters;TITUS scientific equipment;automatic high temperature material processing;crew interface computer;crystallizer;distributed control computer;distributed network control computer;facility computer network nodes;finite state automata;free programmable central controller;heating system;high temperature furnace;mechatronic scientific facility;microgravitation environment;orbital space station;real time operating system;scheduler-dispatcher software architecture;space power facility;telemetric channel;temperature measurement module;vibrationless electric drives;Automatic control;Centralized control;Computer architecture;Computer networks;Distributed computing;Distributed control;Processor scheduling;Resistance heating;Software architecture;Space stations;Measurement;Mechatronics;Real time processing;Software;Space},
}

@InProceedings{7336328,
  author    = {D. Yunge and P. Kindt and M. Balszun and S. Chakraborty},
  title     = {Hybrid Apps: Apps for the Internet of Things},
  booktitle = {2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
  year      = {2015},
  pages     = {1175-1180},
  month     = {Aug},
  abstract  = {Smartphones have become popular mainly because of the large variety of applications they can run. In contrast, most devices in the phone's environment - e.g., household appliances or environmental sensors - are much less flexible because their functionality is hardcoded at the design time. In order to realize the vision of the Internet of Things (IoT), where all devices communicate with each other to realize joint tasks, it is necessary that these devices are able to extend and adapt their functionalities on-the-fly based on their surrounding. To realize smart functionalities for IoT devices, we propose "hybrid Apps", the concept of Smartphone "Apps" applied to small embedded systems. In contrast with current packaged "smart home" solutions, where all appliances have to be changed to their smart counterparts at the same time, hybrid Apps permit an incremental and hence feasible deployment of the IoT vision. In this paper we discuss the challenges and opportunities associated with this approach. We argue code interpretation as a candidate reprogramming method for IoT devices and analyzed its feasibility with real-world measurements of key parameters such as computational and energy overhead. While in general, code interpretation incurs a large energy-overhead, we show that for typical IoT applications executed every few seconds, it is as low as 1%.},
  db        = {IEEE},
  doi       = {10.1109/HPCC-CSS-ICESS.2015.292},
  keywords  = {Internet of Things;embedded systems;home computing;smart phones;Internet of Things;IoT applications;IoT devices;candidate reprogramming method;code interpretation;embedded systems;energy-overhead;hybrid apps;packaged smart home solutions;smartphone apps;Hardware;Java;Middleware;Protocols;Random access memory;Temperature sensors;Apps;Code Interpreter;Reprogrammability;Virtual Machines;Wireless Sensor Networks},
}

@InProceedings{4678868,
  author    = {M. Yu and S. Xiahou and X. Li},
  title     = {A Survey of Studying on Task Scheduling Mechanism for TinyOS},
  booktitle = {2008 4th International Conference on Wireless Communications, Networking and Mobile Computing},
  year      = {2008},
  pages     = {1-4},
  month     = {Oct},
  abstract  = {Although TinyOS has been regarded as the defacto standard for WSN (Wireless Sensor Network) applications, its simple task scheduling mechanism became a great obstacle to WSN applications. This paper, from two directions (one based on cooperative, the other based on preemptive), presented a variety of scheduling algorithms and their application in TinyOS. And their characters and advantage were discussed as well in terms of energy consuming, tasks executing efficiency. Then a new, integrated and adaptive task scheduling mechanism was pointed out for the future TinyOS task scheduling. This new scheduling mechanism was characterized with features of dynamical adaptability and context-awareness.},
  db        = {IEEE},
  doi       = {10.1109/WiCom.2008.960},
  issn      = {2161-9646},
  keywords  = {scheduling;wireless sensor networks;TinyOS;task scheduling mechanism;wireless sensor network;Adaptive scheduling;Computer languages;Context;Dynamic scheduling;Mobile communication;Mobile computing;Processor scheduling;Scheduling algorithm;Sensor systems and applications;Wireless sensor networks},
}

@InProceedings{7473021,
  author    = {M. U. Yaseen and M. S. Zafar and A. Anjum and R. Hill},
  title     = {High Performance Video Processing in Cloud Data Centres},
  booktitle = {2016 IEEE Symposium on Service-Oriented System Engineering (SOSE)},
  year      = {2016},
  pages     = {152-161},
  month     = {March},
  abstract  = {Mobile phones and affordable cameras are generating large amounts of video data. This data holds information regarding several activities and incidents. Video analytics systems have been introduced to extract valuable information from this data. However, most of these systems are expensive, require human supervision and are time consuming. The probability of extracting inaccurate information is also high due to human involvement. We have addressed these challenges by proposing a cloud based high performance video analytics platform. This platform attempts to minimize human intervention, reduce computation time and enables the processing of a large number of video streams. It achieves high performance by optimizing the occupancy of GPU resources in cloud and minimizing the data transfer by concurrently processing a large number of video streams. The proposed video processing platform is evaluated in three stages. The first evaluation was performed at the cloud level in order to evaluate the scalability of the platform. This evaluation includes fetching and distributing video streams and efficiently utilizing available resources within the cloud. The second valuation was performed at the individual cloud nodes. This evaluation includes measuring the occupancy level, effect of data transfer and the extent of concurrency achieved at each node. The third evaluation was performed at the frame level in order to determine the performance of object recognition algorithms. To measure this, compute intensive tasks of the Local Binary Pattern (LBP) algorithm have been ported on to the GPU resources. The platform proved to be very scalable with high throughput and performance when tested on a large number of video streams with increasing number of nodes.},
  db        = {IEEE},
  doi       = {10.1109/SOSE.2016.56},
  keywords  = {cloud computing;computer centres;object recognition;video signal processing;video streaming;GPU resources;LBP algorithm;cameras;cloud based high performance video analytics;cloud data centres;cloud nodes;cloud resources;data transfer;high performance video processing;information extraction;local binary pattern;mobile phones;object recognition algorithms;occupancy level;video data;video stream processing;Cloud computing;Decoding;Graphics processing units;Object detection;Object recognition;Streaming media;Throughput;Cloud Computing;High Performance and GPUs;Video Processing;Video analytics},
}

@InProceedings{4340471,
  author    = {M. Yao and X. Zhu},
  title     = {Study and Transplant of Operating System for Wireless Sensor Network Node},
  booktitle = {2007 International Conference on Wireless Communications, Networking and Mobile Computing},
  year      = {2007},
  pages     = {2803-2807},
  month     = {Sept},
  abstract  = {This paper studies the embedded operating system TinyOS, including its event-driven mechanism, schedule strategy mechanics, power management mechanism, and etc. Then, the component-based architecture of TinyOS is analyzed. Based on these, the transplant scheme, the design principle of the layer of hardware description and the selection principle of processor are provided. Finally, this paper gives some conclusions and foresight.},
  db        = {IEEE},
  doi       = {10.1109/WICOM.2007.696},
  issn      = {2161-9646},
  keywords  = {embedded systems;network operating systems;power aware computing;scheduling;wireless sensor networks;TinyOS embedded operating system transplant scheme;component-based architecture;event-driven mechanism;hardware description layer design principle;power management mechanism;processor selection principle;schedule strategy mechanics;wireless sensor network node;Application software;Batteries;Communication system control;Data processing;Energy management;Hardware;Operating systems;Power supplies;Power system management;Wireless sensor networks},
}

@InProceedings{4797078,
  author    = {Y. XiangMin and W. WenYong and X. Yu},
  title     = {An IPv6 Wireless Sensor Network Node-TaraxNode},
  booktitle = {2009 WRI International Conference on Communications and Mobile Computing},
  year      = {2009},
  volume    = {2},
  pages     = {9-14},
  month     = {Jan},
  abstract  = {This paper presents the IPv6 wireless sensor network platform system TaraxNode. It is designed and implemented with independent intellectual property rights. For effectively monitoring, we developed TaraxOS, which includes a cluster-based self-organized multi-hop routing protocol. It is a multi-task, high-powered, low energy-consumed operating system for sensor nodes. TaraxNode containing heterogeneous elements provides numerous benefits at the traditional intelligent monitor system. It is mainly composed of a low power consumed MCU TaraxCore and WSN data acquired unit etc. When applied at the central air-condition intelligent monitor and control system, it gives excellent result.},
  db        = {IEEE},
  doi       = {10.1109/CMC.2009.111},
  keywords  = {computerised monitoring;industrial property;intelligent sensors;operating systems (computers);routing protocols;wireless sensor networks;IPv6;TaraxNode;TaraxOS;central air-condition intelligent monitor;cluster-based self-organized multihop routing protocol;control system;intellectual property rights;intelligent monitor system;operating system;sensor nodes;wireless sensor network node;Centralized control;Intellectual property;Intelligent control;Intelligent sensors;Intelligent systems;Monitoring;Operating systems;Routing protocols;Sensor systems;Wireless sensor networks},
}

@InProceedings{6270634,
  author    = {Q. Wu and C. Yang and F. Wang and J. Xue},
  title     = {A Fast Parallel Implementation of Molecular Dynamics with the Morse Potential on a Heterogeneous Petascale Supercomputer},
  booktitle = {2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops PhD Forum},
  year      = {2012},
  pages     = {140-149},
  month     = {May},
  abstract  = {Molecular Dynamics (MD) simulations have been widely used in the study of macromolecules. To ensure an acceptable level of statistical accuracy relatively large number of particles are needed, which calls for high performance implementations of MD. These days heterogeneous systems, with their high performance potential, low power consumption, and high price-performance ratio, offer a viable alternative for running MD simulations. In this paper we introduce a fast parallel implementation of MD simulation with the Morse potential on Tianhe-1A, a petascale heterogeneous supercomputer. Our code achieves a speedup of 3.6× on one NVIDIA Tesla M2050 GPU (containing 14 Streaming Multiprocessors) compared to a 2.93GHz six-core Intel Xeon X5670 CPU. In addition, our code runs faster on 1024 compute nodes (with two CPUs and one GPU inside a node) than on 4096 GPU-excluded nodes, effectively rendering one GPU more efficient than six six-core CPUs. Our work shows that large-scale MD simulations can benefit enormously from GPU acceleration in petascale supercomputing platforms. Our performance results are achieved by using (1) a patch-cell design to exploit parallelism across the simulation domain, (2) a new GPU kernel developed by taking advantage of Newton's Third Law to reduce redundant force computation on GPUs, (3) two optimization methods including a dynamic load balancing strategy that adjusts the workload, and a communication overlapping method to overlap the communications between CPUs and GPUs.},
  db        = {IEEE},
  doi       = {10.1109/IPDPSW.2012.13},
  keywords  = {Morse potential;chemistry computing;graphics processing units;macromolecules;molecular dynamics method;parallel machines;resource allocation;statistical analysis;GPU acceleration;GPU kernel;GPU-excluded node;MD simulation;Morse potential;NVIDIA Tesla M2050 GPU;Newton Third Law;Tianhe-1A;communication overlapping method;dynamic load balancing strategy;fast parallel implementation;heterogeneous petascale supercomputer;heterogeneous systems;macromolecules;molecular dynamics simulation;optimization method;parallelism;patch-cell design;petascale supercomputing platform;redundant force computation;six-core Intel Xeon X5670 CPU;statistical accuracy;streaming multiprocessors;workload adjustment;Computational modeling;Force;Graphics processing unit;Indexes;Instruction sets;Kernel;Mathematical model;GPU computing;Molecular Dynamics;heterogeneous computing;petascale supercomputer},
}

@Article{4397184,
  author   = {P. Wilson and A. Frey and T. Mihm and D. Kershaw and T. Alves},
  title    = {Implementing Embedded Security on Dual-Virtual-CPU Systems},
  journal  = {IEEE Design Test of Computers},
  year     = {2007},
  volume   = {24},
  number   = {6},
  pages    = {582-591},
  month    = {Nov},
  issn     = {0740-7475},
  abstract = {In this article, we describe a low-cost, dual-virtual-CPU hardware technology for embedded-systems security. We also present a case study of a programmable software design to exploit such hardware. This design integrates a rich operating system without requiring significant changes to it, while maintaining preemptive and real-time properties, exception handling, and power management.},
  db       = {IEEE},
  doi      = {10.1109/MDT.2007.196},
  keywords = {cryptography;embedded systems;flash memories;logic partitioning;operating systems (computers);virtual storage;dual-virtual-CPU system;embedded-systems security;flash memory;logical partitioning;off-chip storage device;operating system;programmable software design;Application software;Central Processing Unit;Circuit testing;Hardware;Information security;Isolation technology;Kernel;Operating systems;Packaging;Space technology;TrustZone technology;embedded security;programmable;security software framework},
}

@InProceedings{4536359,
  author    = {K. B. Wheeler and R. C. Murphy and D. Thain},
  title     = {Qthreads: An API for programming with millions of lightweight threads},
  booktitle = {2008 IEEE International Symposium on Parallel and Distributed Processing},
  year      = {2008},
  pages     = {1-8},
  month     = {April},
  abstract  = {Large scale hardware-supported multithreading, an attractive means of increasing computational power, benefits significantly from low per-thread costs. Hardware support for lightweight threads is a developing area of research. Each architecture with such support provides a unique interface, hindering development for them and comparisons between them. A portable abstraction that provides basic lightweight thread control and synchronization primitives is needed. Such an abstraction would assist in exploring both the architectural needs of large scale threading and the semantic power of existing languages. Managing thread resources is a problem that must be addressed if massive parallelism is to be popularized. The qthread abstraction enables development of large-scale multithreading applications on commodity architectures. This paper introduces the qthread API and its Unix implementation, discusses resource management, and presents performance results from the HPCCG benchmark.},
  db        = {IEEE},
  doi       = {10.1109/IPDPS.2008.4536359},
  issn      = {1530-2075},
  keywords  = {Unix;application program interfaces;multi-threading;resource allocation;API;HPCCG benchmark;Qthreads;Unix implementation;application program interfaces;large scale hardware supported multithreading;lightweight threads;qthread API;qthread abstraction;resource management;Computer architecture;Costs;Hardware;Laboratories;Large-scale systems;Multithreading;Parallel processing;Programming profession;Resource management;Yarn},
}

@InProceedings{4239012,
  author    = {X. Wang and X. Zhao and Z. Liang and M. Tan},
  title     = {Deploying a Wireless Sensor Network on the Coal Mines},
  booktitle = {2007 IEEE International Conference on Networking, Sensing and Control},
  year      = {2007},
  pages     = {324-328},
  month     = {April},
  abstract  = {In this paper we describe our experiences using a wireless sensor network to monitor the coal mines with sensors. Wireless networks that link sensors have the potential to greatly benefit for monitoring of coal mine conditions and localization of miners. Substituting light, small wireless sensor network nodes for traditional wired, heavy and fixed monitoring equipment leads to faster, easier and larger-scale deployments in complicated environment. Network consisted of many wireless sensor nodes is now feasible in practice. The primary problem of designing a wireless sensor network for coal mine monitoring and localization of miners is the high system reliability and robustness demanded by its application and safety. The topology of sensor networks is also a main factor we have to take into account. The sensor network application we designed for coal mine monitoring bases on Berkeley TinyOS and Motes platform. We evaluate this design and gain some useful experiences which will benefit our subsequent work.},
  db        = {IEEE},
  doi       = {10.1109/ICNSC.2007.372799},
  keywords  = {coal;mining industry;wireless sensor networks;coal mine monitoring;high system reliability;larger-scale deployments;miners localization;wireless sensor network;Accidents;Automation;Energy management;Large-scale systems;Monitoring;Network topology;Reliability;Robustness;Safety;Wireless sensor networks},
}

@InProceedings{5302678,
  author    = {W. h. Wang and Y. l. Cui and T. m. Chen},
  title     = {Identity-Based Authentication Protocol with Paring of Tate on WSN},
  booktitle = {2009 5th International Conference on Wireless Communications, Networking and Mobile Computing},
  year      = {2009},
  pages     = {1-4},
  month     = {Sept},
  abstract  = {Identity cryptography is widely used in security authentication. This paper proposes a standard identity-based authentication scheme, and also proves the security of the scheme under passive attack. On the basis of ECC and bilinear maps, paper implements the authentication protocol in the platform of TinyOs. Finally, paper analyzes its result and proves its feasibility.},
  db        = {IEEE},
  doi       = {10.1109/WICOM.2009.5302678},
  issn      = {2161-9646},
  keywords  = {cryptographic protocols;message authentication;telecommunication security;wireless sensor networks;TinyOs platform;WSN;cryptography;identity-based authentication protocols;security authentication;wireless sensor networks;Application software;Authentication;Cryptographic protocols;Electronic mail;Elliptic curve cryptography;Hardware;Identity-based encryption;Public key cryptography;Security;Wireless sensor networks},
}

@InProceedings{5090916,
  author    = {E. Vecchie and J. P. Talpin and K. Schneider},
  title     = {Separate compilation and execution of imperative synchronous modules},
  booktitle = {2009 Design, Automation Test in Europe Conference Exhibition},
  year      = {2009},
  pages     = {1580-1583},
  month     = {April},
  abstract  = {The compilation of imperative synchronous languages like Esterel has been widely studied, the separate compilation of synchronous modules has not, and remains a challenge. We propose a new compilation method inspired by traditional sequential code generation techniques to produce coroutines whose hierarchical structure reflects the control flow of the original source code. A minimalistic runtime system executes separately compiled modules.},
  db        = {IEEE},
  doi       = {10.1109/DATE.2009.5090916},
  issn      = {1530-1591},
  keywords  = {data flow analysis;program compilers;Esterel language;imperative synchronous language;imperative synchronous modules;minimalistic runtime system;module compilation;module execution;sequential code generation;source code control flow;Automata;Computational modeling;Computer languages;Domain specific languages;Embedded system;Flow graphs;Intellectual property;Real time systems;Virtual prototyping;Yarn},
}

@InProceedings{7562102,
  author    = {S. Thombre and R. Ul Islam and K. Andersson and M. S. Hossain},
  title     = {Performance analysis of an IP based protocol stack for WSNs},
  booktitle = {2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  year      = {2016},
  pages     = {360-365},
  month     = {April},
  abstract  = {Wireless sensor networks (WSNs) are the key enablers of the Internet of Things (IoT) paradigm. Traditionally, sensor network research has been to be unlike the internet, motivated by power and device constraints. The IETF 6LoWPAN draft standard changes this, defining how IPv6 packets can be efficiently transmitted over IEEE 802.15.4 radio links. Due to this 6LoWPAN technology, low power, low cost microcontrollers can be connected to the internet forming what is known as the Wireless embedded Internet. Another IETF recommendation, CoAP allows these devices to communicate interactively over the Internet. The integration of such tiny, ubiquitous electronic devices to the Internet enables interesting real-time applications. We evaluate the performance of a stack consisting of CoAP and 6LoWPAN over the IEEE 802.15.4 radio link using the Contiki OS and Cooja simulator, along with the CoAP framework Californium (Cf).},
  db        = {IEEE},
  doi       = {10.1109/INFCOMW.2016.7562102},
  keywords  = {IP networks;Internet of Things;Zigbee;access protocols;packet radio networks;wireless sensor networks;CoAP framework californium;Contiki OS;Cooja simulator;IEEE 802.15.4 radio links;IETF 6LoWPAN draft standard;IP based protocol stack;IPv6 packets;Internet of Things;IoT;WSN;performance analysis;ubiquitous electronic devices;wireless embedded Internet;wireless sensor networks;IEEE 802.15 Standard;IP networks;Internet of things;Protocols;Wireless sensor networks;6LoWPAN;Californium (Cf);CoAP;Contiki;Cooja},
}

@InProceedings{7001431,
  author    = {M. Tan and B. Liu and S. Dai and Z. Zhang},
  title     = {Multithreaded pipeline synthesis for data-parallel kernels},
  booktitle = {2014 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  year      = {2014},
  pages     = {718-725},
  month     = {Nov},
  abstract  = {Pipelining is an important technique in high-level synthesis, which overlaps the execution of successive loop iterations or threads to achieve high throughput for loop/function kernels. Since existing pipelining techniques typically enforce in-order thread execution, a variable-latency operation in one thread would block all subsequent threads, resulting in considerable performance degradation. In this paper, we propose a multithreaded pipelining approach that enables context switching to allow out-of-order thread execution for data-parallel kernels. To ensure that the synthesized pipeline is complexity effective, we further propose efficient scheduling algorithms for minimizing the hardware overhead associated with context management. Experimental results show that our proposed techniques can significantly improve the effective pipeline throughput over conventional approaches while conserving hardware resources.},
  db        = {IEEE},
  doi       = {10.1109/ICCAD.2014.7001431},
  issn      = {1092-3152},
  keywords  = {multi-threading;pipeline processing;processor scheduling;context management;context switching;data-parallel kernels;hardware overhead;hardware resources;high-level synthesis;in-order thread execution;loop iterations;loop/function kernels;multithreaded pipeline synthesis;out-of-order thread execution;pipeline throughput;pipelining techniques;scheduling algorithms;variable-latency operation;Context;Instruction sets;Kernel;Pipeline processing;Schedules;Switches;Throughput},
}

@InProceedings{4224663,
  author    = {C. Suh and J. E. Joung and Y. B. Ko},
  title     = {New RF Models of the TinyOS Simulator for IEEE 802.15.4 Standard},
  booktitle = {2007 IEEE Wireless Communications and Networking Conference},
  year      = {2007},
  pages     = {2236-2240},
  month     = {March},
  abstract  = {Recently, wireless sensor networks have gained increasing attention from the industry as well as academia. Various research issues related with sensor networks are intensively proposed, and they are evaluated by some network simulators or real sensor platforms. One of the well-known simulators for wireless sensor networks is called TOSSIM. It can simulate with TinyOS source codes on the real testbed without any significant modifications. Although TOSSIM's architecture and interfaces are well designed for wireless sensor networks based on IEEE 802.15.4 standards, its current RF model is too simple to support main features of the PHY stack of the IEEE 802.15.4. In order to enhance the accuracy of wireless simulation results and implement IEEE 802.15.4 standard, we design a new wireless propagation model and RF physical stack based on the two-ray ground path loss model and CC2420 RF transceiver. Our work contributes on the performance evaluation areas of wireless sensor networks and IEEE 802.15.4 WPAN standard using simulations.},
  db        = {IEEE},
  doi       = {10.1109/WCNC.2007.418},
  issn      = {1525-3511},
  keywords  = {IEEE standards;personal area networks;source coding;telecommunication standards;transceivers;wireless sensor networks;CC2420 RF transceiver;IEEE 802.15.4 standard;RF models;RF physical stack;TOSSIM;TinyOS simulator;WPAN standard;source codes;wireless propagation model;wireless sensor networks;Hardware;Intelligent sensors;Operating systems;Propagation losses;Radio frequency;Sensor systems;Transceivers;Wireless application protocol;Wireless communication;Wireless sensor networks},
}

@InProceedings{5663821,
  author    = {M. Strube and M. Daum and R. Kapitza and F. Villanueva and F. Dressler},
  title     = {Dynamic operator replacement in sensor networks},
  booktitle = {The 7th IEEE International Conference on Mobile Ad-hoc and Sensor Systems (IEEE MASS 2010)},
  year      = {2010},
  pages     = {748-750},
  month     = {Nov},
  abstract  = {We present an integrated approach for supporting in-network sensor data processing in dynamic and heterogeneous sensor networks. The concept relies on data stream processing techniques that define and optimize the distribution of queries and their operators. We anticipate a high degree of dynamics in the network, which can for example be expected in the case of wildlife monitoring applications. The distribution of operators to individual nodes demands system level capabilities not available in current sensor node operating systems. In particular, we present a system for seamless and on demand operator migration between sensor nodes. Our framework, which we implemented for Contiki running on TelosB nodes, supports stateful module migration including selected parts of the code and data sections.},
  db        = {IEEE},
  doi       = {10.1109/MASS.2010.5663821},
  issn      = {2155-6806},
  keywords  = {optimisation;wireless sensor networks;Contiki running;TelosB nodes;data stream processing;dynamic operator replacement;dynamic sensor networks;heterogeneous sensor networks;in-network sensor data processing;optimization;Data processing;Distributed databases;Operating systems;Programming;Runtime;Servers;Wireless sensor networks},
}

@InProceedings{4694538,
  author    = {D. Singh and U. S. Tiwary and Wan-Young Chung},
  title     = {IP-based ubiquitous healthcare system},
  booktitle = {2008 International Conference on Control, Automation and Systems},
  year      = {2008},
  pages     = {131-136},
  month     = {Oct},
  abstract  = {This paper presents a new concept of MAC and LOAD protocols for IP based ubiquitous healthcare system. The system used IEEE 802.15.4 standard lowpan with integrated IPv6. For healthcare system we added LOAD (6lowpan Ad-hoc on Demand Distance Vector) and MAC (Medium Access Control) protocols in Harvanpsilas 6lowpan stack. 6lowpan stack has ability to connect the physical environment in real-world applications such as healthcare, wireless sensor network, network technology etc. IP-enable motes set on the patient body for retrieving biomedical from body in PAN. PAN network connected PC via gateway or base station for further analysis or to the doctorpsilas PDA (personal digital assistant). The doctor can recognize or analysis patient data from anywhere on globe by internet service provider equipments (PDA). Result shows the performance biomedical data packets in multi-hope routing as well as represents the topology of the networks. TelosB motes were tested on octopus simulator in tinyOS2.02 for performance of biomedical data communication and network topology.},
  db        = {IEEE},
  doi       = {10.1109/ICCAS.2008.4694538},
  keywords  = {IP networks;Internet;access protocols;ad hoc networks;biomedical communication;data communication;health care;personal area networks;telecommunication network routing;telecommunication network topology;ubiquitous computing;wireless sensor networks;6lowpan ad-hoc on demand distance vector;IEEE 802.15.4 standard lowpan;IP-based ubiquitous healthcare system;IPv6;LOAD protocols;MAC protocols;biomedical data communication;multihope routing;network technology;network topology;personal digital assistant;tinyOS2.02;wireless sensor network;Access protocols;Base stations;Bioinformatics;Data analysis;Media Access Protocol;Medical services;Network topology;Personal digital assistants;Wireless application protocol;Wireless sensor networks;6lowpan;Body Area Networks;Healthcare;IP-based;PAN;TelosB;TinyOS},
}

@InProceedings{7925596,
  author    = {C. Shen and S. Chen},
  title     = {A Cyber-Physical Design for Indoor Temperature Monitoring Using Wireless Sensor Networks},
  booktitle = {2017 IEEE Wireless Communications and Networking Conference (WCNC)},
  year      = {2017},
  pages     = {1-6},
  month     = {March},
  abstract  = {Indoor temperature monitoring using wireless sensor networks is critical in many applications. For example, in data centers, it is important to monitor if the indoor temperature is within certain range so that the computers can function with near-optimal performance. In contrast to existing research that often separates the sensor network design and the measured temperature, this paper proposes a cyber-physical design approach to monitor the indoor temperature using wireless sensor networks. The source sensor wakes up and senses the temperature periodically using sleep#x002F;wake duty cycles and sends the data to the destination via multi-hop relaying nodes in an anycast way. Moreover, the period of sleep#x002F;wake duty cycle is dynamically adjusted based on the sensed temperature: when the measured temperature is normal, the sensor nodes wake up infrequently for better energy efficiency; as the sensed temperature approaches a pre-determined threshold, the sensor nodes wake up more frequently to avoid any delayed alarm trigger. The proposed design is implemented using TelosB with TinyOS, and experiments confirm that the cyber-physical system reports the alarm with a very small delay while achieving high long-term energy efficiency.},
  db        = {IEEE},
  doi       = {10.1109/WCNC.2017.7925596},
  keywords  = {computerised monitoring;cyber-physical systems;temperature sensors;wireless sensor networks;cyber-physical design;energy efficiency;indoor temperature monitoring;multihop relaying nodes;source sensor;wireless sensor networks;Monitoring;Protocols;Relays;Temperature distribution;Temperature measurement;Temperature sensors;Wireless sensor networks},
}

@InProceedings{6416747,
  author    = {R. R. Sharma and Y. Rajasekhar and R. Sass},
  title     = {Exploring hardware work queue support for lightweight threads in MPSoCs},
  booktitle = {2012 International Conference on Reconfigurable Computing and FPGAs},
  year      = {2012},
  pages     = {1-6},
  month     = {Dec},
  abstract  = {Fine-grain thread parallelism using task based programming models are a new trend in achieving massively parallel computations. Often, software pre-fetching and queuing mechanisms for managing these dynamic environments are inadequate, failing to keep the processor cores busy with computation. At the same time, the CPU-memory performance gap is getting worse and this puts a strain on memory subsystem to keep cores in a busy state. We describe a hardware based pre-fetching and queuing mechanism aimed at assisting the over-subscription of very lightweight threads per core. Experiments with a soft processor and a reconfigurable accelerator core are reported. The hardware demonstrates the ability to block on out-of-order memory transactions and alleviates the software bottleneck.},
  db        = {IEEE},
  doi       = {10.1109/ReConFig.2012.6416747},
  issn      = {2325-6532},
  keywords  = {multiprocessing systems;parallel programming;queueing theory;storage management;system-on-chip;CPU-memory performance gap;MPSoC;fine-grain thread parallelism;hardware based pre-fetching;hardware work queue support;lightweight threads;memory subsystem;multiprocessing system on chip;out-of-order memory transactions;parallel computations;queuing mechanisms;reconfigurable accelerator core;soft processor;software pre-fetching;task based programming models;Hardware;Instruction sets;Memory management;Random access memory;Registers;Switches;Throughput},
}

@InProceedings{4577683,
  author    = {H. Schweppe and A. Zimmermann and D. Grilly},
  title     = {Flexible in-vehicle stream processing with distributed automotive control units for engineering and diagnosis},
  booktitle = {2008 International Symposium on Industrial Embedded Systems},
  year      = {2008},
  pages     = {74-81},
  month     = {June},
  abstract  = {This paper introduces a method for selectively pre-processing and recording sensor data for engineering testing purposes in vehicles. In order to condense data, methodologies from the domain of sensor networks and stream processing are applied, which results in a reduction of the quantity of data, while maintaining information quality. A situation-dependent modification of recording parameters allows for a detailed profiling of vehicle-related errors. We developed a data-flow oriented model, in which data streams are connected by processing nodes. These nodes filter and aggregate the data and can be connected in nearly any order, which permits a successive composition of the aggregation and recording strategy. The integration with an event-condition-action model provides adaptability of the processing and recording, depending on the state of the vehicle. In a proof-of-concept system, which we implemented on top of the automotive diagnostic protocols KWP and UDS, the feasibility of the approach was shown. The target platform was an embedded on-board computer that is connected to the OBD-II interface of the vehicle. As the scope of recording can be adjusted flexibly, the recording system can not only be used for diagnostic purposes, but also serves objectives in development, quality assurance, and even marketing.},
  db        = {IEEE},
  doi       = {10.1109/SIES.2008.4577683},
  issn      = {2150-3109},
  keywords  = {automobiles;automotive electronics;fault diagnosis;OBD-II interface;automotive diagnostic protocol;data-flow oriented model;diagnostic software interface;distributed automotive control unit;embedded onboard computer;engineering testing purpose;event-condition-action model;flexible in-vehicle stream processing;proof-of-concept system;sensor network;Aggregates;Automotive engineering;Computer interfaces;Data engineering;Distributed control;Filters;Maintenance engineering;Protocols;Testing;Vehicles},
}

@InProceedings{5751508,
  author    = {C. Schumacher and R. Leupers and D. Petras and A. Hoffmann},
  title     = {parSC: Synchronous parallel SystemC simulation on multi-core host architectures},
  booktitle = {2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)},
  year      = {2010},
  pages     = {241-246},
  month     = {Oct},
  abstract  = {Time-consuming cycle-accurate MPSoC simulation is often needed for debugging and verification. Its practicability is put at risk by the growing MPSoC complexity. This work presents a conservative synchronous parallel simulation approach along with a SystemC framework to accelerate tightly-coupled MPSoC simulations on multi-core hosts. Key contribution is the implementation strategy, which utilizes techniques from the high-performance computing domain. Results show speed-ups of up to 4.4 on four host cores.},
  db        = {IEEE},
  doi       = {10.1145/1878961.1879005},
  keywords  = {computer debugging;multiprocessing systems;network interfaces;parallel architectures;system-on-chip;MPSoC complexity;high performance computing domain;multicore host architectures;multicore host core;synchronous parallel systemC simulation;tightly coupled MPSoC simulation;time consuming cycle accurate MPSoC simulation;Computational modeling;Data models;Kernel;Load modeling;Logic gates;Prefetching;Synchronization;Experimentation;Measurement;Performance},
}

@InProceedings{7160118,
  author    = {M. Schoeberl and R. B. Sørensen and J. Sparsø},
  title     = {Models of Communication for Multicore Processors},
  booktitle = {2015 IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
  year      = {2015},
  pages     = {9-16},
  month     = {April},
  abstract  = {To efficiently use multicore processors we need to ensure that almost all data communication stays on chip, i.e., The bits moved between tasks executing on different processor cores do not leave the chip. Different forms of on-chip communication are supported by different hardware mechanism, e.g., Shared caches with cache coherency protocols, core-to-core networks-on-chip, and shared scratchpad memories. In this paper we explore the different hardware mechanism for on-chip communication and how they support or favor different models of communication. Furthermore, we discuss the usability of the different models of communication for real-time systems.},
  db        = {IEEE},
  doi       = {10.1109/ISORCW.2015.57},
  keywords  = {data communication;multiprocessing systems;core-to-core networks-on-chip;data communication modelling;multicore processors;on-chip communication;processor cores;real-time systems;shared caches;shared scratchpad memories;Computational modeling;Hardware;Multicore processing;Program processors;Real-time systems;System-on-chip;Time division multiplexing;multicore communication;real-time systems;time-predictable systems},
}

@InProceedings{6910501,
  author    = {S. Savas and E. Gebrewahid and Z. Ul-Abdin and T. Nordström and M. Yang},
  title     = {An evaluation of code generation of dataflow languages on manycore architectures},
  booktitle = {2014 IEEE 20th International Conference on Embedded and Real-Time Computing Systems and Applications},
  year      = {2014},
  pages     = {1-9},
  month     = {Aug},
  abstract  = {Today computer architectures are shifting from single core to manycores due to several reasons such as performance demands, power and heat limitations. However, shifting to manycores results in additional complexities, especially with regard to efficient development of applications. Hence there is a need to raise the abstraction level of development techniques for the manycores while exposing the inherent parallelism in the applications. One promising class of programming languages is dataflow languages and in this paper we evaluate and optimize the code generation for one such language, CAL. We have also developed a communication library to support the intercore communication. The code generation can target multiple architectures, but the results presented in this paper is focused on Adapteva's many core architecture Epiphany. We use the two-dimensional inverse discrete cosine transform (2D-IDCT) as our benchmark and compare our code generation from CAL with a hand-written implementation developed in C. Several optimizations in the code generation as well as in the communication library are described, and we have observed that the most critical optimization is reducing the number of external memory accesses. Combining all optimizations we have been able to reduce the difference in execution time between auto-generated and handwritten implementations from a factor of 4.3× down to a factor of only 1.3×.},
  db        = {IEEE},
  doi       = {10.1109/RTCSA.2014.6910501},
  issn      = {2325-1271},
  keywords  = {computer architecture;data flow computing;multiprocessing systems;program compilers;2D inverse discrete cosine transform;2D-IDCT;code generation;communication library;computer architectures;dataflow languages;external memory accesses;heat limitations;intercore communication;manycore architectures;programming languages;Generators;Libraries;Multicore processing;Ports (Computers);Program processors;Programming;2D-IDCT;Actor Machine;Dataflow Languages;Epiphany;Manycore;code generation;evaluation},
}

@InProceedings{6164943,
  author    = {S. Roloff and F. Hannig and J. Teich},
  title     = {Approximate time functional simulation of resource-aware programming concepts for heterogeneous MPSoCs},
  booktitle = {17th Asia and South Pacific Design Automation Conference},
  year      = {2012},
  pages     = {187-192},
  month     = {Jan},
  abstract  = {The design and the programming of heterogeneous future MPSoCs including thousands of processor cores is a hard challenge. Means are necessary to program and simulate the dynamic behavior of such systems in order to dimension the hardware design and to verify the software functionality as well as performance goals. Cycle-accurate simulation of multiple parallel applications simultaneously running on different cores of the architecture would be much too slow and is not the desired level of detail. In this paper, we therefore present a novel high-level simulation approach which tackles the complexity and the heterogeneity of such systems and enables the investigation of a new computing paradigm called invasive computing. Here, the workload and its distribution are not known at compile-time but are highly dynamic and have to be adapted to the status (load, temperature, etc.) of the underlying architecture at run-time. We propose an approach for the modeling of tiled MPSoC architectures and the simulation of resource-aware programming concepts on these. This approach delivers important timing information about the parallel execution and also is taking into account the computational properties of possibly different types of cores.},
  db        = {IEEE},
  doi       = {10.1109/ASPDAC.2012.6164943},
  issn      = {2153-6961},
  keywords  = {Computational modeling;Computer architecture;Programming;Reduced instruction set computing;Synchronization;Tiles},
}

@Article{7937791,
  author   = {L. Rodríguez-Gil and J. García-Zubia and P. Orduña and D. López-de-Ipiña},
  title    = {An Open and Scalable Web-Based Interactive Live-Streaming architecture: The WILSP Platform},
  journal  = {IEEE Access},
  year     = {2017},
  volume   = {5},
  pages    = {9842-9856},
  issn     = {2169-3536},
  abstract = {Interactive live-streaming applications and platforms face particular challenges: the actions of the viewer's affect the content of the stream. A minimal capture-render delay is critical. This is the case of applications, such as remote laboratories, which allow students to view specific hardware through a webcam, and interact with it remotely in close to real time. It is also the case of other applications, such as videoconferencing or remote rendering. In the latest years, several commercial live-streaming platforms have appeared. However, the most of them have two significant limitations. First, because they are oriented toward standard live-streaming, their capture-render delay tends to be too high for interactive live-streaming. Second, their architectures and sources are closed. That makes them unsuitable for many research and practical purposes, especially when customization is required. This paper presents the requirements for an interactive live-streaming platform, focusing on remote lab needs as a case study. Then, it proposes an architecture to satisfy those requirements that relies on Redis to achieve high scalability. The architecture is based on open technologies, and has been implemented and published as open source. From a client-side perspective, it is web-based and mobile-friendly. It is intended to be useful for both research and practical purposes. Finally, this paper experimentally evaluates the proposed architecture through its contributed implementation, analyzing its performance and scalability.},
  db       = {IEEE},
  doi      = {10.1109/ACCESS.2017.2710328},
  keywords = {Internet;computer aided instruction;interactive systems;laboratories;media streaming;Redis;WILSP platform;Webcam;client-side perspective;commercial live-streaming platforms;minimal capture-render delay;open Web-based interactive live-streaming architecture;open technologies;remote lab needs;scalable Web-based interactive live-streaming architecture;standard live-streaming;viewer action;Computer architecture;Delays;Remote laboratories;Robots;Scalability;Standards;Streaming media;Webcam;live streaming;live streaming platform;online learning tools;open;remote laboratories},
}

@InProceedings{5678449,
  author    = {T. Riedel and N. Fantana and A. Genaid and D. Yordanov and H. R. Schmidtke and M. Beigl},
  title     = {Using web service gateways and code generation for sustainable IoT system development},
  booktitle = {2010 Internet of Things (IOT)},
  year      = {2010},
  pages     = {1-8},
  month     = {Nov},
  abstract  = {Wireless Sensing and Radio Identification systems have undergone many innovations during the past years. This has led to short product lifetimes for both software and hardware compared to classical industries. However, especially industries dealing with long-term support of products, e.g. of industrial machinery, and product lifetime of 40+ years may especially profit from an Internet of Things. Motivated by a practical industrial servicing use case this paper shows how we hope to make equally sustainable IoT solutions by employing a model driven software development approach based on code generation for multi-protocol web service gateways.},
  db        = {IEEE},
  doi       = {10.1109/IOT.2010.5678449},
  keywords  = {Web services;internetworking;program compilers;protocols;software engineering;sustainable development;Internet of things;IoT system;Web service gateways;code generation;industrial servicing;multi-protocol;radio identification systems;software development approach;sustainable development;Automata;Logic gates;Radiofrequency identification;Semantics;Unified modeling language;Web services;XML},
}

@InProceedings{7515633,
  author    = {D. P. B. Renaux and F. Pöttker and C. E. Soares and C. C. Valério},
  title     = {A State-Based Function-Queue Software Architecture for Electric Motor Control},
  booktitle = {2016 IEEE 19th International Symposium on Real-Time Distributed Computing (ISORC)},
  year      = {2016},
  pages     = {229-236},
  month     = {May},
  abstract  = {Increasing demands on functional and temporal requirements for the software in electric motor controllers demand for solutions that are efficient in time and space usage while providing the required functionality. Embedded software for electric motor control must deal with the control itself, and with operation, protection, supervision, safety, and user interfaces. Concerning this need, an embedded software multitasking architecture that combines the concept of function queues and of state-based code is proposed and compared to a standard implementation based on an RTOS. In the proposed solution, the queue of function pointers is partitioned into several shorter queues each one active in a given state of the system, thus, reducing queue management overhead.},
  db        = {IEEE},
  doi       = {10.1109/ISORC.2016.39},
  keywords  = {control engineering computing;embedded systems;machine control;software architecture;RTOS;electric motor control;embedded software multitasking architecture;function pointer queue;queue management;state-based code;state-based function-queue software architecture;user interfaces;Computer architecture;Electric motors;Embedded software;Motor drives;Multitasking;Real-time systems;Electrical Motor Control;Embedded Software Multitasking Architecture;Real-Time Embedded Software;Task Scheduling},
}

@InProceedings{7345624,
  author    = {E. Rakadjiev and T. Shimosawa and H. Mine and S. Oshima},
  title     = {Parallel SMT Solving and Concurrent Symbolic Execution},
  booktitle = {2015 IEEE Trustcom/BigDataSE/ISPA},
  year      = {2015},
  volume    = {3},
  pages     = {17-26},
  month     = {Aug},
  abstract  = {Satisfiability Modulo Theories (SMT) solving is a fundamental tool in numerous areas of computer science, where problems are expressed as logical formulas whose satisfiability has to be decided. State-of-the-art solvers can handle many real-world problems efficiently, however, SMT solving is an NP-hard problem, and the strong reliance on the solvers typically makes them the dominating performance hot spot of the systems utilizing them. Symbolic execution is a software analysis method used for automated high-coverage test generation, among others. It relies heavily on SMT solving and spends substantial amount of its run time, commonly more than 90%, in solver activities. In this paper, we investigate how symbolic execution can benefit from the use of general-purpose, parallel SMT solving. We present design, prototypical implementation, and evaluation of a linearly scalable SMT solver cluster and an extension of the KLEE symbolic execution engine, offering concurrent execution and asynchronous constraint solving. We show that, depending on the characteristics of the program being analyzed, KLEE's performance is improved by up to 7.6x with the help of our approach.},
  db        = {IEEE},
  doi       = {10.1109/Trustcom.2015.608},
  keywords  = {computability;computational complexity;concurrency control;constraint handling;parallel processing;program diagnostics;KLEE symbolic execution engine;NP-hard problem;asynchronous constraint solving;automated high-coverage test generation;concurrent symbolic execution;linearly scalable SMT solver cluster;logical formulas;parallel SMT solving;satisfiability modulo theories;software analysis method;Computer science;Concurrent computing;Data structures;Explosions;Scalability;Search problems;Software;Asynchronous SMT Solving;Concurrent Symbolic Execution;Distributed SMT Solving;Parallel SMT Solving;SMT Solving;Symbolic Execution},
}

@InProceedings{7972165,
  author    = {W. Pipatsakulroj and V. Visoottiviseth and R. Takano},
  title     = {muMQ: A lightweight and scalable MQTT broker},
  booktitle = {2017 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)},
  year      = {2017},
  pages     = {1-6},
  month     = {June},
  abstract  = {A message broker is an imperative component in IoT systems, and it works as a gateway between IoT devices and application platforms. With the growth of IoT devices today, these systems can easily overwhelm message brokers unless the software can fully utilize hardware resources such as multi-core facility. This paper presents muMQ, a high-performance MQTT broker running on Commercial-Off-The-Shelf hardware. It tackles the challenge to improve the performance of message brokering on a single machine by efficiently utilizing multi-core CPUs. First, muMQ exploits an event-driven I/O mechanism for multi-core scalability. Each CPU core equally handles dispatched TCP connections and locally processes MQTT logic. Second, muMQ adopts a user-level TCP/IP stack, mTCP with DPDK, to avoid the overhead of the in-kernel TCP/IP stack, including system call overhead and resource contention. We evaluate the effectiveness of our approach through experiments. The results show that muMQ can handle 512K or greater long-lived subscribers with no message loss; muMQ achieves a publish messaging rate at 930K messages per second, which is 5.38 times faster than an existing MQTT broker. We also confirm mTCP accelerates the performance by 1.8 times compared with muMQ using the in-kernel TCP/IP stack.},
  db        = {IEEE},
  doi       = {10.1109/LANMAN.2017.7972165},
  keywords  = {Internet of Things;multiprocessing systems;transport protocols;CPU core;Commercial-Off-The-Shelf hardware;DPDK;IoT devices;IoT systems;MQTT logic;application platforms;dispatched TCP connections;event-driven I/O mechanism;hardware resources;high-performance MQTT broker;in-kernel TCP/IP stack;mTCP;message brokering;muMQ;multicore CPU;multicore facility;multicore scalability;publish messaging rate;resource contention;scalable MQTT broker;single machine;user-level TCP/IP stack;Hardware;Kernel;Message systems;Multicore processing;Scalability;Sockets;TCPIP;MQTT;high performance computing;message broker;multi-core system;user-level TCP/IP stack},
}

@InProceedings{6549920,
  author    = {E. Pereira and C. Potiron and C. M. Kirsch and R. Sengupta},
  title     = {Modeling and controlling the structure of heterogeneous mobile robotic systems: A bigactor approach},
  booktitle = {2013 IEEE International Systems Conference (SysCon)},
  year      = {2013},
  pages     = {442-447},
  month     = {April},
  abstract  = {In this paper we address the problem of modelling and controlling heterogeneous mobile robotic systems at a structure-level abstraction. We consider a system of mobile robotic entities that are able to observe, control, compute, and communicate. They operate upon an abstraction of the structure of the world that entails location and connectivity as first-class concepts. Our approach is to model mobile robotic entities as bigActors [18], a model of computation that combines bigraphs with the actor model for modeling structure-aware computation. As case study, we model a mission of heterogeneous unmanned vehicles performing an environmental monitoring mission.},
  db        = {IEEE},
  doi       = {10.1109/SysCon.2013.6549920},
  keywords  = {mobile robots;BigActor approach;heterogeneous mobile robotic system;heterogeneous unmanned vehicle;structure-aware computation;structure-level abstraction;Computational modeling;Mathematical model;Mobile communication;Robots;Semantics;Vehicles},
}

@InProceedings{7117986,
  author    = {M. Pavlov and A. Petrov},
  title     = {Software architecture for scalable computing systems with automatic granularity selection of executable code},
  booktitle = {2015 17th Conference of Open Innovations Association (FRUCT)},
  year      = {2015},
  pages     = {151-156},
  month     = {April},
  abstract  = {The problem of developing software architecture and its platform implementation for scalable cloud services is addressed in the paper. New scheme of distributed software developing and executing is presented with argumentation and main principles behind solution. Performance evaluation of one of the platform components (data storage) is described.},
  db        = {IEEE},
  doi       = {10.1109/FRUCT.2015.7117986},
  issn      = {2305-7254},
  keywords  = {cloud computing;granular computing;software architecture;automatic granularity selection;data storage;distributed software development;distributed software execution;executable code;performance evaluation;scalable cloud services;scalable computing systems;software architecture;Computer architecture;Memory;Optimization;Runtime;Software;Software architecture;Virtual machining},
}

@Article{4135373,
  author   = {H. D. Patel and S. K. Shukla and R. A. Bergamaschi},
  title    = {Heterogeneous Behavioral Hierarchy Extensions for SystemC},
  journal  = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year     = {2007},
  volume   = {26},
  number   = {4},
  pages    = {765-780},
  month    = {April},
  issn     = {0278-0070},
  abstract = {System level design methodology and language support for high-level modeling enhances productivity for designing complex embedded systems. For an effective methodology, efficiency of simulation and a sound refinement-based implementation path are also necessary. Although some of the recent system level design languages (SLDLs) such as SystemC, SystemVerilog, or SpecC have features for system level abstractions, several essential ingredients are missing from these. We consider: 1) explicit support for multiple models of computation (MoCs) or heterogeneity so that distributed reactive embedded systems with hardware and software components can be easily modeled; 2) the ability to build complex behaviors by hierarchically composing simpler behaviors and the ability to distinguish between structural and heterogeneous behavioral hierarchy; and 3) hierarchical composition of behaviors that belong to distinct MoCs, as essential for successful SLDLs. One important requirement for such an SLDL should be that the simulation semantics are compositional, and hence no flattening of hierarchically composed behaviors are needed for simulation. In this paper, we show how we designed SystemC extensions to facilitates for heterogeneous behavioral hierarchy, compositional simulation semantics, and a simulation kernel that shows up to 40% more efficient than standard SystemC simulation},
  db       = {IEEE},
  doi      = {10.1109/TCAD.2006.884859},
  keywords = {circuit simulation;embedded systems;high level synthesis;logic design;specification languages;SystemC;behavioral decomposition;compositional simulation semantics;distributed reactive embedded systems;heterogeneous behavioral hierarchy;hierarchical finite state machine;hierarchical synchronous data flow;high-level modeling;language support;multiple models of computation;simulation kernel;structural modeling;system level abstractions;system level design;Circuit simulation;Computational modeling;Design methodology;Embedded computing;Embedded software;Embedded system;Hardware design languages;Productivity;Software systems;System-level design;Behavioral decomposition;SystemC;behavioral modeling;embedded system design;heterogeneous behavioral hierarchy;hierarchical finite state machine (HFSM);hierarchical synchronous data flow (SDF);models of computation (MoCs);simulation efficiency;structural modeling;system level designs},
}

@Article{4100760,
  author   = {S. Pasricha and N. D. Dutt},
  title    = {A Framework for Cosynthesis of Memory and Communication Architectures for MPSoC},
  journal  = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year     = {2007},
  volume   = {26},
  number   = {3},
  pages    = {408-420},
  month    = {March},
  issn     = {0278-0070},
  abstract = {Memory and communication architectures have a significant impact on the cost, performance, and time-to-market of complex multiprocessor system-on-chip (MPSoC) designs. The memory architecture dictates most of the data traffic flow in a design, which in turn influences the design of the communication architecture. Thus, there is a need to cosynthesize the memory and communication architectures to avoid making suboptimal design decisions. This is in contrast to traditional platform-based design approaches where memory and communication architectures are synthesized separately. In this paper, the authors propose an automated application-specific cosynthesis framework for memory and communication architecture (COSMECA) in MPSoC designs. The primary objective is to design a communication architecture having the least number of buses, which satisfies performance and memory-area constraints, while the secondary objective is to reduce the memory-area cost. Results of applying COSMECA to several industrial strength MPSoC applications from the networking domain indicate a saving of as much as 40% in number of buses and 29% in memory area compared to the traditional approach},
  db       = {IEEE},
  doi      = {10.1109/TCAD.2006.884487},
  keywords = {high level synthesis;integrated circuit design;integrated memory circuits;memory architecture;multiprocessing systems;system buses;system-on-chip;COSMECA;automated application-specific cosynthesis framework;communication architectures;complex multiprocessor system-on-chip designs;data traffic flow;memory architectures;Bandwidth;Costs;Digital systems;High level synthesis;Libraries;Memory architecture;Multiprocessing systems;Network synthesis;System performance;Time to market;Communication system performance;digital systems;high-level synthesis;memory architecture},
}

@InProceedings{7363616,
  author    = {S. Park and H. Kim and S. Y. Kang and C. H. Koo and H. Joe},
  title     = {Lua-Based Virtual Machine Platform for Spacecraft On-Board Control Software},
  booktitle = {2015 IEEE 13th International Conference on Embedded and Ubiquitous Computing},
  year      = {2015},
  pages     = {44-51},
  month     = {Oct},
  abstract  = {Mission critical embedded software for autonomous operation requires high development cost due to its long development cycle. One of the potential solutions for reducing the cost is to reuse the software developed at previous missions. Virtual machine platform such as JVM is a good example to provide code portability across various missions. Flight software in aerospace field is adopting this concept to improve reusability and eventually to reduce development cost. In this paper, we propose a Lua-based virtualization environment for spacecraft flight software. Flight software for spacecraft control consists of a few tasks that are highly autonomous. Lua is chosen as the script language for programming the control tasks. Though Lua was designed with simplicity and portability, it only supports multithreading with collaborative coroutines. To support preemptive multitasking, we implement time slicing coroutines as spacecraft control processes. New coroutine scheduler is devised and time slicing functionality is added into the scheduler. Scheduler locking and message passing with external flight software are also implemented. Instead of modifying the Lua interpreter, we have exploited the debug support APIs for our implementation. For evaluation, we have implemented the flight software virtualization environment on the flight computer. Accuracy of the time slicing scheduler is also analyzed.},
  db        = {IEEE},
  doi       = {10.1109/EUC.2015.21},
  keywords  = {aerospace control;application program interfaces;authoring languages;control engineering computing;message passing;multi-threading;program debugging;scheduling;software portability;software reusability;space vehicles;spacecraft computers;virtual machines;virtualisation;JVM;Lua interpreter;Lua script language;Lua-based virtual machine platform;Lua-based virtualization environment;aerospace field;autonomous operation;code portability;collaborative coroutines;control task programming;coroutine scheduler;debug support API;development cost reduction;flight computer;flight software virtualization environment;highly autonomous task;message passing;mission critical embedded software;multithreading;preemptive multitasking;scheduler locking;software reuse;spacecraft control;spacecraft flight software;spacecraft on-board control software;time slicing coroutines;time slicing scheduler;Computers;Engines;Runtime;Software;Space vehicles;Virtual machining;Virtualization;Lua;OBCP;mission critical embedded software;reusability;spacecraft;virtual machine},
}

@InProceedings{7774446,
  author    = {J. O. Ooi and F. A. B. Hussin and N. Zakaria},
  title     = {Dual-Engine Cross-ISA DBTO Technique Utilising MultiThreaded Support for Multicore Processor System},
  booktitle = {2016 IEEE 10th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSOC)},
  year      = {2016},
  pages     = {257-264},
  month     = {Sept},
  abstract  = {The emergence of new era of Internet of Things or IoT have encouraged intensive if not extensive usage of modern mobile apps, thus multi-ISA equipped multicore processor gain great potential to be used for more efficient instruction binary processing in near future. In order to support this ISA diversity of computing platforms, mix modes of statically and dynamically Binary Translation and Optimization system, popularly consists of QEMU and LLVM or similar system, is the default technique used. However this complex system exhibits heavy slowdown (60x slowdown as compare to generic QEMU) [21] which impede its performance especially for short running application codes, typically used in IoT based apps applications. This research introduce a dual binary code translation engines to support apps based and kernel based application codes, through utilising multithreaded supported apart of original single thread supported binary translation processing in run-time. The dual engine consists of TCG generator from QEMU, and LLVM which include rich optimisations library. The evaluation through PARSEC-3.0 Benchmark shows our Hybrid DBTO system achieved performance improvement approaching 2.0x for apps based programs and 1.25x for kernel based programs, for x86 to X86-64 emulation. This technique possess great potential and serve as research based platform for future binary translation technique development, including adaptive method.},
  db        = {IEEE},
  doi       = {10.1109/MCSoC.2016.36},
  keywords  = {Internet of Things;binary codes;mobile computing;multi-threading;multiprocessing systems;Internet of Things;IoT;LLVM;PARSEC-3.0 benchmark;QEMU;TCG generator;X86-64 emulation;apps based application codes;dual binary code translation engines;dual-engine cross-ISA DBTO technique;dynamically binary translation and optimization system;hybrid DBTO system;instruction binary processing;kernel based application codes;mobile apps;multiISA equipped multicore processor;multicore processor system;multithreaded support;optimisations library;short running application codes;statically binary translation and optimization system;Emulation;Instruction sets;Kernel;Multicore processing;Optimization;Registers;Virtual machining;Binary Optimization;Binary Translation;Multi-ISA processor;Multicores;Multitheraded},
}

@InProceedings{5210958,
  author    = {F. Oldewurtel and J. Riihijarvi and K. Rerkrai and P. Mahonen},
  title     = {The RUNES Architecture for Reconfigurable Embedded and Sensor Networks},
  booktitle = {2009 Third International Conference on Sensor Technologies and Applications},
  year      = {2009},
  pages     = {109-116},
  month     = {June},
  abstract  = {We present the RUNES architecture for reconfigurable embedded networked systems and wireless sensor networks. It is the first systems-level architecture for such networks to explicitly deal with heterogeneity in hardware platforms, link-layer technologies and networking protocols while offering a simple programming language independent set of APIs together with a component-oriented middleware for the application developers to work on. The solutions developed are particularly appropriate for use in various emergency response scenarios, in which reconfigurability is often a key requirement. We also report on an example realisation of our architecture in a prototypical demonstration environment in a particular emergency scenario. The evaluation of architectural aspects such as reconfigurability shows that great programming flexibility can be achieved at low implementation overhead. The experience gained from RUNES modular architecture are very promising both in academic and industry projects context.},
  db        = {IEEE},
  doi       = {10.1109/SENSORCOMM.2009.26},
  keywords  = {embedded systems;intelligent sensors;wireless sensor networks;RUNES architecture;reconfigurable embedded networked systems;wireless sensor networks;Actuators;Computer architecture;Hardware;Middleware;Operating systems;Protocols;Sensor systems;Sensor systems and applications;System testing;Wireless sensor networks;architecture;programming model;prototype;sensor networks;software platform},
}

@InProceedings{7983156,
  author    = {U. A. Noman and B. Negash and A. M. Rahmani and P. Liljeberg and H. Tenhunen},
  title     = {From threads to events: Adapting a lightweight middleware for Contiki OS},
  booktitle = {2017 14th IEEE Annual Consumer Communications Networking Conference (CCNC)},
  year      = {2017},
  pages     = {486-491},
  month     = {Jan},
  abstract  = {Interoperability is one of the key requirements in the Internet of Things considering the diverse platforms, communication standards and specifications available today. Inherent resource constraints in the majority of IoT devices makes it very difficult to use existing solutions for interoperability, thus demanding new approaches. This paper presents the process of adapting a lightweight interoperability middleware for IoT, LISA, from RIOT to Contiki OS and evaluates memory and power overheads. The middleware follows a service oriented architecture and classifies devices according to available resources to assign different roles, such as Application, Service and Manager Nodes. These roles live in different tiers in a generic IoT architecture, where the Manager nodes are located in the intermediate Fog layer. To adapt to an event based kernel of Contiki, the middleware defines and handles a set of events that are used to communicate with the user application. A network of nodes is simulated to show the architecture promoted by the middleware and the results are presented.},
  db        = {IEEE},
  doi       = {10.1109/CCNC.2017.7983156},
  keywords  = {Internet of Things;middleware;open systems;operating systems (computers);service-oriented architecture;Contiki OS;IoT architecture;IoT devices;LISA;RIOT;event based kernel;intermediate fog layer;lightweight interoperability middleware;manager nodes;memory overheads;power overheads;resource constraints;Internet of Things;Interoperability;Manganese;Message systems;Middleware;Protocols;Semantics;Contiki;Internet of Things;Interoperability;LISA},
}

@InProceedings{6047305,
  author    = {H. Nguyen and D. Abramson and B. Bethwaite and M. N. Dinh and C. Enticott and S. Garic and A. B. M. Russel and S. Firth and I. Harper and M. Lackmann and M. Vail and S. Schek},
  title     = {Integrating Scientific Workflows and Large Tiled Display Walls: Bridging the Visualization Divide},
  booktitle = {2011 40th International Conference on Parallel Processing Workshops},
  year      = {2011},
  pages     = {308-316},
  month     = {Sept},
  abstract  = {Modern in-silico science (or e-Science) is a complex process, often involving multiple steps conducted across different computing environments. Scientific workflow tools help scientists automate, manage and execute these steps, providing a robust and repeatable research environment. Increasingly workflows generate data sets that require scientific visualization, using a range of display devices such as local workstations, immersive 3D caves and large display walls. Traditionally, this display step handled outside the workflow, and output files are manually copied to a suitable visualization engine for display. This inhibits the scientific discovery process disconnecting the workflow that generated the data from the display and interpretation processes. In this paper we present a solution that links scientific workflows with a variety of display devises, including large tiled display walls. We demonstrate the feasibility of the system by a prototype implementation that leverages the Kepler workflow engine and the SAGE display software. We illustrate the use of the system with a case study in workflow driven microscopy.},
  db        = {IEEE},
  doi       = {10.1109/ICPPW.2011.30},
  issn      = {0190-3918},
  keywords  = {data visualisation;display devices;file organisation;scientific information systems;workflow management software;Kepler workflow engine;SAGE display software;data sets;display device;e-science;file copying;in-silico science;interpretation processes;large tiled display walls;scientific discovery process;scientific visualization;scientific workflow tool;visualization divide;visualization engine;Data visualization;Educational institutions;Engines;Middleware;Rendering (computer graphics);Streaming media;E-Science;Kepler;Optiportal;Scientific Workflows;Tiled Display Wall;Visualization},
}

@InProceedings{6473629,
  author    = {Â. L. V. d. Negreiros and A. V. Brito},
  title     = {The Development of a Methodology with a Tool Support to the Distributed Simulation of Heterogeneous and Complexes Embedded Systems},
  booktitle = {2012 Brazilian Symposium on Computing System Engineering},
  year      = {2012},
  pages     = {37-42},
  month     = {Nov},
  abstract  = {Nowadays, embedded systems contains a big computational power and consequently a big complexity. It is very common to find different kinds of applications being executed in embedded systems. With this scenario, it is necessary some method and/or tool that allows the simulation of those systems in an efficient and practice way. The goal of this paper is to expose the integration between Ptolemy II and HLA in order to enable the elaboration of one methodology, with a tool support, to model and simulate large scale heterogeneous embedded systems.},
  db        = {IEEE},
  doi       = {10.1109/SBESC.2012.16},
  issn      = {2324-7886},
  keywords  = {computational complexity;digital simulation;embedded systems;HLA;Ptolemy II;big complexity;complexes embedded systems;computational power;distributed simulation;large scale heterogeneous embedded systems;tool support;Computational modeling;Computer architecture;Embedded systems;Hardware;Integrated circuit modeling;Mathematical model;Unified modeling language;Distributed Simulation;HLA;Heterogeneous Systems;High Level Architecture;Ptolemy},
}

@InProceedings{6913222,
  author    = {C. Motika and R. von Hanxleden and M. Heinold},
  title     = {Programming deterministic reactive systems with Synchronous Java},
  booktitle = {16th IEEE International Symposium on Object/component/service-oriented Real-time distributed Computing (ISORC 2013)},
  year      = {2013},
  pages     = {1-8},
  month     = {June},
  abstract  = {A key issue in the development of reliable embedded software is the proper handling of reactive control-flow, which typically involves concurrency. Java and its thread concept have only limited provisions for implementing deterministic concurrency. Thus, as has been observed in the past, it is challenging to develop concurrent Java programs without any deadlocks or race conditions. To alleviate this situation, the Synchronous Java (SJ) approach presented here adopts the key concepts that have been established in the world of synchronous programming for handling reactive control-flow. Thus SJ not only provides deterministic concurrency, but also different variants of deterministic preemption. Furthermore SJ allows concurrent threads to communicate with Esterel-style signals. As a case study for an embedded system usage, we also report on how the SJ concepts have been ported to the ARM-based Lego Mindstorms NXT system.},
  db        = {IEEE},
  doi       = {10.1109/ISORC.2013.6913222},
  issn      = {1555-0885},
  keywords  = {Java;concurrency control;embedded systems;object-oriented programming;ARM-based Lego Mindstorms NXT system;Esterel-style signals;Synchronous Java;concurrent Java programs;deterministic concurrency;deterministic preemption;deterministic reactive systems programming;embedded software development;embedded system usage;reactive control-flow handling;synchronous programming;Concurrent computing;Instruction sets;Java;Monitoring;Real-time systems;Switches;Synchronization},
}

@Article{6242797,
  author   = {C. J. Martin-Arguedas and D. Romero-Laorden and O. Martinez-Graullera and M. Perez-Lopez and L. Gomez-Ullate},
  title    = {An ultrasonic imaging system based on a new SAFT approach and a GPU beamformer},
  journal  = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  year     = {2012},
  volume   = {59},
  number   = {7},
  pages    = {1402-1412},
  month    = {July},
  issn     = {0885-3010},
  abstract = {The design of newer ultrasonic imaging systems attempts to obtain low-cost, small-sized devices with reduced power consumption that are capable of reaching high frame rates with high image quality. In this regard, synthetic aperture techniques have been very useful. They reduce hardware requirements and accelerate information capture. However, the beamforming process is still very slow, limiting the overall speed of the system. Recently, general-purpose computing on graphics processing unit techniques have been proposed as a way to accelerate image composition. They provide excellent computing power with which a very large volume of data can easily and quickly be processed. This paper describes a new system architecture that merges both principles. Thus, using a minimum-redundancy synthetic aperture technique to acquire the signals (2R-SAFT), and a graphics processing unit as a beamformer, we have developed a new scanner with full dynamic focusing, both on emission and reception, that attains real-time imaging with very few resources.},
  db       = {IEEE},
  doi      = {10.1109/TUFFC.2012.2341},
  keywords = {array signal processing;computerised instrumentation;graphics processing units;signal detection;ultrasonic imaging;2R-SAFT approach;GPU beamforming processing;dynamic focusing;general-purpose computing;graphics processing unit technique;hardware requirement;image composition acceleration;image quality;information capture acceleration;minimum-redundancy synthetic aperture technique;power consumption;real-time imaging;signal acquisition;ultrasonic imaging system;Apertures;Array signal processing;Focusing;Graphics processing unit;Hardware;Ultrasonic imaging;0},
}

@InProceedings{6176441,
  author    = {A. Marongiu and P. Burgio and L. Benini},
  title     = {Fast and lightweight support for nested parallelism on cluster-based embedded many-cores},
  booktitle = {2012 Design, Automation Test in Europe Conference Exhibition (DATE)},
  year      = {2012},
  pages     = {105-110},
  month     = {March},
  abstract  = {Several recent many-core accelerators have been architected as fabrics of tightly-coupled shared memory clusters. A hierarchical interconnection system is used - with a crossbar-like medium inside each cluster and a network-on-chip (NoC) at the global level - which make memory operations non-uniform (NUMA). Nested parallelism represents a powerful programming abstraction for these architectures, where a first level of parallelism can be used to distribute coarse-grained tasks to clusters, and additional levels of fine-grained parallelism can be distributed to processors within a cluster. This paper presents a lightweight and highly optimized support for nested parallelism on cluster-based embedded many-cores. We assess the costs to enable multi-level parallelization and demonstrate that our techniques allow to extract high degrees of parallelism.},
  db        = {IEEE},
  doi       = {10.1109/DATE.2012.6176441},
  issn      = {1530-1591},
  keywords  = {embedded systems;network-on-chip;shared memory systems;NUMA;NoC;cluster based embedded manycores;fine grained parallelism;hierarchical interconnection system;manycore accelerators;memory operations nonuniform;nested parallelism;network-on-chip;programming abstraction;shared memory clusters;Arrays;Instruction sets;Parallel processing;Programming;Synchronization},
}

@InProceedings{6843715,
  author    = {R. Mancuso and O. D. Dantsker and M. Caccamo and M. S. Selig},
  title     = {A low-power architecture for high frequency sensor acquisition in many-DOF UAVs},
  booktitle = {2014 ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)},
  year      = {2014},
  pages     = {103-114},
  month     = {April},
  abstract  = {Unmanned Aerial Vehicles (UAVs) are becoming increasingly popular thanks to an increase in the accessibility of components with high reliability and reduced cost, making them suitable for civil, military and research purposes. Vehicles classified as UAVs can have largely different properties in terms of physical design, size, power, capabilities, as well as associated production and operational cost. In this work, we target UAVs that feature a high number of degrees of freedom (DOF) and that are instrumented with a large number of sensors. For such platforms, we propose an architecture to perform data acquisition from on-board instrumentation at a frequency (100 Hz) that is twice as fast as existing products. Our architecture is capable of performing acquisition with strict timing constraints, thus, the produced data stream is suitable for performing real-time sensor fusion. Furthermore, our architecture can be implemented using embedded, commercial hardware, resulting in a low-cost solution. Finally, the resulting data acquisition unit features a low-power consumption, allowing it to operate for two to three hours with a miniature battery.},
  db        = {IEEE},
  doi       = {10.1109/ICCPS.2014.6843715},
  keywords  = {autonomous aerial vehicles;data acquisition;mobile robots;sensor fusion;data stream;degrees-of-freedom;frequency 100 Hz;high frequency sensor acquisition;low-power architecture;manyDOF UAV;miniature battery;sensor fusion;timing constraints;unmanned aerial vehicles;Data acquisition;Hardware;Magnetic separation;Magnetometers;Magnetosphere;Monitoring;Pulse width modulation},
}

@InProceedings{5272418,
  author    = {E. Lubbers and M. Platzner},
  title     = {Cooperative multithreading in dynamically reconfigurable systems},
  booktitle = {2009 International Conference on Field Programmable Logic and Applications},
  year      = {2009},
  pages     = {551-554},
  month     = {Aug},
  abstract  = {Preemptive multitasking, a popular technique for timesharing of computational resources in software-based systems, faces considerable difficulties when applied to partially reconfigurable hardware. In this paper, we propose a cooperative scheduling technique for reconfigurable hardware threads as a feasible compromise between computational efficiency and implementation complexity. We have implemented this mechanism for the multithreaded reconfigurable operating system ReconOS and evaluated its overheads and performance on a prototype.},
  db        = {IEEE},
  doi       = {10.1109/FPL.2009.5272418},
  issn      = {1946-147X},
  keywords  = {multi-threading;multiprogramming;operating systems (computers);reconfigurable architectures;scheduling;ReconOS;cooperative multithreading;cooperative scheduling technique;dynamically reconfigurable system;multithreaded reconfigurable operating system;preemptive multitasking;Delay;Field programmable gate arrays;Hardware;Multitasking;Multithreading;Operating systems;Processor scheduling;Prototypes;Reconfigurable logic;Yarn},
}

@Article{5710575,
  author   = {W. Liu and J. Xu and J. K. Muppala and W. Zhang and X. Wu and Y. Ye},
  title    = {Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models},
  journal  = {IEEE Embedded Systems Letters},
  year     = {2011},
  volume   = {3},
  number   = {1},
  pages    = {46-49},
  month    = {March},
  issn     = {1943-0663},
  abstract = {SystemC is a widely used electronic system-level (ESL) design language that can be used to model both hardware and software at different stages of system design. There has been a lot of research on behavior synthesis of hardware from SystemC, but relatively little work on synthesizing embedded software for SystemC designs. In this letter, we present an approach to automatic software synthesis from SystemC-based on coroutines instead of the traditional approaches based on real-time operating system (RTOS) threads. Performance evaluation results on some realistic applications show that our approach results in impressive reduction of runtime overheads compared to the thread-based approaches.},
  db       = {IEEE},
  doi      = {10.1109/LES.2011.2112634},
  keywords = {C++ language;embedded systems;operating systems (computers);SystemC models;coroutine-based synthesis;electronic system-level design language;embedded software synthesis;real-time operating system threads;Context;Instruction sets;Kernel;Prototypes;Switches;Synchronization;Performance;SystemC;software synthesis},
}

@Article{7927932,
  author   = {J. Lin},
  title    = {In Defense of MapReduce},
  journal  = {IEEE Internet Computing},
  year     = {2017},
  volume   = {21},
  number   = {3},
  pages    = {94-98},
  month    = {May},
  issn     = {1089-7801},
  abstract = {Don't throw the MapReduce baby out with the bath water! MapReduce represents a specific instance of a general class of data-parallel dataflow languages, in which computations are conceptualized as directed graphs, where vertices represent operations on records that flow along the directed edges. From this perspective, MAP and REDUCE are the two operators that MapReduce provides, which define particular configurations of the edges that flow into and out of vertices and specify the computations that occur at the vertices themselves.},
  db       = {IEEE},
  doi      = {10.1109/MIC.2017.53},
  keywords = {data flow computing;data handling;MapReduce;Big Data;Computational modeling;Internet;Internet and web services;Optimization;Performance evaluation;Internet/Web technologies;MapReduce;Spark;big data},
}

@Article{7513207,
  author   = {L. Li and D. Li and Z. Su and L. Jin and G. Huang},
  title    = {Performance analysis and framework optimization of open source cloud storage system},
  journal  = {China Communications},
  year     = {2016},
  volume   = {13},
  number   = {6},
  pages    = {110-122},
  month    = {June},
  issn     = {1673-5447},
  abstract = {More and more embedded devices, such as mobile phones, tablet PCs and laptops, are used in every field, so huge files need to be stored or backed up into cloud storage. Optimizing the performance of cloud storage is very important for Internet development. This paper presents the performance evaluation of the open source distributed storage system, a highly available, distributed, eventually consistent object/blob store from OpenStack cloud computing components. This paper mainly focuses on the mechanism of cloud storage as well as the optimization methods to process different sized files. This work provides two major contributions through comprehensive performance evaluations. First, it provides different configurations for OpenStack Swift system and an analysis of how every component affects the performance. Second, it presents the detailed optimization methods to improve the performance in processing different sized files. The experimental results show that our method improves the performance and the structure. We give the methods to optimize the object-based cloud storage system to deploy the readily available storage system.},
  db       = {IEEE},
  doi      = {10.1109/CC.2016.7513207},
  keywords = {cloud computing;public domain software;software performance evaluation;storage management;Internet development;OpenStack Swift system;OpenStack cloud computing components;comprehensive performance evaluations;embedded devices;framework optimization;object-based cloud storage system;open source cloud storage system;open source distributed storage system;optimization methods;performance analysis;Cloud computing;File systems;Hard disks;Optimization;Performance evaluation;Servers;Cloud Computing;Distribute System;Object Storage;OpenStack Swift;Storage Service Optimization},
}

@InProceedings{6651056,
  author    = {J. D. Leidel and J. Bolding and G. Rogers},
  title     = {Toward a Scalable Heterogeneous Runtime System for the Convey MX Architecture},
  booktitle = {2013 IEEE International Symposium on Parallel Distributed Processing, Workshops and Phd Forum},
  year      = {2013},
  pages     = {1597-1606},
  month     = {May},
  abstract  = {Given the recent advent of the multicore era [1], research efforts in the area of high performance, low latency runtime systems have increased significantly. This research has given birth to new techniques in low-overhead scheduling techniques, small-memory footprint parallel execution units and kernel-free contextual environments. This paper presents a framework and runtime system for a truly heterogeneous approach to low-latency, high performance runtime techniques on the Convey MX-100 platform and CHOMP micro-architecture [14]. This framework, deemed the Convey Lightweight Runtime [CLR], is designed to provide high performance, programming-model agnostic parallel library support to the massively parallel CHOMP infrastructure. This work explores the fundamental design requirements and implementation details behind constructing the CLR system as a truly heterogeneous low-level runtime system for a wide array of parallel programming model targets.},
  db        = {IEEE},
  doi       = {10.1109/IPDPSW.2013.18},
  keywords  = {multiprocessing systems;parallel programming;scheduling;CHOMP micro-architecture;CLR system;convey MX architecture;convey lightweight runtime;kernel-free contextual environments;low-overhead scheduling techniques;multicore era;parallel CHOMP infrastructure;parallel programming model;scalable heterogeneous runtime system;small-memory footprint parallel execution units;Computer architecture;Coprocessors;Hardware;Instruction sets;Programming;Registers;Runtime;architecture;heterogeneous;instruction set architecture;multithreading;runtime;scheduling;tasking;work stealing},
}

@InProceedings{6064506,
  author    = {E. A. Lee},
  title     = {Heterogeneous actor modeling},
  booktitle = {2011 Proceedings of the Ninth ACM International Conference on Embedded Software (EMSOFT)},
  year      = {2011},
  pages     = {3-12},
  month     = {Oct},
  abstract  = {Complex systems demand diversity in the modeling mechanisms. This “roadmap” paper prescribes an approach to modeling based on concurrent communicating components (called actors), where a diversity of orchestration strategies govern the execution and interaction of the components. The prescribed approach has been extensively explored in the Ptolemy Project, but as yet is not widely deployed in engineering practice. The approach achieves interaction between diverse models using an abstract semantics, which is a deliberately incomplete semantics that cannot by itself define a useful modeling framework. It instead focuses on the interactions between diverse models, reducing the nature of those interactions to a minimum that achieves a well-defined composition. The actor semantics is an abstract semantics that can handle many heterogeneous models that are built today, and some that are not common today. The actor abstract semantics and many concrete semantics are implemented in Ptolemy II, an open-source software framework.},
  db        = {IEEE},
  doi       = {10.1145/2038642.2038646},
  keywords  = {large-scale systems;multiprocessing programs;public domain software;Ptolemy project;abstract semantics;actor semantics;complex systems;concurrent communicating components;heterogeneous actor modeling;modeling mechanisms;open-source software;orchestration strategies;roadmap;Adaptation models;Computational modeling;Mathematical model;Object oriented modeling;Semantics;Syntactics;Unified modeling language;Ptolemy;heterogeneity;models of computation},
}

@Article{6472115,
  author   = {M. T. Lazarescu},
  title    = {Design of a WSN Platform for Long-Term Environmental Monitoring for IoT Applications},
  journal  = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  year     = {2013},
  volume   = {3},
  number   = {1},
  pages    = {45-54},
  month    = {March},
  issn     = {2156-3357},
  abstract = {The Internet of Things (IoT) provides a virtual view, via the Internet Protocol, to a huge variety of real life objects, ranging from a car, to a teacup, to a building, to trees in a forest. Its appeal is the ubiquitous generalized access to the status and location of any “thing” we may be interested in. Wireless sensor networks (WSN) are well suited for long-term environmental data acquisition for IoT representation. This paper presents the functional design and implementation of a complete WSN platform that can be used for a range of long-term environmental monitoring IoT applications. The application requirements for low cost, high number of sensors, fast deployment, long lifetime, low maintenance, and high quality of service are considered in the specification and design of the platform and of all its components. Low-effort platform reuse is also considered starting from the specifications and at all design levels for a wide array of related monitoring applications.},
  db       = {IEEE},
  doi      = {10.1109/JETCAS.2013.2243032},
  keywords = {IP networks;Internet of Things;data acquisition;environmental monitoring (geophysics);environmental science computing;quality of service;sensor placement;telecommunication network reliability;wireless sensor networks;Internet Protocol;Internet-of-Things;IoT application;IoT representation;WSN platform;functional design;long-term environmental data acquisition;long-term environmental monitoring;network lifetime;quality of service;sensor deployment;ubiquitous generalized access;wireless sensor networks;Internet of Things (IoT);IoT applications;WSN optimized design;WSN platform;WSN protocol;long term environmental monitoring applications;wireless sensor networks (WSN)},
}

@Article{6733370,
  author   = {W. B. Langdon and M. Harman},
  title    = {Optimizing Existing Software With Genetic Programming},
  journal  = {IEEE Transactions on Evolutionary Computation},
  year     = {2015},
  volume   = {19},
  number   = {1},
  pages    = {118-135},
  month    = {Feb},
  issn     = {1089-778X},
  abstract = {We show that the genetic improvement of programs (GIP) can scale by evolving increased performance in a widely-used and highly complex 50000 line system. Genetic improvement of software for multiple objective exploration (GISMOE) found code that is 70 times faster (on average) and yet is at least as good functionally. Indeed, it even gives a small semantic gain.},
  db       = {IEEE},
  doi      = {10.1109/TEVC.2013.2281544},
  keywords = {genetic algorithms;software engineering;GIP;GISMOE;genetic improvement of programs;genetic improvement of software for multiple objective exploration;genetic programming;software optimization;Complexity theory;DNA;Genetic programming;Grammar;Semantics;Software;${\rm Bowtie2}^{GP}$;Automatic software reengineering;genetic programming (GP);multiple objective exploration;search based software engineering (SBSE)},
}

@InProceedings{6575497,
  author    = {P. Kugler and P. Nordhus and B. Eskofier},
  title     = {Shimmer, Cooja and Contiki: A new toolset for the simulation of on-node signal processing algorithms},
  booktitle = {2013 IEEE International Conference on Body Sensor Networks},
  year      = {2013},
  pages     = {1-6},
  month     = {May},
  abstract  = {Wearable sensors are widely used for data collection in many applications. Ssensor nodes have also been applied for real-time applications, e.g. for ECG analysis or activity and fall detection. Processing of the sensor data is either done on an external device or on the node itself. While on-node processing reduces data rate and increases battery life, development and testing can be time-consuming. To allow faster implementation of such algorithms, we propose a simulation framework for the Shimmer platform using the Cooja simulator, MSPSim and the Contiki operating system. We provide the simulator and example applications compatible with the ShimmerConnect protocol, allowing streaming of raw and pre-processed sensor data to MATLAB, LabView and Android. Additionally, a simple activity and fall detection algorithm was implemented on the sensor node and evaluated using both the simulator and real hardware. In the future this will allow rapid development and testing of on-node pre-processing algorithms.},
  db        = {IEEE},
  doi       = {10.1109/BSN.2013.6575497},
  issn      = {2376-8886},
  keywords  = {Bluetooth;Hardware;Operating systems;Sensors;Testing;Wireless communication;Wireless sensor networks},
}

@InProceedings{4400379,
  author    = {A. Krystosik},
  title     = {Model Checking in Concurrent Programming Teaching},
  booktitle = {EUROCON 2007 - The International Conference on "Computer as a Tool"},
  year      = {2007},
  pages     = {2390-2396},
  month     = {Sept},
  abstract  = {The paper presents an application of model checking in teaching a concurrent programming. The success of this approach is based on features of DT-CSM automata and EMLAN modeling language. EMLAN is a C-like, high level language for modeling and model checking of embedded systems. The language is equipped with a lot of synchronization mechanisms (semaphores, mutexes, monitors). This allows easy modeling and verification of concurrent, cooperating tasks, which is very useful for educational purposes. As an example, a typical student exercise: a producer-consumer is given.},
  db        = {IEEE},
  doi       = {10.1109/EURCON.2007.4400379},
  keywords  = {computer science education;distributed programming;embedded systems;finite state machines;program verification;specification languages;synchronisation;DT-CSM automata;EMLAN C-like high level language;EMLAN modeling language;concurrent programming teaching;embedded system model checking;synchronization mechanisms;Automata;Computer science;Concurrent computing;Education;Embedded system;Error correction;Information technology;Logic;Paper technology;Programming profession;Modeling;Software verification and validation;Teaching},
}

@InProceedings{4394196,
  author    = {M. Koutsoubelias and S. Lalis},
  title     = {Design and Implementation of an Extensible Architecture for the Efficient Remote Access of Simple RFID-Readers},
  booktitle = {2007 IEEE 18th International Symposium on Personal, Indoor and Mobile Radio Communications},
  year      = {2007},
  pages     = {1-5},
  month     = {Sept},
  abstract  = {This paper describes a software architecture for the remote monitoring of warehouses equipped with simple RFID reader devices. Its main design objective is to enable a flexible and efficient integration of resource constrained readers that may be implemented as low-cost embedded systems, while allowing higher-level middleware components to access them in a transparent way. The proposed design has been implemented in a Linux-based environment and is currently being tested in conjunction with early prototypes of simple RFID readers that are accessed over low-bandwidth.},
  db        = {IEEE},
  doi       = {10.1109/PIMRC.2007.4394196},
  issn      = {2166-9570},
  keywords  = {embedded systems;radiofrequency identification;software architecture;telecontrol;warehouse automation;efficient remote access;extensible architecture;higher-level middleware components;low-cost embedded systems;simple RFID-readers;software architecture;Computer architecture;Hardware;Information filtering;Information filters;Middleware;Mobile communication;Protocols;Radiofrequency identification;Remote monitoring;Testing},
}

@InProceedings{4624024,
  author    = {D. G. Kim and S. M. Lee and D. R. Shin},
  title     = {Design of the Operating System Virtualization on L4 Microkernel},
  booktitle = {2008 Fourth International Conference on Networked Computing and Advanced Information Management},
  year      = {2008},
  volume    = {1},
  pages     = {307-310},
  month     = {Sept},
  abstract  = {The importance of the virtualization in embedded computing area is currently emerging. The virtualization can enhance system flexibility by enabling the concurrent execution of an application OS and a real-time OS (RTOS) on the same processor. L4 microkernel can be used as an efficient hypervisor which provides environment for operating systems virtualization. In order to run the application OSes on L4 microkernel, the application OSes should be adapted. The source code of Linux kernel can be readily accessed and modified. Hence, the Linux kernel is chosen as virtualized operating systems. In this paper, the architecture for virtualization of Linux kernel which is based on L4 microkernel is proposed.},
  db        = {IEEE},
  doi       = {10.1109/NCM.2008.165},
  keywords  = {Linux;operating system kernels;virtual machines;L4 microkernel;Linux kernel virtualization;concurrent execution;embedded computing;hypervisor;operating system virtualization;real-time operating system;system flexibility;Application software;Application virtualization;Embedded computing;Kernel;Linux;Operating systems;Platform virtualization;Real time systems;Virtual machine monitors;Yarn},
}

@InProceedings{4725258,
  author    = {M. Khezri and M. A. Sarram and F. Adibniya},
  title     = {Simplifying Concurrent Programming of Networked Embedded Systems},
  booktitle = {2008 IEEE International Symposium on Parallel and Distributed Processing with Applications},
  year      = {2008},
  pages     = {993-998},
  month     = {Dec},
  abstract  = {TinyOS is the current state of the art in operating systems for sensor network research. Event- based programming model of TinyOS presents concept of Task to allow postponing processing. For little processing and memory overhead and to avoid race conditions, tasks are non-preemptive. This causes executing long running task reduce system responsiveness. In general two approaches suggested for solving this problem: cooperative and multithreaded multitasking. In this paper we propose a new TinyOS task scheduler to integrate these approaches with new type of tasks. We argue that this approach improves the overall system responsiveness without concerning about data races or complicate programming for developers.},
  db        = {IEEE},
  doi       = {10.1109/ISPA.2008.138},
  issn      = {2158-9178},
  keywords  = {multi-threading;operating systems (computers);processor scheduling;telecommunication computing;wireless sensor networks;TinyOS;concurrent programming;cooperative multitasking;event-based programming model;memory overhead;multithreaded multitasking;networked embedded systems;operating systems;postponing processing;sensor network;task scheduler;Delay;Embedded system;Job shop scheduling;Multitasking;Operating systems;Programming profession;Sensor systems;Sensor systems and applications;Wireless sensor networks;Yarn;Cooperative;Embedded System;Multitasking;Scheduler;TinyOS;Yield},
}

@InProceedings{5456987,
  author    = {R. S. Khaligh and M. Radetzki},
  title     = {Modeling constructs and kernel for parallel simulation of accuracy adaptive TLMs},
  booktitle = {2010 Design, Automation Test in Europe Conference Exhibition (DATE 2010)},
  year      = {2010},
  pages     = {1183-1188},
  month     = {March},
  abstract  = {We present a set of modeling constructs accompanied by a high performance simulation kernel for accuracy adaptive transaction level models. In contrast to traditional, fixed accuracy TLMs, accuracy of adaptive TLMs can be changed during simulation to the level which is most suitable for a given use case and scenario. Ad-hoc development of adaptive models can result in complex models, and the implementation detail of adaptivity mechanisms can obscure the actual logic of a model. To simplify and enable systematic development of adaptive models, we have identified several mechanisms which are applicable to a wide variety of models. The proposed constructs relieve the modeler from low level implementation details of those mechanisms. We have developed an efficient, light-weight simulation kernel optimized for the proposed constructs, which enables parallel simulation of large models on widely available, low-cost multi-core simulation hosts. The modeling constructs and the kernel have been evaluated using industrial benchmark applications.},
  db        = {IEEE},
  doi       = {10.1109/DATE.2010.5456987},
  issn      = {1530-1591},
  keywords  = {operating system kernels;transaction processing;accuracy adaptive transaction level model;ad-hoc development;adaptive TLM;adaptive models systematic development;adaptivity mechanisms;high performance simulation kernel;light weight simulation kernel;low cost multicore simulation hosts;parallel simulation;Adaptive systems;Computational modeling;Concurrent computing;Context modeling;Discrete event simulation;Embedded system;Kernel;Logic;Natural languages;Performance loss},
}

@InProceedings{5775121,
  author    = {R. S. Khaligh and M. Radetzki},
  title     = {A dynamic load balancing method for parallel simulation of accuracy adaptive TLMs},
  booktitle = {2010 Forum on Specification Design Languages (FDL 2010)},
  year      = {2010},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {In this paper we present a load balancing method for parallel simulation of accuracy adaptive transaction level models. In contrast to traditional fixed accuracy TLMs, timing accuracy of adaptive TLMs changes during simulation. This makes the computation and synchronization characteristics of the models variable, and practically prohibits the use of static load balancing. To deal with this issue, we present a light-weight load balancing method which takes advantage of, and can be easily incorporated with the simulation time synchronization scheme used in parallel TLM simulation. We have developed a high performance parallel simulation kernel based on the proposed method, and our experiments using the developed kernel show the effectiveness of the proposed approach in a realistic scenario.},
  db        = {IEEE},
  doi       = {10.1049/ic.2010.0141},
  keywords  = {discrete event simulation;resource allocation;accuracy adaptive TLM;dynamic load balancing method;high performance parallel simulation kernel;parallel simulation;simulation time synchronization scheme},
}

@InProceedings{4292873,
  author    = {M. Karpinski and V. Cahill},
  title     = {High-Level Application Development is Realistic for Wireless Sensor Networks},
  booktitle = {2007 4th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks},
  year      = {2007},
  pages     = {610-619},
  month     = {June},
  abstract  = {Programming wireless sensor network (WSN) applications is known to be a difficult task. Part of the problem is that the resource limitations of typical WSN nodes force programmers to use relatively low-level techniques to deal with the logical concurrency and asynchronous event handling inherent in these applications. In addition, existing general-purpose, node-level programming tools only support the networked nature of WSN applications in a limited way and result in application code that is hardly portable across different software platforms. All of this makes programming a single device a tedious and error-prone task. To address these issues we propose a high-level programming model that allows programmers to express applications as hierarchical state machines and to handle events and application concurrency in a way similar to imperative synchronous languages. Our program execution model is based on static scheduling what allows for standalone application analysis and testing. For deployment, the resulting programs are translated into efficient sequential C code. A prototype compiler for TinyOS has been implemented and its evaluation in described in this paper.},
  db        = {IEEE},
  doi       = {10.1109/SAHCN.2007.4292873},
  issn      = {2155-5486},
  keywords  = {C++ language;wireless sensor networks;TinyOS;asynchronous event handling;hierarchical state machines;high-level application development;high-level programming model;logical concurrency;node-level programming tools;nodes force programmers;resource limitations;sequential C code;software platforms;synchronous languages;wireless sensor networks;Application software;Computer languages;Computer science;Concurrent computing;Hardware;Operating systems;Peer to peer computing;Programming profession;Prototypes;Wireless sensor networks},
}

@InProceedings{6926617,
  author    = {Ye Jihua and W. Wang},
  title     = {Research and design of solar photovoltaic power generation monitoring system based on TinyOS},
  booktitle = {2014 9th International Conference on Computer Science Education},
  year      = {2014},
  pages     = {1020-1023},
  month     = {Aug},
  abstract  = {In this paper, in order to solve management problems and field maintenance difficult issues existing in the process of PV power generation, we have designed a remote intelligent monitoring system based on TinyOS for monitoring and management. This system had implemented remote monitoring and reverse control by host computer, ARM gateways, wireless sensor networks and other components.},
  db        = {IEEE},
  doi       = {10.1109/ICCSE.2014.6926617},
  keywords  = {microcontrollers;photovoltaic power systems;power system measurement;wireless sensor networks;ARM gateways;PV power generation;TinyOS;field maintenance;host computer;management problems;remote intelligent monitoring system;remote monitoring;reverse control;wireless sensor networks;Computers;Data analysis;Logic gates;Monitoring;Routing;Wireless communication;Wireless sensor networks;IOT;TinyOS;node;remote monitoring},
}

@InProceedings{4686688,
  author    = {M. C. Jadud and C. L. Jacobsen and C. G. Ritson and J. Simpson},
  title     = {Safe parallelism for robotic control},
  booktitle = {2008 IEEE International Conference on Technologies for Practical Robot Applications},
  year      = {2008},
  pages     = {137-142},
  month     = {Nov},
  abstract  = {During the Spring 2008 semester at Olin College, we introduced the programming language occam-pi to undergraduates as part of their first course in robotics. Students were able to explore image processing and autonomous behavioral control in a parallel programming language on a small mobile robotics platform with just two weeks of tutorial instruction. Our experiences to date suggest that the language and tools we have developed allow the concise expression of complex robotic control systems, and enable the integration of events from the environment in a consistent and safe model for parallel control that is directly expressed in software.},
  db        = {IEEE},
  doi       = {10.1109/TEPRA.2008.4686688},
  issn      = {2325-0526},
  keywords  = {control engineering education;educational courses;image processing;mobile robots;parallel languages;parallel programming;robot programming;autonomous behavioral control;complex robotic control system;image processing;mobile robotics;occam-pi programming language;parallel programming language;robotic course;safe parallelism;tutorial instruction;Computer languages;Control system synthesis;Educational institutions;Educational robots;Image processing;Mobile robots;Parallel programming;Parallel robots;Robot control;Springs},
}

@InProceedings{6059016,
  author    = {R. Inam and J. Mäki-Turja and M. Sjödin and S. M. H. Ashjaei and S. Afshar},
  title     = {Support for hierarchical scheduling in FreeRTOS},
  booktitle = {ETFA2011},
  year      = {2011},
  pages     = {1-10},
  month     = {Sept},
  abstract  = {This paper presents the implementation of a Hierarchical Scheduling Framework (HSF) on an open source real-time operating system (FreeRTOS) to support the temporal isolation between a number of applications, on a single processor. The goal is to achieve predictable integration and reusability of independently developed components or applications. We present the initial results of the HSF implementation by running it on an AVR 32-bit board EVK1100. The paper addresses the fixed-priority preemptive scheduling at both global and local scheduling levels. It describes the detailed design of HSF with the emphasis of doing minimal changes to the underlying FreeRTOS kernel and keeping its API intact. Finally it provides (and compares) the results for the performance measures of idling and deferrable servers with respect to the overhead of the implementation.},
  db        = {IEEE},
  doi       = {10.1109/ETFA.2011.6059016},
  issn      = {1946-0740},
  keywords  = {application program interfaces;object-oriented programming;operating system kernels;public domain software;real-time systems;scheduling;software reusability;API;AVR EVK1100;FreeRTOS kernel;application reusability;fixed-priority preemptive scheduling;global scheduling levels;hierarchical scheduling framework;independently developed component reusability;local scheduling levels;open source real-time operating system;predictable integration;single processor;temporal isolation;Job shop scheduling;Kernel;Processor scheduling;Real time systems;Schedules;Servers;fixed-priority scheduling;hierarchical scheduling framework;real-time systems},
}

@InProceedings{4570792,
  author    = {P. K. Huang and M. Hashemi and S. Ghiasi},
  title     = {System-Level Performance Estimation for Application-Specific MPSoC Interconnect Synthesis},
  booktitle = {2008 Symposium on Application Specific Processors},
  year      = {2008},
  pages     = {95-100},
  month     = {June},
  abstract  = {We present a framework for development of streaming applications as concurrent software modules running on multi-processors system-on-chips (MPSoC). We propose an iterative design space exploration mechanism to customize MPSoC architecture for given applications. Central to the exploration engine is our system-level performance estimation methodology, that both quickly and accurately determine quality of candidate architectures. We implemented a number of streaming applications on candidate architectures that were emulated on an FPGA. Hardware measurements show that our system-level performance estimation method incurs only 15% error in predicting application throughput. More importantly, it always correctly guides design space exploration by achieving 100% fidelity in quality-ranking candidate architectures. Compared to behavioral simulation of compiled code, our system-level estimator runs more than 12 times faster, and requires 7 times less memory.},
  db        = {IEEE},
  doi       = {10.1109/SASP.2008.4570792},
  keywords  = {field programmable gate arrays;multiprocessing systems;parallel architectures;system-on-chip;FPGA;MPSoC interconnect synthesis;design space exploration;system-level performance estimation;Application software;Computational modeling;Computer architecture;Field programmable gate arrays;Hardware;Network synthesis;Software performance;Space exploration;System-on-a-chip;Throughput},
}

@Article{6403642,
  author   = {M. Hosseinabady and J. l. Nunez-Yanez},
  title    = {Fast and low overhead architectural transaction level modelling for large-scale network-on-chip simulation},
  journal  = {IET Computers Digital Techniques},
  year     = {2012},
  volume   = {6},
  number   = {6},
  pages    = {384-395},
  month    = {November},
  issn     = {1751-8601},
  abstract = {Early system modelling is an essential tool to accelerate software development, architectural analysis and hardware verification in complex many-core system-on-chips (SoCs). Transaction level modelling (TLM) offers a higher level of abstraction than register transfer level (RTL) and can be used for early system modelling. Maintaining simulation speed with the right accuracy is a major challenge and this paper proposes SystemC-based architectural modelling techniques that extend TLM to deliver faster simulation models for many-core system. The proposed approach considers a micro-scheduler for large modules (in the sense of SystemC modules) to locally manage all events in the module. Exploiting this micro-scheduler along with function object and coroutine concepts, the authors propose a lightweight thread process that significantly reduces the context switching overhead among the different processes. Additionally the micro-scheduler allows some processes to be run ahead of simulation time. The proposed techniques are applied to the model of a very large networks-on-chip (NoC) formed by thousands of cores stressing the simulation capabilities of the host computer and operating system. The experimental results demonstrate that the model can run successfully and exhibits up to 93% improvement in simulation speed compared to traditional SystemC-based modelling.},
  db       = {IEEE},
  doi      = {10.1049/iet-cdt.2012.0001},
  keywords = {electronic engineering computing;integrated circuit modelling;network-on-chip;operating systems (computers);software engineering;system-on-chip;transaction processing;RTL;SystemC-based architectural modelling techniques;architectural analysis;coroutine concepts;function object concepts;hardware verification;host computer;large-scale NoC;large-scale network-on-chip simulation;low overhead architectural transaction level modelling;many-core SoC;many-core system-on-chips;microscheduler;operating system;register transfer level;software development},
}

@InProceedings{7173939,
  author    = {M. Hölzl and T. Gabor},
  title     = {Continuous Collaboration: A Case Study on the Development of an Adaptive Cyber-physical System},
  booktitle = {2015 IEEE/ACM 1st International Workshop on Software Engineering for Smart Cyber-Physical Systems},
  year      = {2015},
  pages     = {19-25},
  month     = {May},
  abstract  = {The need to interact with complex environments that are often not well understood at design time makes the development of smart cyber-physical systems (sCPS) a challenging endeavor. We propose a set of practices and tools that support the design and implementation of sCPS using continuous collaboration -- a development lifecycle and architecture to continuously incorporate data gained from the operation of the sCPS into the system. Continuous collaboration attempts to harmonize three interlocking feedback cycles: refinement of the system design by the developers, autonomous evolution of agents in the sCPS, and feedback from the evolving system to the developers. To support the process we introduce tools and techniques that we have found helpful to realize continuous collaboration: The HADES/Hexameter platform, extended behavior trees and the teacher/student learning pattern.},
  db        = {IEEE},
  doi       = {10.1109/SEsCPS.2015.12},
  keywords  = {software architecture;HADES-Hexameter platform;adaptive cyber-physical system;complex environments;continuous collaboration;extended behavior trees;interlocking feedback cycles;sCPS;software architecture;software development lifecycle approach;system design;teacher-student learning pattern;Collaboration;Cyber-physical systems;Hardware;Navigation;Rescue robots;Software;Cyber-Physical Systems;Embodied Evolution;Evolutionary Algorithms;Reinforcement Learning;Software Engineering},
}

@Article{7374832,
  author   = {J. Herbert and S. Wilson and A. D. Rakic and T. Taimre},
  title    = {FPGA implementation of a high-speed, real-time, windowed standard deviation filter},
  journal  = {Electronics Letters},
  year     = {2016},
  volume   = {52},
  number   = {1},
  pages    = {22-23},
  issn     = {0013-5194},
  abstract = {Characterisation of the standard deviation of a time-series signal has uncommon, yet widespread applications. The usual requirement for a representation of signal standard deviation in real-time implies a high computation speed. A method based on a field programmable gate array (FPGA) implementation is presented. The technique is benchmarked against conventional computational approaches and shows a single windowed standard deviation update calculation of a 16 bit sample can be achieved in 11 ns on a modern CPU. The FPGA implementation is found to be superior to all other approaches examined with an operation time of below 10 ns, and thus provides a useful tool for the real-time measurement of the standard deviation of signals above 100 MHz.},
  db       = {IEEE},
  doi      = {10.1049/el.2015.2407},
  keywords = {field programmable gate arrays;filters;time series;FPGA;field programmable gate array;modern CPU;time-series signal;windowed standard deviation filter;word length 16 bit},
}

@InProceedings{6513574,
  author    = {R. von Hanxleden and M. Mendler and J. Aguado and B. Duderstadt and I. Fuhrmann and C. Motika and S. Mercer and O. O'Brien},
  title     = {Sequentially constructive concurrency A conservative extension of the synchronous model of computation},
  booktitle = {2013 Design, Automation Test in Europe Conference Exhibition (DATE)},
  year      = {2013},
  pages     = {581-586},
  month     = {March},
  abstract  = {Synchronous languages ensure deterministic concurrency, but at the price of heavy restrictions on what programs are considered valid, or constructive. Meanwhile, sequential languages such as C and Java offer an intuitive, familiar programming paradigm but provide no guarantees with regard to deterministic concurrency. The sequentially constructive model of computation (SC MoC) presented here harnesses the synchronous execution model to achieve deterministic concurrency while addressing concerns that synchronous languages are unnecessarily restrictive and difficult to adopt. In essence, the SC MoC extends the classical synchronous MoC by allowing variables to be read and written in any order as long as sequentiality expressed in the program provides sufficient scheduling information to rule out race conditions. The SC MoC is a conservative extension in that programs considered constructive in the common synchronous MoC are also SC and retain the same semantics. In this paper, we identify classes of variable accesses, define sequential constructiveness based on the concept of SC-admissible scheduling, and present a priority-based scheduling algorithm for analyzing and compiling SC programs.},
  db        = {IEEE},
  doi       = {10.7873/DATE.2013.128},
  issn      = {1530-1591},
  keywords  = {Computational modeling;Concurrent computing;Electronic mail;Instruction sets;Java;Programming;Schedules},
}

@InProceedings{6069480,
  author    = {B. Haetzer and M. Radetzki},
  title     = {A case study on message-based discrete event simulation for Transaction Level Modeling},
  booktitle = {FDL 2011 Proceedings},
  year      = {2011},
  pages     = {1-8},
  month     = {Sept},
  abstract  = {Transaction Level Modeling is a system-level design methodology for early design space exploration. The increasing complexity of systems makes it necessary to improve simulation performance. Using parallel discrete event simulation approaches seems promising to speedup the simulation runs of complex transaction level models. One of such approaches is the message-based PDES approach which is applied to TLM in this paper. Two different TLM case studies are used to evaluate and compare the execution times of sequential and message-based simulation. We show that with message-based simulation a speedup over sequential simulation can be achieved even if using only one processor core. This result lies the foundation for further speedup if running on multiple cores as no more significant synchronization overhead is expected.},
  db        = {IEEE},
  issn      = {1636-9874},
  keywords  = {computational complexity;discrete event simulation;electronic engineering computing;system-on-chip;design space exploration;message based PDES;message based discrete event simulation;multiple cores;parallel discrete event simulation;processor core;sequential simulation;system level design methodology;systems complexity;transaction level modeling;Computational modeling;Context;Kernel;Switches;Time domain analysis;Time varying systems},
}

@InProceedings{5751491,
  author    = {M. Geilen and S. Stuijk},
  title     = {Worst-case performance analysis of Synchronous Dataflow scenarios},
  booktitle = {2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)},
  year      = {2010},
  pages     = {125-134},
  month     = {Oct},
  abstract  = {Synchronous Dataflow (SDF) is a powerful analysis tool for regular, cyclic, parallel task graphs. The behaviour of SDF graphs however is static and therefore not always able to accurately capture the behaviour of modern, dynamic dataflow applications, such as embedded multimedia codecs. An approach to tackle this limitation is by means of scenarios. In this paper we introduce a technique and a tool to automatically analyse a scenario-aware dataflow model for its worst-case performance. A system is specified as a collection of SDF graphs representing individual scenarios of behaviour and a finite state machine that specifies the possible orders of scenario occurrences. This combination accurately captures more dynamic applications and this way provides tighter results than an existing analysis based on a conservative static dataflow model, which is too pessimistic, while looking only at the `worst-case' individual scenario, without considering scenario transitions, can be too optimistic. We introduce a formal semantics of the model, in terms of (max; +) linear system-theory and in particular (max; +) automata. Leveraging existing results and algorithms from this domain, we give throughput analysis and state space generation algorithms for worst-case performance analysis. The method is implemented in a tool and the effectiveness of the approach is experimentally evaluated.},
  db        = {IEEE},
  doi       = {10.1145/1878961.1878985},
  keywords  = {computational complexity;data analysis;data flow analysis;data flow graphs;finite state machines;SDF graph;embedded multimedia codecs;finite state machine;formal semantics;linear system theory;parallel task graph;scenario-aware dataflow model;state space generation algorithm;synchronous dataflow scenario;worst case performance analysis;(max; +) algebra;Synchronous Data Flow;worst-case performance analysis},
}

@InProceedings{6962305,
  author    = {E. Gebrewahid and M. Yang and G. Cedersjö and Z. U. Abdin and V. Gaspes and J. W. Janneck and B. Svensson},
  title     = {Realizing Efficient Execution of Dataflow Actors on Manycores},
  booktitle = {2014 12th IEEE International Conference on Embedded and Ubiquitous Computing},
  year      = {2014},
  pages     = {321-328},
  month     = {Aug},
  abstract  = {Embedded DSP computing is currently shifting towards manycore architectures in order to cope with the ever growing computational demands. Actor based dataflow languages are being considered as a programming model. In this paper we present a code generator for CAL, one such dataflow language. We propose to use a compilation tool with two intermediate representations. We start from a machine model of the actors that provides an ordering for testing of conditions and firing of actions. We then generate an Action Execution Intermediate Representation that is closer to a sequential imperative language like C and Java. We describe our two intermediate representations and show the feasibility and portability of our approach by compiling a CAL implementation of the Two-Dimensional Inverse Discrete Cosine Transform on a general purpose processor, on the Epiphany manycore architecture and on the Ambric massively parallel processor array.},
  db        = {IEEE},
  doi       = {10.1109/EUC.2014.55},
  keywords  = {data flow computing;digital signal processing chips;discrete cosine transforms;embedded systems;inverse transforms;multiprocessing systems;parallel processing;program compilers;program processors;Ambric massively parallel processor array;C language;CAL;CAL implementation;Epiphany manycore architecture;Java language;action execution intermediate representation;code generator;computational demands;dataflow actor execution;dataflow languages;embedded DSP computing;general purpose processor;machine model;manycore architectures;programming model;sequential imperative language;two-dimensional inverse discrete cosine transform;Arrays;Availability;Computational modeling;Optimization;Ports (Computers);Programming;Switches;CAL;code generation;compilation framework;dataflow languages;manycore},
}

@InProceedings{7336309,
  author    = {W. B. Gardner and A. Gumtie and J. D. Carter},
  title     = {Supporting Selective Formalism in CSP++ with Process-Specific Storage},
  booktitle = {2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
  year      = {2015},
  pages     = {1057-1065},
  month     = {Aug},
  abstract  = {Communicating Sequential Processes (CSP) is a formal language whose primary purpose is to model and verify concurrent systems. The CSP++ toolset was created to realize the concept of selective formalism by making machine-readable CSPm specifications both executable (through automatic C++ code generation) and extensible (by allowing integration of C++ user-coded functions, UCFs). However, UCFs were limited by their inability to share data with each other, thus their application was constrained to solving simple problems in isolation. We extend CSP++ by providing UCFs in the same CSP process with safe access to a shared storage area, similar in concept and API to Pthreads' thread-local storage, enabling cooperation between them and granting them the ability to undertake more complex tasks without breaking the formalism of the underlying specification. Process-specific storage is demonstrated with a line-following robot case study, applying CSP++ in a soft real-time system. Also described is the Eclipse plug-in that supports the CSPm design flow.},
  db        = {IEEE},
  doi       = {10.1109/HPCC-CSS-ICESS.2015.265},
  keywords  = {C++ language;application program interfaces;communicating sequential processes;concurrency (computers);control engineering computing;formal languages;formal specification;formal verification;program compilers;real-time systems;robots;storage management;API;C++ user-coded function;CSP++;CSPm design flow;Eclipse plug-in;Pthread thread-local storage;UCF;automatic C++ code generation;concurrent system modelling;concurrent system verification;formal language;line-following robot case study;machine-readable CSPm specification;process-specific storage;selective formalism;soft real-time system;Libraries;Real-time systems;Robot sensing systems;Switches;System recovery;Writing;C++;CSPm;Eclipse;Timed CSP;code generation;embedded systems;formal methods;model-based design;selective formalism;soft real-time;software synthesis},
}

@InProceedings{5665620,
  author    = {R. Fritzsche and C. Siemers},
  title     = {Scheduling of time enhanced c (TEC)},
  booktitle = {2010 World Automation Congress},
  year      = {2010},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {Real-time systems mainly consist of time or event-triggered tasks that must satisfy deadline-constraints and other limitations to the execution time. Scheduling of them is a common problem especially if no operating system can be used because of limited resources like code-size and CPU power. Previous approaches deal with multi-frame models to split tasks into smaller subtask that may be arranged at compile-time in a static way to cope with given deadlines. Handling of non-periodic events and context-switching problems demand a more dynamic scheduling. This paper presents an approach of using manually given information for timing constraints in order to rearrange the code to satisfy the deadlines automatically. The presented design is still able to handle events and to force the given functions to cooperate. Supporting hardware for producing timing-events may further help the system to organize the program-flow.},
  db        = {IEEE},
  issn      = {2154-4824},
  keywords  = {dynamic scheduling;multiprogramming;real-time systems;software engineering;CPU power;context switching problem;deadline constraint;dynamic scheduling;event triggered task;multiframe model;nonperiodic event;program flow;real time system;split task;time enhanced C;timing constraint;Context;Switches;application-internal scheduler;forced cooperative design;multi-frame tasks;semi-dynamic scheduling;time-enhanced language},
}

@InProceedings{7371363,
  author    = {G. Ferro and R. Silva and L. Lopes},
  title     = {Towards Out-of-the-Box Programming of Wireless Sensor-Actuator Networks},
  booktitle = {2015 IEEE 18th International Conference on Computational Science and Engineering},
  year      = {2015},
  pages     = {110-119},
  month     = {Oct},
  abstract  = {We address the problem of providing users, namely non specialists, with out-of-the-box, programmable, Wireless Sensor-Actuator Networks (WSN). The idea is that users get a package containing a gateway and an undetermined number of nodes, pre-configured to work as a self-organized wireless mesh. Each node comes with two pre-installed components: a small operating system and a virtual machine. The user can then use a simple, domain-specific, programming language to implement periodic tasks that are compiled into byte-code, and can be sent to the nodes for execution. At the nodes, the operating system manages a task table and schedules non-preemptive tasks for execution using the virtual machine. No subtle hardware or software configuration is required from the user as these details are abstracted away by the virtual machine. We developed a full specification for a data-layer that follows the aforementioned guidelines and implemented a complete prototype, integrated in our own Publish/Subscribe middleware called SONAR. In this paper we report the first results of using the prototype as compared to using the low level programming tools provided with the hardware. We measure a small increase in both resource consumption and processing overhead suggesting that this data-layer can be used effectively in WSN, even in cases where nodes have very limited hardware resources.},
  db        = {IEEE},
  doi       = {10.1109/CSE.2015.20},
  keywords  = {actuators;programming languages;virtual machines;wireless sensor networks;Publish/Subscribe middleware;SONAR;WSN;byte-code;gateway;level programming tools;operating system;out-of-the-box programming;programming language;virtual machine;wireless sensor-actuator networks;Logic gates;Operating systems;Programming;Sensors;Sonar;Virtual machining;Wireless sensor networks;Programming Language;Virtual Machine;Wireless Sensor Network},
}

@InProceedings{6269627,
  author    = {J. F. Ferreira and G. He and S. Qin},
  title     = {Automated Verification of the FreeRTOS Scheduler in HIP/SLEEK},
  booktitle = {2012 Sixth International Symposium on Theoretical Aspects of Software Engineering},
  year      = {2012},
  pages     = {51-58},
  month     = {July},
  abstract  = {Automated verification of operating system kernels is a challenging problem, partly due to the use of shared mutable data structures. In this paper, we show how we can automatically verify memory safety and functional correctness of the task scheduler component of the FreeRTOS kernel using the verification system HIP/SLEEK. We show how some of HIP/SLEEK features like user-defined predicates and lemmas make the specifications highly expressive and the verification process viable. To the best of our knowledge, this is the first code-level verification of memory safety and functional correctness properties of the FreeRTOS scheduler. The outcome of our experiment confirms that HIP/SLEEK can indeed be used to verify code that is used in production. Moreover, since the properties that we verify are quite general, we envisage that the same approach can be adopted to verify the scheduler of other operating systems.},
  db        = {IEEE},
  doi       = {10.1109/TASE.2012.45},
  keywords  = {data structures;formal verification;operating system kernels;scheduling;shared memory systems;FreeRTOS kernel;FreeRTOS scheduler;HIP-SLEEK verification system;automated operating system kernel verification;first code-level verification;functional correctness verification;memory safety verification;real-time operating systems;shared mutable data structures;task scheduler component;user-defined lemmas;user-defined predicates;Context;Data structures;Hip;Kernel;Safety;Shape;FreeRTOS;HIP/SLEEK;automated verification;embedded systems;operating systems;separation logic;task scheduler},
}

@InProceedings{8016226,
  author    = {A. Elsts and G. Oikonomou and X. Fafoutis and R. Piechocki},
  title     = {Internet of Things for smart homes: Lessons learned from the SPHERE case study},
  booktitle = {2017 Global Internet of Things Summit (GIoTS)},
  year      = {2017},
  pages     = {1-6},
  month     = {June},
  abstract  = {Building large-scale low-power Internet of Things (IoT) systems remains a challenge, as these systems have to meet the requirements of reliability, robustness, and energy-efficiency while running on resource-restricted microcontrollers without memory protection. In this paper we present the case study of IoT in SPHERE (Sensor Platform for HEalthcare in a Residential Environment), a project with the objective to develop a multipurpose, multi-modal sensor platform for monitoring people's health inside their homes. Atypically for academic projects, in 2017 the SPHERE software is going to be deployed in a 100-home study in volunteer homes, therefore it has to satisfy many real-world requirements. We discuss the requirements for IoT networking in this project, the IoT architecture (built on top of Contiki OS), software engineering challenges and lessons learned, as well as some of the general aspects that still make embedded low-power IoT software development difficult.},
  db        = {IEEE},
  doi       = {10.1109/GIOTS.2017.8016226},
  keywords  = {Internet of Things;assisted living;power aware computing;sensors;software engineering;IoT;SPHERE case study;embedded low-power IoT software development;energy-efficiency;large-scale low-power Internet of Things systems;multipurpose multimodal sensor platform;real-world requirements;resource-restricted microcontrollers;sensor platform for healthcare in a residential environment;smart homes;software engineering challenges;volunteer homes;Hardware;IEEE 802.15 Standard;Logic gates;Protocols;Reliability;Servers;Software},
}

@Article{6122018,
  author   = {J. Diaz and C. Muñoz-Caro and A. Niño},
  title    = {A Survey of Parallel Programming Models and Tools in the Multi and Many-Core Era},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  year     = {2012},
  volume   = {23},
  number   = {8},
  pages    = {1369-1386},
  month    = {Aug},
  issn     = {1045-9219},
  abstract = {In this work, we present a survey of the different parallel programming models and tools available today with special consideration to their suitability for high-performance computing. Thus, we review the shared and distributed memory approaches, as well as the current heterogeneous parallel programming model. In addition, we analyze how the partitioned global address space (PGAS) and hybrid parallel programming models are used to combine the advantages of shared and distributed memory systems. The work is completed by considering languages with specific parallel support and the distributed programming paradigm. In all cases, we present characteristics, strengths, and weaknesses. The study shows that the availability of multi-core CPUs has given new impulse to the shared memory parallel programming approach. In addition, we find that hybrid parallel programming is the current way of harnessing the capabilities of computer clusters with multi-core nodes. On the other hand, heterogeneous programming is found to be an increasingly popular paradigm, as a consequence of the availability of multi-core CPUs+GPUs systems. The use of open industry standards like OpenMP, MPI, or OpenCL, as opposed to proprietary solutions, seems to be the way to uniformize and extend the use of parallel programming models.},
  db       = {IEEE},
  doi      = {10.1109/TPDS.2011.308},
  keywords = {distributed memory systems;parallel programming;shared memory systems;MPI;OpenCL;OpenMP;computer clusters;distributed memory approach;distributed memory systems;heterogeneous parallel programming model;high-performance computing;hybrid parallel programming model;multicore CPUs+GPUs systems;multicore nodes;open industry standards;partitioned global address space;shared memory approach;shared memory parallel programming;Computational modeling;Graphics processing unit;Instruction sets;Message systems;Multicore processing;Parallel programming;Parallelism and concurrency;distributed programming;heterogeneous (hybrid) systems.},
}

@InProceedings{6007780,
  author    = {S. P. Crago and D. I. Kang and M. Kang and R. Kost and K. Singh and J. Suh and J. P. Walters},
  title     = {Programming Models and Development Software for a Space-Based Many-Core Processor},
  booktitle = {2011 IEEE Fourth International Conference on Space Mission Challenges for Information Technology},
  year      = {2011},
  pages     = {95-102},
  month     = {Aug},
  abstract  = {The Maestro processor is a 49-core many-core processor for space based on the TILE64 architecture and implemented in rad-hard-by-design technology by Boeing. In this paper we discuss the programming models for Maestro, the implications of the programming model on fault tolerance and flight software, and the software development tools that have been developed for Maestro. The software described here is experimental development software that allows application and algorithm evaluation on the architecture, but we believe this software can be used as the basis for flight software. The software includes libraries, performance analysis and optimization tools, and compilers. While this work was done on the Maestro chip, the principles discussed can be applied to any multi-core or many-core processor.},
  db        = {IEEE},
  doi       = {10.1109/SMC-IT.2011.29},
  keywords  = {aerospace computing;computer architecture;microprocessor chips;multiprocessing systems;program compilers;program processors;software architecture;software fault tolerance;software libraries;software performance evaluation;49-core manycore processor;Maestro chip;Maestro processor;TILE64 architecture;fault tolerance;flight software;multicore processor;optimization tool;programming model;rad-hard-by-design technology;software compiler;software development tool;software library;space-based manycore processor;Computer architecture;Libraries;Linux;Message passing;Programming;Real time systems;Software;Multi-core programming;parallel software;space-based processing},
}

@InProceedings{4228186,
  author    = {M. Cohen and T. Ponte and S. Rossetto and N. Rodriguez},
  title     = {Using Coroutines for RPC in Sensor Networks},
  booktitle = {2007 IEEE International Parallel and Distributed Processing Symposium},
  year      = {2007},
  pages     = {1-8},
  month     = {March},
  abstract  = {This paper proposes a concurrency model which integrates the asynchronous and event-driven nature of wireless sensor networks with higher-level abstractions that provide a more familiar programming style for the developer. As a basis for this proposal, we designed and implemented a cooperative multitasking scheduler, based on coroutines, for the TinyOS operating system. We then used this scheduler to implement RPC-like interfaces that capture different communication patterns common in wireless sensor networks. This allows the programmer to work, when appropriate, with a synchronous style, while maintaining an asynchronous model at the message exchange level.},
  db        = {IEEE},
  doi       = {10.1109/IPDPS.2007.370458},
  issn      = {1530-2075},
  keywords  = {concurrency control;network operating systems;remote procedure calls;scheduling;wireless sensor networks;RPC coroutine;RPC-like interface;TinyOS operating system;concurrency model;cooperative multitasking scheduler;event-driven wireless sensor network;Computer languages;Concurrent computing;Embedded system;Multitasking;Operating systems;Programming profession;Proposals;Sensor phenomena and characterization;Testing;Wireless sensor networks},
}

@InProceedings{5314042,
  author    = {D. L. Clark},
  title     = {Powering intelligent instruments with Lua scripting},
  booktitle = {2009 IEEE AUTOTESTCON},
  year      = {2009},
  pages     = {101-106},
  month     = {Sept},
  abstract  = {As the power of the integrated processors that control today's instruments continues to climb, instrument vendors will increasingly add features that allow users to utilize the added intelligence by embedding custom applications directly onboard the instrument. For the test, measurement and automation industries, this paradigm is a complement to, among other things, the advent of synthetic instruments that can ldquobe anything you want,rdquo the frequent use of mezzanine type hardware and the rise of the LXI specification in which instrument to instrument messaging allows one instrument to control and communicate with another without the necessity of a host PC. There are various approaches the instrument vendor can take to permit users to develop embedded applications to be run on the instrument processor. Arguably the most advantageous approach, to both the vendor and customer, is to embed a high level scripting language allowing the user to easily develop scripts to perform instrument based operations. The Lua scripting language is a compact, full featured scripting language that is easily portable and seamlessly integrates into embedded designs. Written in pure ISO ANSI-C, the Lua interpreter and Lua libraries have been successfully ported to a large number of platforms, big and small, and with and without advanced operating systems such as Windows and Linux. Lua contains an API for interfacing directly to and from the instrument's embedded firmware and includes a full suite of libraries. Further, Lua is extendable. Thus, in addition to embedding the language interpreter and libraries, the vendor can implement custom libraries and various other custom utilities to increase the flexibility of the system and enhance the capabilities of the user developed scripts. This paper studies the use of Lua in intelligent instrumentation. It discusses features that provide flexibility and power to users embedding applications onboard instruments and it presents some real wo- rld applications of the technology.},
  db        = {IEEE},
  doi       = {10.1109/AUTEST.2009.5314042},
  issn      = {1088-7725},
  keywords  = {Linux;application program interfaces;authoring languages;automatic test equipment;embedded systems;API;ATE system;ISO ANSI-C;LXI specification;Linux;Lua scripting language;Windows;automated test equipment;automation industries;custom libraries;custom utilities;embedded applications;full featured scripting language;high level scripting language;instrument based operation;instrument to instrument messaging;integrated processor;intelligent instrumentation;language interpreter;mezzanine type hardware;onboard instruments;Automatic control;Automatic testing;Automation;Communication industry;Hardware;ISO;Industrial control;Instruments;Libraries;Process control},
}

@InProceedings{6108279,
  author    = {C. Chise and I. Jurca},
  title     = {Hybrid Analytical-Simulation Model Used to Evaluate and Improve System Performance},
  booktitle = {2011 10th International Symposium on Parallel and Distributed Computing},
  year      = {2011},
  pages     = {240-246},
  month     = {July},
  abstract  = {Performance prediction has been intensively studied in the last decade, alongside the accelerated development of distributed systems. This paper focuses on a hybrid approach regarding model solving, combining two popular prediction techniques applied separately so far, analytical and simulation modeling, in order to benefit from the strengths of both. The input UML model with MARTE (Modeling and Analysis of Real-time and Embedded systems) annotations is transformed into a hierarchically decomposed performance model, and performance results for simulated sub models are used by an analytical solver. The validation of the proposed method is to be performed with a tool called PHYMSS (Performance Hybrid Model Solver and Simulator) developed by the authors that implements both the hybrid solver and a multithreaded simulator.},
  db        = {IEEE},
  doi       = {10.1109/ISPDC.2011.42},
  issn      = {2379-5352},
  keywords  = {Unified Modeling Language;distributed processing;performance evaluation;MARTE;PHYMSS;distributed systems;hybrid analytical-simulation model;input UML model;system performance;Analytical models;Computational modeling;Mathematical model;Predictive models;Servers;Throughput;Unified modeling language;LQN;hybrid model;simulation},
}

@InProceedings{7383583,
  author    = {Z. Cheng and Y. Li and R. West},
  title     = {Qduino: A Multithreaded Arduino System for Embedded Computing},
  booktitle = {2015 IEEE Real-Time Systems Symposium},
  year      = {2015},
  pages     = {261-272},
  month     = {Dec},
  abstract  = {Arduino is an open source platform that offers a clear and simple environment for physical computing. It is now widely used in modern robotics and Internet of Things (IoT) applications, due in part to its low-cost, ease of programming, and rapid prototyping capabilities. Sensors and actuators can easily be connected to the analog and digital I/O pins of an Arduino device, which features an on-board microcontroller programmed using the Arduino API. The increasing complexity of physical computing applications has now led to a series of Arduino-compatible devices with faster processors, increased flash storage, larger memories and more complicated I/O architectures. The Intel Galileo, for example, is designed to support the Arduino API on top of a Linux system, code-named Clanton. However, the standard API is restricted to the capabilities found on less powerful devices, lacking support for multithreaded programs, or specification of real-time requirements. In this paper, we present Qduino, a system developed for Arduino compatible boards. Qduino provides an extended Arduino API which, while backward-compatible with the original API, supports real-time multithreaded sketches and event handling. Experiments show the performance gains of Qduino compared to Clanton Linux.},
  db        = {IEEE},
  doi       = {10.1109/RTSS.2015.32},
  issn      = {1052-8725},
  keywords  = {Linux;application program interfaces;formal specification;multi-threading;public domain software;real-time systems;Arduino API;Arduino compatible boards;Arduino-compatible devices;Clanton;I/O architectures;Intel Galileo;Internet of Things applications;IoT applications;Linux system;Qduino;Quest real-time operating system;actuators;backward-compatibility;embedded computing;event handling;flash storage;multithreaded Arduino system;multithreaded programs;on-board microcontroller;open source platform;physical computing applications;programming;rapid prototyping capabilities;real-time multithreaded sketches;real-time requirement specification;robotics;sensors;Computer architecture;Hardware;Instruction sets;Kernel;Linux;Real-time systems;Standards;Arduino;embedded systems;multi-threading;real-time},
}

@InProceedings{4724900,
  author    = {J. Chase and B. Nelson and J. Bodily and Z. Wei and D. J. Lee},
  title     = {Real-Time Optical Flow Calculations on FPGA and GPU Architectures: A Comparison Study},
  booktitle = {2008 16th International Symposium on Field-Programmable Custom Computing Machines},
  year      = {2008},
  pages     = {173-182},
  month     = {April},
  abstract  = {FPGA devices have often found use as higher-performance alternatives to programmable processors for implementing a variety of computations. Applications successfully implemented on FPGAs have typically contained high levels of parallelism and have often used simple statically-scheduled control and modest arithmetic. Recently introduced computing devices such as coarse grain reconfigurable arrays, multi-core processors, and graphical processing units (GPUs) promise to significantly change the computational landscape for the implementation of high-speed real-time computing tasks. One reason for this is that these architectures take advantage of many of the same application characteristics that fit well on FPGAs. One real-time computing task, optical flow, is difficult to apply in robotic vision applications in practice because of its high computational and data rate requirements, and so is a good candidate for implementation on FPGAs and other custom computing architectures. In this paper, a tensor-based optical flow algorithm is implemented on both an FPGA and a GPU and the two implementations discussed. The two implementations had similar performance, but with the FPGA implementation requiring 12Ã more development time. Other comparison data for these two technologies is then given for three additional applications taken from a MIMO digital communication system design, providing additional examples of the relative capabilities of these two technologies.},
  db        = {IEEE},
  doi       = {10.1109/FCCM.2008.24},
  keywords  = {MIMO systems;field programmable gate arrays;optical computing;program processors;FPGA devices;MIMO digital communication system design;computing architectures;graphical processing units;multicore processors;statically-scheduled control;tensor-based optical flow algorithm;Arithmetic;Computer architecture;Computer vision;Data flow computing;Field programmable gate arrays;High speed optical techniques;Image motion analysis;Multicore processing;Optical computing;Parallel processing},
}

@InProceedings{5694285,
  author    = {D. W. Chang and C. D. Jenkins and P. C. Garcia and S. Z. Gilani and P. Aguilera and A. Nagarajan and M. J. Anderson and M. A. Kenny and S. M. Bauer and M. J. Schulte and K. Compton},
  title     = {ERCBench: An Open-Source Benchmark Suite for Embedded and Reconfigurable Computing},
  booktitle = {2010 International Conference on Field Programmable Logic and Applications},
  year      = {2010},
  pages     = {408-413},
  month     = {Aug},
  abstract  = {Researchers in embedded and reconfigurable computing are often hindered by a lack of suitable benchmarks with which to accurately evaluate their work. Without a suitable benchmark suite, researchers use either outdated, unrealistic benchmarks or spend valuable time creating their own. In this paper, we present ERCBench - a freely-available, open-source benchmark suite geared towards embedded and reconfigurable computing research. ERCBench benchmarks represent a variety of application areas, including multimedia processing, wireless communications, and cryptography. They consist of synthesizable Verilog models for hardware accelerators and hybrid hardware/software applications that combine software-based control flow with hardware-based computation tasks.},
  db        = {IEEE},
  doi       = {10.1109/FPL.2010.85},
  issn      = {1946-147X},
  keywords  = {benchmark testing;hardware description languages;public domain software;reconfigurable architectures;ERCBench;Verilog model;embedded computing;hardware accelerator;hardware-based computation;open source benchmark suite;reconfigurable computing;software- based control flow;benchmarks;embedded computing;open-source;reconfigurable computing},
}

@InProceedings{7459504,
  author    = {D. Cesarini and A. Marongiu and L. Benini},
  title     = {An optimized task-based runtime system for resource-constrained parallel accelerators},
  booktitle = {2016 Design, Automation Test in Europe Conference Exhibition (DATE)},
  year      = {2016},
  pages     = {1261-1266},
  month     = {March},
  abstract  = {Manycore accelerators have recently proven a promising solution for increasingly powerful and energy efficient computing systems. This raises the need for parallel programming models capable of effectively leveraging hundreds to thousands of processors. Task-based parallelism has the potential to provide such capabilities, offering flexible support to fine-grained and irregular parallelism. However, efficiently supporting this programming paradigm on resource-constrained parallel accelerators is a challenging task. In this paper, we present an optimized implementation of the OpenMP tasking model for embedded parallel accelerators, discussing the key design solution that guarantee small memory (footprint) and minimize performance overheads. We validate our design by comparing to several state-of-the-art tasking implementations, using the most representative parallelization patterns. The experimental results confirm that our solution achieves near-ideal speedups for tasks as small as 5K cycles.},
  db        = {IEEE},
  keywords  = {embedded systems;multiprocessing systems;parallel programming;performance evaluation;OpenMP tasking model;embedded parallel accelerators;energy efficIent computing systems;fine-grained parallelism;irregular parallelism;manycore accelerators;optimized task-based runtime system;parallel programming models;performance overhead minimization;resource-constrained parallel accelerators;task-based parallelism;Context;Instruction sets},
}

@InProceedings{6842273,
  author    = {U. Cekmez and M. Ozsiginan and O. K. Sahingoz},
  title     = {A UAV path planning with parallel ACO algorithm on CUDA platform},
  booktitle = {2014 International Conference on Unmanned Aircraft Systems (ICUAS)},
  year      = {2014},
  pages     = {347-354},
  month     = {May},
  abstract  = {Solving the path planning problem of a UAV is a challenging issue especially if there are too many checkpoints to visit. Mainly, the brute force approach is used to find the shortest path in the mission area, which requires too many times to find a solution. Therefore, evolutionary algorithms and swarm intelligence techniques are used to find a feasible solution in an acceptable time. In this study, path planning problem of a UAV is solved by using a highly parallelized Ant Colony Optimization (ACO) algorithm on CUDA platform. The UAV path is constructed for disseminating keys and collecting data from a Wireless Sensor Network, which is previously defined. Due to its simplicity and effectiveness, ACO is selected as a path planning algorithm. However, ACO is not satisfactory if the mission area becomes large and there are an excessive number of checkpoints and/or additional constraints. In order to increase the performance, some parallelization techniques must be used in high performance computing platforms. GPU architecture has emerged as a powerful and low cost architecture for enabling impressive speedups for scientific calculations. Therefore, the parallel structure is constructed on CUDA architecture. The experimental results are compared with the CPU performance of the serial algorithm, and they clearly show that the proposed approach have a great potential for acceleration of ACO and allow to solve many complex tasks such as UAV path planning problem. We also present the execution results with different parameter values to expose the results for the researchers.},
  db        = {IEEE},
  doi       = {10.1109/ICUAS.2014.6842273},
  keywords  = {ant colony optimisation;autonomous aerial vehicles;graphics processing units;mobile robots;parallel architectures;path planning;CUDA platform;GPU architecture;UAV path planning;ant colony optimization;brute force approach;compute unified device architecture;evolutionary algorithms;graphics processing units;parallel ACO algorithm;swarm intelligence techniques;unmanned aerial vehicle;wireless sensor network;Central Processing Unit;Cities and towns;Computer architecture;Graphics processing units;Instruction sets;Path planning;Planning},
}

@InProceedings{7818327,
  author    = {G. Cedersjö and J. W. Janneck},
  title     = {Processes and actors: Translating Kahn processes to dataflow with firing},
  booktitle = {2016 International Conference on Embedded Computer Systems: Architectures, Modeling and Simulation (SAMOS)},
  year      = {2016},
  pages     = {21-30},
  month     = {July},
  abstract  = {Dataflow programming is a paradigm for describing stream processing algorithms in a manner that naturally exposes their concurrency and makes the resulting programs readily implementable on highly parallel architectures. Dataflow programs are graph structured, with nodes representing computational kernels that process the data flowing over the edges. There are two major families of languages for the kernels: process languages and languages for dataflow with firing. While processes tend to be easier to write, the additional structure provided by the dataflow-with-firing style increases the analyzability of dataflow programs and supports more efficient implementation techniques. This paper seeks to combine these benefits in a principled manner by constructing a family of translations from a process language to dataflow with firing. In order to formally relate these descriptions, we first introduce a notion of firing to the semantics of Kahn processes, which allows us to give a precise definition of equivalence between programs written in these different styles. Then we introduce a family of translations between them and and show that they retain meaning of a program. The presented language and its translation has been implemented in a compiler for the dataflow programming language CAL.},
  db        = {IEEE},
  doi       = {10.1109/SAMOS.2016.7818327},
  keywords  = {concurrency control;data flow computing;parallel architectures;program compilers;CAL;Kahn process translation;compiler;computational kernels;dataflow programming language;dataflow-with-firing style;parallel architectures;process languages;stream processing algorithms;Computational modeling;Computer languages;Grammar;Ports (Computers);Programming;Semantics;Structural rings},
}

@InProceedings{7328218,
  author    = {A. Capotondi and A. Marongiu and L. Benini},
  title     = {Enabling Scalable and Fine-Grained Nested Parallelism on Embedded Many-cores},
  booktitle = {2015 IEEE 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip},
  year      = {2015},
  pages     = {297-304},
  month     = {Sept},
  abstract  = {Current high-end embedded systems are designed as heterogeneous systems-on-chip (SoCs), where a general-purpose host processor is coupled to a programmable manycore accelerator (PMCA). Such PMCAs typically leverage hierarchical interconnect and distributed memory with non-uniform access (NUMA). Nested parallelism is a convenient programming abstraction for large-scale cc-NUMA systems, which allows to hierarchically (and dynamically) create multiple levels of fine-grained parallelism whenever it is available. Available implementations for cc-NUMA systems introduce large overheads for nested parallelism management, which cannot be tolerated due to the extremely fine-grained nature of embedded parallel workloads. In particular, creating a team of parallel threads has a cost that increases linearly with the number of threads, which is inherently non scalable. This work presents a software cache mechanism for frequently-used parallel team configurations to speed up parallel thread creation overheads in PMCA systems. When a configuration is found in the cache the cost for parallel team creation has a constant time, providing a scalable mechanism. We evaluated our support on the STMicroelectronics STHORM many-core. Compared to the state-of-the art, our solution shows that: i) the cost for parallel team creation is reduced by up to 67%, ii) the tangible effect on real ultra-fine-grained parallel kernels is a speedup of up to 80%.},
  db        = {IEEE},
  doi       = {10.1109/MCSoC.2015.47},
  keywords  = {cache storage;embedded systems;multiprocessing systems;parallel programming;system-on-chip;PMCA;STMicroelectronics STHORM many-core;SoC;distributed memory with nonuniform access;embedded many-cores;embedded systems;fine-grained parallelism;heterogeneous systems-on-chip;nested parallelism;parallel team configuration;parallel thread creation overhead;programmable manycore accelerator;programming abstraction;software cache mechanism;Fabrics;Instruction sets;Message systems;Parallel processing;Programming;Recruitment;Embedded Many-Core Architectures;OpenMP;Parallel Programming Models},
}

@InProceedings{5751519,
  author    = {C. Brooks and E. A. Lee and S. Tripakis},
  title     = {Exploring models of computation with Ptolemy II},
  booktitle = {2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)},
  year      = {2010},
  pages     = {331-332},
  month     = {Oct},
  abstract  = {The Ptolemy project studies modeling, simulation, and design of concurrent, real-time, embedded systems. The focus is on assembly of concurrent components. The key underlying principle in the project is the use of well-defined models of computation that govern the interaction between components. A major problem area being addressed is the use of heterogeneous mixtures of models of computation. Ptolemy II takes a component view of design, in that models are constructed as a set of interacting components. A model of computation governs the semantics of the interaction, and thus imposes an execution-time discipline. Ptolemy II has implementations of many models of computation including Synchronous Data Flow, Kahn Process Networks, Discrete Event, Continuous Time, Synchronous/Reactive and Modal Models This hands-on tutorial explores how these models of computation are implemented in Ptolemy II and how to create new models of computation such as a "non-dogmatic" Process Networks example and a left-to-right execution policy example.},
  db        = {IEEE},
  doi       = {10.1145/1878961.1879020},
  keywords  = {embedded systems;object-oriented methods;public domain software;Kahn process networks;Ptolemy II;concurrent embedded systems;continuous time models;discrete event models;execution time discipline;left-to-right execution policy;modal models;non dogmatic process networks;real time embedded systems;synchronous data flow;synchronous-reactive models;Computational modeling;Data models;Object oriented modeling;Real time systems;Semantics;Software;Tutorials;Modeling;concurrency;simulation},
}

@InProceedings{6690509,
  author    = {A. V. Brito and A. V. Negreiros and C. Roth and O. Sander and J. Becker},
  title     = {Development and Evaluation of Distributed Simulation of Embedded Systems Using Ptolemy and HLA},
  booktitle = {2013 IEEE/ACM 17th International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2013},
  pages     = {189-196},
  month     = {Oct},
  abstract  = {Nowadays, embedded systems have a huge amount of computational power and consequently, high complexity. It is quite usual to find different applications being executed in embedded systems. Embedded system design demands for method and tools that allow the simulation and verification in an efficient and practical way. This paper proposes the development and evaluation of a solution for embedded modeling and simulation of heterogeneous Models of Computation (MoCs) in a distributed way by the integration of Ptolemy II and the High Level Architecture (HLA), a middleware for distributed discrete event simulation, in order to create an environment with high-performance execution of large-scale heterogeneous models. Experimental results demonstrate, that the use of a non distributed simulation for some situations can be infeasible, as well as the use of distributed simulation with few machines, like one, two or three computers. It was demonstrated that a speedup of factor 4 was acquired when a model with 4,000 thousands actors were distributed in 8 different machines.},
  db        = {IEEE},
  doi       = {10.1109/DS-RT.2013.28},
  issn      = {1550-6525},
  keywords  = {discrete event simulation;embedded systems;middleware;HLA;MoC;Ptolemy II;computational power;distributed discrete event simulation;embedded modeling and simulation;embedded systems;heterogeneous models of computation;high level architecture;high-performance execution;large-scale heterogeneous models;middleware;nondistributed simulation;Computational modeling;Computer architecture;Embedded systems;Ports (Computers);Sensors;Unified modeling language;Wireless sensor networks;Distributed Simulation;Embedded Systems;Heterogeneous Simulation},
}

@InProceedings{6825342,
  author    = {A. V. Brito and A. V. Negreiros},
  title     = {Allowing Large-Scale Systems Evaluation with Ptolemy through Distributed Simulation},
  booktitle = {2013 III Brazilian Symposium on Computing Systems Engineering},
  year      = {2013},
  pages     = {53-58},
  month     = {Dec},
  abstract  = {Nowadays, embedded systems have a huge amount of computational power and consequently, high complexity. It is quite usual to find different applications being executed in embedded systems. Embedded system design demands for method and tools that allow the simulation and verification in an efficient and practical way. This paper proposes the development and evaluation of a solution for embedded modeling and simulation of embedded systems in a distributed way by the integration of Ptolemy II and the High Level Architecture (HLA), in order to create an environment with high-performance execution of large-scale models. Experimental results demonstrated that the use of a non distributed simulation for some situations can be infeasible. It was demonstrated that a speedup of factor 4 was acquired when a model with 4,000 thousands actors were distributed in 8 different machines. It also presented a model of execution of each CPU core during the simulation.},
  db        = {IEEE},
  doi       = {10.1109/SBESC.2013.19},
  issn      = {2324-7886},
  keywords  = {digital simulation;embedded systems;telecommunication computing;wireless sensor networks;CPU core;HLA;Ptolemy II;embedded modeling;embedded simulation;embedded system design;high level architecture;high-performance execution;large-scale models;large-scale systems evaluation;nondistributed simulation;wireless sensor network;Computational modeling;Computer architecture;Embedded systems;Graphics;Unified modeling language;Wireless sensor networks;Distributed Simulation;Embedded Systems;Heterogeneous Simulation},
}

@InProceedings{6651023,
  author    = {A. Branco and A. L. d. Moura and N. Rodriguez and S. Rossetto},
  title     = {Teaching Concurrent and Distributed Computing -- Initiatives in Rio de Janeiro},
  booktitle = {2013 IEEE International Symposium on Parallel Distributed Processing, Workshops and Phd Forum},
  year      = {2013},
  pages     = {1318-1323},
  month     = {May},
  abstract  = {In this paper we describe two ongoing initiatives for teaching concurrency and distribution in PUC-Rio and UFRJ. One of them is a new approach for teaching distributed systems. Conventional distributed system courses follow a syllabus in which a list of topics is discussed independently and at different levels of abstractions. In Edupar'2012, we proposed a course with a novel approach, using a wireless sensor network environment to pin all topics down to concrete applications and to maintain issues such as fault tolerance and coordination continuously present. The second initiative is a smaller one, in which we insert a new topic in a Systems Software course to allow students to have a better understanding of what is application-level multitasking and of how it can be implemented. In this paper, we report on the experience of teaching the proposed syllabus and the adjustments that were necessary. We also discuss some plans for the courses in 2013.},
  db        = {IEEE},
  doi       = {10.1109/IPDPSW.2013.33},
  keywords  = {concurrency control;distributed processing;teaching;wireless sensor networks;application-level multitasking;concurrent computing;distributed computing;systems software course;teaching;wireless sensor network environment;Education;Fault tolerance;Fault tolerant systems;Materials;Programming;Proposals;Wireless sensor networks;application-level multitasking;coroutines;cross-cutting approaches;event-based programming;fault tolerance},
}

@Article{5492692,
  author   = {A. Bergel and W. Harrison and V. Cahill and S. Clarke},
  title    = {FlowTalk: Language Support for Long-Latency Operations in Embedded Devices},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2011},
  volume   = {37},
  number   = {4},
  pages    = {526-543},
  month    = {July},
  issn     = {0098-5589},
  abstract = {Wireless sensor networks necessitate a programming model different from those used to develop desktop applications. Typically, resources in terms of power and memory are constrained. C is the most common programming language used to develop applications on very small embedded sensor devices. We claim that C does not provide efficient mechanisms to address the implicit asynchronous nature of sensor sampling. C applications for these devices suffer from a disruption in their control flow. In this paper, we present FlowTalk, a new object-oriented programming language aimed at making software development for wireless embedded sensor devices easier. FlowTalk is an object-oriented programming language in which dynamicity (e.g., object creation) has been traded for a reduction in memory consumption. The event model that traditionally comes from using sensors is adapted in FlowTalk with controlled disruption, a light-weight continuation mechanism. The essence of our model is to turn asynchronous long-latency operations into synchronous and blocking method calls. FlowTalk is built for TinyOS and can be used to develop applications that can fit in 4 KB of memory for a large number of wireless sensor devices.},
  db       = {IEEE},
  doi      = {10.1109/TSE.2010.66},
  keywords = {C language;embedded systems;intelligent sensors;object-oriented languages;object-oriented programming;software engineering;wireless sensor networks;C language;FlowTalk;TinyOS;asynchronous long-latency operations;embedded sensor devices;language support;light-weight continuation mechanism;memory consumption;memory size 4 KByte;object-oriented programming language;programming language;sensor sampling;wireless sensor networks;Application software;Automotive engineering;Biosensors;Computer languages;Embedded software;Java;Object oriented modeling;Object oriented programming;Sampling methods;Wireless sensor networks;Embedded systems;object-based programming.},
}

@InProceedings{7883359,
  author    = {T. Ball and J. Protzenko and J. Bishop and M. Moskal and J. de Halleux and M. Braun and S. Hodges and C. Riley},
  title     = {Microsoft Touch Develop and the BBC micro:bit},
  booktitle = {2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)},
  year      = {2016},
  pages     = {637-640},
  month     = {May},
  abstract  = {The chance to influence the lives of a million children does not come often. Through a partnership between the BBC and several technology companies, a small instructional computing device called the BBC micro:bit will be given to a million children in the UK in 2016. Moreover, using the micro:bit will be part of the CS curriculum. We describe how Microsoft's Touch Develop programming platform works with the BBC micro:bit. We describe the design and architecture of the micro:bit and the software engineering hurdles that had to be overcome to ensure it was as accessible as possible to children and teachers. The combined hardware/software platform is evaluated and early anecdotal evidence is presented.},
  db        = {IEEE},
  keywords  = {hardware-software codesign;BBC micro:bit;Microsoft touch develop programming platform;combined hardware-software platform;instructional computing device;software engineering;C++ languages;Computers;Encoding;Hardware;Libraries;Programming;Software;BBC micro:bit;K-12 education;Touch Develop;cloud;devices},
}

@InProceedings{6820867,
  author    = {O. Baldellon and J. C. Fabre and M. Roy},
  title     = {Minotor: Monitoring Timing and Behavioral Properties for Dependable Distributed Systems},
  booktitle = {2013 IEEE 19th Pacific Rim International Symposium on Dependable Computing},
  year      = {2013},
  pages     = {206-215},
  month     = {Dec},
  abstract  = {Assessing the correct behavior of a given system at run-time can be achieved by monitoring its execution, and is complementary to off-line analysis such as static verification. In this work, we focus on run-time monitoring of system properties that include both causality and timing constraints, in distributed and time-constrained systems. Based on a description of a property that includes events and temporal constraints, expressed as a timed-arc Petri net, we show how to automatically transform it into a an executable and distributed monitoring engine. To that aim, we introduce a modification of the semantics of Petri nets to be able to execute it online on partial executions and distributed observation environments. We show how to use this formal framework to provide MINOTOR, a model-driven distributed monitoring system, describe its implementation and show its applicability on a transportation use-case.},
  db        = {IEEE},
  doi       = {10.1109/PRDC.2013.41},
  keywords  = {Petri nets;formal specification;program diagnostics;program verification;rail traffic;system monitoring;transportation;MINOTOR;Petri net semantics modification;behavioral property monitoring;causality;dependable distributed systems;distributed monitoring engine;distributed observation environment;executable monitoring engine;execution monitoring;model-driven distributed monitoring system;off-line analysis;partial execution;railway transportation;run-time monitoring;run-time system behavior assessment;static verification;temporal constraint;time-constrained system;timed-arc Petri net;timing constraint;timing property monitoring;Delays;Message systems;Monitoring;Petri nets;Real-time systems;Semantics;Ditributed Systems;Fault-tolerant Systems;Online Monitoring;Petri nets;Time-constrained Systems},
}

@InProceedings{6961841,
  author    = {Y. Bai and K. Schneider and N. Bhardwaj and B. Katti and T. Shazadi},
  title     = {From clock-driven to data-driven models},
  booktitle = {2014 Twelfth ACM/IEEE Conference on Formal Methods and Models for Codesign (MEMOCODE)},
  year      = {2014},
  pages     = {32-41},
  month     = {Oct},
  abstract  = {Clock/time-driven models are powerful abstractions of real-time systems, as e.g., provided by the synchronous models of computation which lend themselves well for simulation and verification. At every clock cycle, new inputs are read, computations are performed in zero-time, and results are immediately/synchronously communicated between components. However, such zero-time idealizations are not realistic since computation and communication finally takes time in implementations. For implementations, data-driven execution models have the advantage to impose no timing constraints other than arrival of input data, and thus, these models are perfectly suited for distributed or other kinds of asynchronous implementations. For this reason, modern model-based design flows consider the desynchronization of synchronous models for system synthesis which is possible for the subclass of endochronous systems only. While definitions of endochrony were considered for years, it is shown in this paper how to efficiently verify endochrony by SAT solving. Our procedure consists of two steps: In the first step, we introduce buffers to the interface of a clock-driven component, so that its inputs can arrive at different points of time. After this step, clocks of signals are viewed as `instructions' telling the component which input values have to be consumed for the current reaction.We call such components clock-scheduled. In the second step, we remove the clocks from the interface of the clock-scheduled components, so that the component may now become nondeterministic. We prove in this paper that a synchronous component is endochronous, if and only if the clock signals can be safely removed in this step without destroying determinism. Based on this result, we present a decision procedure based on symbolic system representations to check whether components are endochronous. Preliminary experimental results show the effectiveness of our method.},
  db        = {IEEE},
  doi       = {10.1109/MEMCOD.2014.6961841},
  keywords  = {computability;symbol manipulation;SAT solving;clock cycle;clock-driven models;clock-scheduled components;data-driven execution models;endochronous systems;model-based design flows;symbolic system representations;synchronous models;system synthesis;time-driven models;zero-time idealizations;Circuit synthesis;Clocks;Computational modeling;Distributed databases;Integrated circuit modeling;Semantics;Synchronization},
}

@InProceedings{6544384,
  author    = {A. Asaduzzaman and F. N. Sibai and S. Aramco and H. El-Sayed},
  title     = {Performance and power comparisons of MPI Vs Pthread implementations on multicore systems},
  booktitle = {2013 9th International Conference on Innovations in Information Technology (IIT)},
  year      = {2013},
  pages     = {1-6},
  month     = {March},
  abstract  = {The advancement of multicore systems demands applications with more threads. In order to facilitate this demand, parallel programming models such as message passing interface (MPI) are developed. By using such models, the execution time and the power consumption can be reduced significantly. However, the performance of MPI programming depends on the total number of threads and the number of processing cores in the system. In this work, we experimentally study the impact of Open MPI and POSIX Thread (Pthread) implementations on performance and power consumption of multicore systems. Data dependent (like heat conduction on 2D surface) and data independent (like matrix multiplication) applications are used with high performance hardware in the experiments. Simulation results suggest that both implementations of more threads running in a system with more cores have potential to reduce the execution time with negligible or little increase in total power consumption. It is observed that the performance of MPI implementation varies (due to the dynamic communication overhead among the processing cores).},
  db        = {IEEE},
  doi       = {10.1109/Innovations.2013.6544384},
  keywords  = {application program interfaces;matrix algebra;message passing;multiprocessing systems;parallel programming;power aware computing;Open MPI;POSIX thread;Pthread implementations;data dependent;dynamic communication;matrix multiplication;message passing interface;multicore systems;parallel programming models;performance comparisons;performance hardware;power comparisons;power consumption;processing cores;pthread implementations;Instruction sets;Message systems;Multicore processing;Parallel programming;Power demand;Supercomputers;Workstations;Open MPI;Pthread;data dependency;message passing interface;multicore architecture},
}

@InProceedings{7460722,
  author    = {M. P. Andersen and G. Fierro and D. E. Culler},
  title     = {System Design for a Synergistic, Low Power Mote/BLE Embedded Platform},
  booktitle = {2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)},
  year      = {2016},
  pages     = {1-12},
  month     = {April},
  abstract  = {Modern IoT prototyping platforms fall short in terms of energy efficiency, connectivity and software programming practices. We present the design of a new hardware and software platform that addresses these shortcomings by bringing together Mobile, Wearable, Maker and Wireless Sensor Network technologies to enable rapid prototyping with a high degree of synergy and energy efficiency. This is achieved in part by leveraging the Memory Protection Unit on modern microcontrollers along with a novel syscall interface to provide kernel / user isolation and a clean concurrency model. Such a design allows a wide range of languages to be used for application development without significant adaptation. We demonstrate how careful choice of application language allows the naturally asynchronous nature of embedded programming to be expressed cleanly and powerfully. Finally we evaluate the platform in several integrated use cases, providing examples of the capabilities introduced by Synergy.},
  db        = {IEEE},
  doi       = {10.1109/IPSN.2016.7460722},
  keywords  = {concurrency (computers);embedded systems;microcontrollers;clean concurrency model;embedded programming;low power mote-BLE embedded platform;memory protection unit;microcontrollers;mobile network technologies;rapid prototyping;syscall interface;wearable technologies;wireless sensor network technologies;Hardware;IEEE 802.15 Standard;Microcontrollers;Software;Storms;Technological innovation;Wireless sensor networks},
}

@InProceedings{7471346,
  author    = {M. P. Andersen and G. Fierro and D. E. Culler},
  title     = {Enabling Synergy in IoT: Platform to Service and Beyond},
  booktitle = {2016 IEEE First International Conference on Internet-of-Things Design and Implementation (IoTDI)},
  year      = {2016},
  pages     = {1-12},
  month     = {April},
  abstract  = {To enable a prosperous Internet of Things, devices and services must be extensible and adapt to changes in the environment or user interaction patterns. These requirements manifest as a set of design principles for each of the layers in an IoT ecosystem, from hardware to cloud services. This paper gives concrete guidelines learned from building a full-stack Synergistic IoT platform.},
  db        = {IEEE},
  doi       = {10.1109/IoTDI.2015.45},
  keywords  = {Internet of Things;wireless sensor networks;Internet of Things;IoT synergy;synergistic IoT platform;user interaction pattern;Complexity theory;Context;Hardware;IEEE 802.15 Standard;Metadata;Protocols;Software;Internet of Things;Sensor motes;Wireless sensor networks},
}

@Article{6463378,
  author   = {S. Andalam and P. S. Roop and A. Girault and C. Traulsen},
  title    = {A Predictable Framework for Safety-Critical Embedded Systems},
  journal  = {IEEE Transactions on Computers},
  year     = {2014},
  volume   = {63},
  number   = {7},
  pages    = {1600-1612},
  month    = {July},
  issn     = {0018-9340},
  abstract = {Safety-critical embedded systems, commonly found in automotive, space, and health-care, are highly reactive and concurrent. Their most important characteristics are that they require both functional and timing correctness. C has been the language of choice for programming such systems. However, C lacks many features that can make the design process of such systems seamless while also maintaining predictability. This paper addresses the need for a C-based design framework for achieving time predictability. To this end, we propose the PRET-C language and the ARPRET architecture. PRET-C offers a small set of extensions to a subset of C to facilitate effective concurrent programming. We present a new synchronous semantics for PRET-C. It guarantees that all PRET-C programs are deterministic, reactive, and provides thread-safe communication via shared memory access. This simplifies considerably the design of safety-critical systems. We also present the architecture of a precision timed machine (PRET) called ARPRET. It offers the ability to design time predictable architectures through simple customizations of soft-core processors. We have designed ARPRET particularly for efficient and predictable execution of PRET-C. We demonstrate through extensive benchmarking that PRET-C based system design excels in comparison to existing C-based paradigms. We also qualitatively compare our approach to the Berkeley-Columbia PRET approach. We have demonstrated that the proposed approach provides an ideal framework for designing and validating safety-critical embedded systems.},
  db       = {IEEE},
  doi      = {10.1109/TC.2013.28},
  keywords = {C language;embedded systems;multi-threading;programming language semantics;safety-critical software;shared memory systems;ARPRET;ARPRET architecture;Berkeley-Columbia PRET approach;C-based design framework;PRET-C language;PRET-C programs;Precision Timed C language;architecture of a precision timed machine;concurrent programming;deterministic programs;lightweight multithreaded language;reactive programs;safety-critical embedded systems;shared memory access;soft-core processors;synchronous semantics;thread-safe communication;time predictable architectures;Computer architecture;Instruction sets;Programming;Real-time systems;Semantics;Timing;PRET;PRET-C;Safety-critical systems;WCET;WCRT;synchronous languages;time predictability},
}

@InProceedings{5558636,
  author    = {S. Andalam and P. Roop and A. Girault},
  title     = {Predictable multithreading of embedded applications using PRET-C},
  booktitle = {Eighth ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE 2010)},
  year      = {2010},
  pages     = {159-168},
  month     = {July},
  abstract  = {We propose a new language called Precision Timed C (PRET-C), for predictable and lightweight multi-threading in C. PRET-C supports synchronous concurrency, preemption, and a high-level construct for logical time. In contrast to existing synchronous languages, PRET-C offers C-based shared memory communications between concurrent threads that is guaranteed to be thread safe. Due to the proposed synchronous semantics, the mapping of logical time to physical time can be achieved much more easily than with plain C, thanks to a Worst Case Reaction Time (WCRT) analyzer (not presented here). Associated to the PRET-C programming language, we present a dedicated target architecture, called ARPRET, which combines a hardware accelerator associated to an existing softcore processor. This allows us to improve the throughput while preserving the predictability. With extensive benchmarking, we then demonstrate that ARPRET not only achieves completely predictable execution of PRET-C programs, but also improves the throughput when compared to the pure software execution of PRET-C. The PRET-C software approach is also significantly more efficient in comparison to two other light-weight concurrent C variants (namely SC and Protothreads), as well as the well-known Esterel synchronous programming language.},
  db        = {IEEE},
  doi       = {10.1109/MEMCOD.2010.5558636},
  keywords  = {C language;embedded systems;multi-threading;shared memory systems;ARPRET;Esterel synchronous programming language;PRET-C programming language;embedded applications;precision timed C;predictable multithreading;shared memory communications;worst case reaction time analyzer;Assembly;Concurrent computing;Hardware;Instruction sets;Semantics;Timing},
}

@InProceedings{4542057,
  author    = {A. Anane and E. M. Aboulhamid and J. Vachon and Y. Savaria},
  title     = {Modeling and simulation of complex heterogeneous systems},
  booktitle = {2008 IEEE International Symposium on Circuits and Systems},
  year      = {2008},
  pages     = {2873-2876},
  month     = {May},
  abstract  = {Given the increasing heterogeneity and complexity of systems being developed, untimed modeling at a system level becomes more and more important for design space exploration and verification, due to its conciseness and speed. After showing inadequacies of SystemC, which is the predominant modeling environment in this area, we propose a paradigm shift from immediate notifications and coroutines in SystemC to Atomic Actions and true parallelism in an extension of Esys.NET. We exploit the introspection and attribute programming to extend the capabilities of the environment and to build the basis for heterogeneous cosimulation. This paper aims to show the main advantages of this paradigm shift, such as (1) the improvement of simulation time by exploiting the capabilities of multicore simulation hosts, (2) the reduction of modeling hazards related to parallelism and resource sharing, and (3) a more efficient design space exploration.},
  db        = {IEEE},
  doi       = {10.1109/ISCAS.2008.4542057},
  issn      = {0271-4302},
  keywords  = {programming language semantics;software engineering;temporal logic;Esys.NET;SystemC;atomic actions;complex heterogeneous systems;heterogeneous cosimulation;multicore simulation;paradigm shift;resource sharing;space exploration;Collaborative work;Costs;Hazards;Kernel;Libraries;Manufacturing processes;Multicore processing;Productivity;Resource management;Space exploration},
}

@Article{7387670,
  author   = {M. Amjad and M. Sharif and M. K. Afzal and S. W. Kim},
  title    = {TinyOS-New Trends, Comparative Views, and Supported Sensing Applications: A Review},
  journal  = {IEEE Sensors Journal},
  year     = {2016},
  volume   = {16},
  number   = {9},
  pages    = {2865-2889},
  month    = {May},
  issn     = {1530-437X},
  abstract = {The wireless sensor network (WSN) is an interesting area for modern day research groups. Tiny sensor nodes are deployed in a diversity of environments but with limited resources. Scarce resources compel researchers to employ an operating system that requires limited memory and minimum power. Tiny operating system (TinyOS) is a widely used operating system for sensor nodes, which provides concurrency and flexibility while adhering to the constraints of scarce resources. Comparatively, TinyOS is considered to be the most robust, innovative, energy-efficient, and widely used operating system in sensor networks. This paper looks at the state-of-the-art TinyOS and the different dimensions of its design paradigm, programming model, execution model, scheduling algorithms, concurrency, memory management, hardware support platforms, and other features. The addition of different features in TinyOS makes it the operating system of choice for WSNs. Sensing nodes with TinyOS seem to show more flexibility in supporting diverse types of sensing applications.},
  db       = {IEEE},
  doi      = {10.1109/JSEN.2016.2519924},
  keywords = {systems software;wireless sensor networks;Tiny operating system;concurrency;design paradigm;execution model;hardware support platforms;memory management;programming model;scheduling algorithms;sensor nodes;wireless sensor network;Adaptation models;Concurrent computing;Instruction sets;Operating systems;Programming;Sensors;Wireless sensor networks;Wireless sensor networks;energy efficiency;operating system;sensor nodes},
}

@Article{Zhang2017,
  author   = {Yangyang Zhang and Jianxin Li and Chenggen Sun and Md Zakirul Alam Bhuiyan and Weiren Yu and Richong Zhang},
  title    = {HotML: A DSM-based Machine Learning System for Social Networks},
  journal  = {Journal of Computational Science},
  year     = {2017},
  pages    = {-},
  issn     = {1877-7503},
  abstract = {Abstract In big data era, social networks, such as Twitter, Weibo, Facebook, are becoming more and more popular worldwide. To help social networks analysis, many machine learning (ML) algorithms have been adopted, e.g. user classification, link prediction, sentiment analysis, recommendations, etc. However, the dataset could be so large that it might take even days to train a model on a machine learning system. Performance issues should be considered to boost the training process. In this paper, we proposed HotML, a general machine learning system. HotML is designed in the parameter server (PS) architecture where the servers manage the globally shared parameters organized in tabular structure, and the workers compute the dataset in parallel and update the global parameters. HotML is based on our prior work \{DPS\} that provides high-level data abstraction, lightweight task scheduling system, and \{SSP\} consistency. HotML improved the \{DPS\} design by decoupling \{PS\} server and \{PS\} worker physically, and provides flexible consistency models including SSPPush, \{SSPDrop\} besides SSP, fault tolerance including consistent server-side checkpoint and flexible worker-side checkpoint, and workload balancing. To demonstrate the performance and scalability of the proposed system, a series of experiments are conducted and the results show that HotML can reduce networking time by about 74%, and achieve up to 1.9x performance compared to the popular \{ML\} system, Petuum. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jocs.2017.09.006},
  keywords = {Big data, Parameter server, Distributed machine learning, Fault tolerance },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877750317303459},
}

@InCollection{Wolf2007223,
  author    = {Wayne Wolf},
  title     = {Chapter 4 - Processes and Operating Systems},
  booktitle = {High-Performance Embedded Computing},
  publisher = {Morgan Kaufmann},
  year      = {2007},
  editor    = {Wolf, Wayne},
  pages     = {223 - 265},
  address   = {San Francisco},
  isbn      = {978-0-12-369485-0},
  abstract  = {Publisher Summary Multiple processes may be executed on a single computer processing unit (CPU) to save hardware and, to some extent, to save energy; however, it is important to be careful to share the \{CPU\} so as to meet all the real-time deadlines. A large body of literature has been written on real-time scheduling, taking into account various conditions on execution and assumptions. Real-time operating systems must be designed to efficiently implement basic operations such as scheduling, interrupt handling, and interprocess communication. Several scheduling protocols can be used to guarantee basic real-time behavior. However, it may not be possible to use 100% of the \{CPU\} if it has to be guaranteed that all the deadlines will be met. Scheduling for dynamic voltage scaling tries to stretch the execution time of processes just to meet their deadline to take advantage of the lower operating voltages allowed by slower execution. Context switching and interrupt overhead may be important in heavily utilized systems. File systems implemented in flash memory must use specialized techniques to avoid wearing out the flash memory. Concurrent system verification builds and searches state machine models to determine whether desired properties are satisfied. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-012369485-0/50005-1},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780123694850500051},
}

@InCollection{Wolf2014201,
  author    = {Marilyn Wolf},
  title     = {Chapter 4 - Processes and Operating Systems},
  booktitle = {High-Performance Embedded Computing (Second Edition)},
  publisher = {Morgan Kaufmann},
  year      = {2014},
  editor    = {Wolf, Marilyn},
  pages     = {201 - 241},
  address   = {Boston},
  edition   = {Second Edition},
  isbn      = {978-0-12-410511-9},
  abstract  = {Abstract This chapter covers multiple-process systems. It compares scheduling algorithms, including the interaction between language design and scheduling mechanisms. It evaluates operating system architectures and the overhead incurred by the operating system and also considers methods for verifying the behavior of multiple process systems. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-410511-9.00004-6},
  keywords  = {processes and scheduling, processes versus tasks, static versus dynamic, constructive versus iterative improvement, priority schedulers, real-time versus general-purpose, hard versus soft, deadline definitions, process specifications, utilization, static scheduling algorithms, data dependencies and scheduling, resource dependencies, implementation, list scheduler, interval scheduling, dynamic and priority-driven scheduling, static versus dynamic priorities, Liu and Layland, RMS priority assignment, RMS utilization, earliest deadline first, least-laxity first scheduling, response time, priority inversion, priority inheritance protocols, priority ceiling protocol, hot swapping, mixed-criticality schedulability, load-based schedulability, PLRS, CBEDF, ductility, scheduling for dynamic voltage scaling, discrete voltages and frequencies, slack-based scheduling, checkpoint-driven scheduling, leakage minimization, leakage and temperature, multitasking and caches, program placement for caches, simplified process caching models, caches and scheduling, multitasking and scratch pads, CFSMs, Petri-net scheduling, software thread integration, Giotto, SHIM, general-purpose versus real-time, interrupts and scheduling, ISRs and ISTs, OS simulation, overhead study, RTU, Spring scheduler, RTM, IPC in general-purpose systems, streaming and large transfers, ACPI, embedded file systems, flash-based file challenges, wear leveling, virtual mapping, block cleaning costs, log-structured file systems, NAND versus \{NOR\} flash, NAND-oriented file systems, block-device emulation, properties, deadlock, property specification, product machines, debugging },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124105119000046},
}

@InCollection{Walls2012229,
  author    = {Colin Walls},
  title     = {Chapter 6 - Real Time},
  booktitle = {Embedded Software (Second Edition)},
  publisher = {Newnes},
  year      = {2012},
  editor    = {Walls, Colin},
  pages     = {229 - 241},
  address   = {Oxford},
  edition   = {Second Edition},
  isbn      = {978-0-12-415822-1},
  abstract  = {This chapter focuses on the core features of real time systems. Four ways to implement a real time system have been described. Visualizing program models and event handling in embedded systems are presented in “question and answer” format. The importance of interrupts in a real-time program is also discussed. It was concluded that programming to accommodate interrupts is being readily accomplished in C using modern development tools. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-415822-1.00006-4},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124158221000064},
}

@Article{Venkatesan2017311,
  author   = {Varun Venkatesan and Swamy D. Ponpandi and Akhilesh Tyagi},
  title    = {Shaping data for application performance and energy optimization in dynamic data view framework},
  journal  = {Integration, the \{VLSI\} Journal},
  year     = {2017},
  volume   = {58},
  pages    = {311 - 319},
  issn     = {0167-9260},
  abstract = {Abstract Memory access bottlenecks are often due to the result of mismatch between the processor hardware's view of data and the algorithmic/logical view of data. This variation in data views is especially more pronounced in applications involving large datasets, leading to significantly increased latency and user response times. Previous attempts to tackle this problem were primarily targeted at execution time optimization. We present a dynamic technique piggybacked on the classical dynamic binary optimization (DBO) to shape the data view for each program phase differently resulting in program execution time reduction along with reductions in access energy. Our implementation rearranges non-adjacent data into a contiguous dataview. It uses wrappers to replace irregular data access patterns with spatially local dataview. \{DDV\} (Dynamic data view), a runtime dynamic binary translation and optimization framework has been used to perform runtime instrumentation and dynamic data optimization to achieve this goal. This scheme not only ensures a reduced program execution time, but also results in lower cache access energy. Some of the commonly used benchmarks from the \{SPEC\} 2006 and SPLASH-2 suite were profiled to determine irregular data accesses from procedures which contributed heavily to the overall execution time. Wrappers built to replace these accesses with spatially adjacent data led to a significant improvement in the total execution time. On average, 20% reduction in time was achieved along with a 5% reduction in energy for \{SPEC\} 2006 and 11% reduction in time was achieved along with a 6% reduction in energy for SPLASH-2. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.vlsi.2016.12.001},
  keywords = {Dynamic binary optimization, Data shapers, Spatial locality, Performance optimization, Time and energy },
  url      = {http://www.sciencedirect.com/science/article/pii/S016792601630178X},
}

@Article{Uddin2014529,
  author   = {Irfan Uddin and Raphael Poss and Chris Jesshope},
  title    = {Cache-based high-level simulation of microthreaded many-core architectures},
  journal  = {Journal of Systems Architecture},
  year     = {2014},
  volume   = {60},
  number   = {7},
  pages    = {529 - 552},
  issn     = {1383-7621},
  abstract = {Abstract The accuracy of simulated cycles in high-level simulators is generally less than the accuracy in detailed simulators for a single-core systems, because high-level simulators simulate the behaviour of components rather than the components themselves as in detailed simulators. The simulation problem becomes more challenging when simulating many-core systems, where many cores are executing instructions concurrently. In these systems data may be accessed from multiple caches and the abstraction of the instruction execution has to consider the dynamic resource sharing on the whole chip. The problem becomes even more challenging in microthreaded many-core systems, because there may exist concurrent hardware threads. Which means that the latency of long latency operations can be tolerated from many cycles to just few cycles. We have previously presented a simulation technique to improve the accuracy in high-level simulation of microthreaded many-core systems, known as Signature-based high- level simulator, which adapts the throughput of the program based on the type of instructions, number of instructions and number of active threads in the pipeline. However, it disregards the access to different levels of the caches on the many-core system. Accessing L1-cache has far less latency than accessing off-chip memory and if the core is not able to tolerate latency, different levels of caches can not be treated equally. The distributed cache network along with the synchronization-aware coherency protocol in the Microgrid is a complicated memory architecture and it is difficult to simulate its behaviour at a high-level. In this article we present a high-level cache model, which aims to improve the accuracy in high-level simulators for general-purpose many-core systems by adding little complexity to the simulator and without affecting the simulation speed. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sysarc.2014.05.003},
  keywords = {Distributed cache network, High-level cache modelling, High-level simulation, Many-core systems },
  url      = {http://www.sciencedirect.com/science/article/pii/S1383762114000812},
}

@InCollection{Tratt2009149,
  author    = {Laurence Tratt},
  title     = {Chapter 5 Dynamically Typed Languages},
  publisher = {Elsevier},
  year      = {2009},
  volume    = {77},
  series    = {Advances in Computers},
  pages     = {149 - 184},
  abstract  = {Abstract Dynamically typed languages such as Python and Ruby have experienced a rapid grown in popularity in recent times. However, there is much confusion as to what makes these languages interesting relative to statically typed languages, and little knowledge of their rich history. In this chapter, I explore the general topic of dynamically typed languages, how they differ from statically typed languages, their history, and their defining features. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/S0065-2458(09)01205-4},
  issn      = {0065-2458},
  url       = {http://www.sciencedirect.com/science/article/pii/S0065245809012054},
}

@Article{Susilo200949,
  author   = {E. Susilo and P. Valdastri and A. Menciassi and P. Dario},
  title    = {A miniaturized wireless control platform for robotic capsular endoscopy using advanced pseudokernel approach},
  journal  = {Sensors and Actuators A: Physical},
  year     = {2009},
  volume   = {156},
  number   = {1},
  pages    = {49 - 58},
  issn     = {0924-4247},
  note     = {\{EUROSENSORS\} XXII, 2008},
  abstract = {A ZigBee compliant wireless controller which manages multiple tasks, such as acquiring data from sensors and driving actuators, has been purposely developed for robotic capsular endoscopy applications. Preemptive priority pseudokernel, consisting of state-driven code, coroutine, and pooled-loop algorithm, has been implemented to perform hard, firm and soft real time applications. All the components have been placed on a miniaturized board ready to be integrated in a robotic capsule (max volume of 2 cm3). },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sna.2009.03.036},
  keywords = {Pseudokernel, Real time embedded system, Robotic capsular endoscopy, Wireless miniaturized control board },
  url      = {http://www.sciencedirect.com/science/article/pii/S0924424709001642},
}

@Article{Suri20101780,
  author   = {Neeraj Suri and Arshad Jhumka and Martin Hiller and András Pataricza and Shariful Islam and Constantin Sârbu},
  title    = {A software integration approach for designing and assessing dependable embedded systems},
  journal  = {Journal of Systems and Software},
  year     = {2010},
  volume   = {83},
  number   = {10},
  pages    = {1780 - 1800},
  issn     = {0164-1212},
  abstract = {Embedded systems increasingly entail complex issues of hardware–software (HW–SW) co-design. As the number and range of \{SW\} functional components typically exceed the finite \{HW\} resources, a common approach is that of resource sharing (i.e., the deployment of diverse \{SW\} functionalities onto the same \{HW\} resources). Consequently, to result in a meaningful co-design solution, one needs to factor the issues of processing capability, power, communication bandwidth, precedence relations, real-time deadlines, space, and cost. As \{SW\} functions of diverse criticality (e.g. brake control and infotainment functions) get integrated, an explicit integration requirement need is to carefully plan resource sharing such that faults in low-criticality functions do not affect higher-criticality functions. On this background, the main contribution of this paper is a dependability-driven framework that helps to conduct the integration of \{SW\} components onto \{HW\} resources such that the maintenance of system dependability over integration of diverse criticality components is assured by design. We first develop a clustering strategy for \{SW\} components into Fault Containment Modules (FCMs) such that error propagation via interaction is minimized. Subsequently, the rules of composition for \{FCMs\} with respect to error propagation are developed. To allocate the resulting \{FCMs\} to the existing \{HW\} resources we provide several heuristics, each optimizing particular attributes thereof. Further, a framework for assessing the goodness of the achieved HW–SW composition as a dependable embedded system is presented. Two new techniques for quantifying the goodness of the proposed mappings are introduced by examples, both based on a multi-criteria decision theoretic approach. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jss.2010.04.063},
  keywords = {Embedded systems, Dependability, Software integration, Assessment, Decision theory },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121210001305},
}

@Article{Skyrme20142266,
  author   = {Alexandre Skyrme and Noemi Rodriguez and Roberto Ierusalimschy},
  title    = {A survey of support for structured communication in concurrency control models},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2014},
  volume   = {74},
  number   = {4},
  pages    = {2266 - 2285},
  issn     = {0743-7315},
  abstract = {Abstract The two standard models used for communication in concurrent programs, shared memory and message passing, have been the focus of much debate for a long time. Still, we believe the main issue at stake should not be the choice between these models, but rather how to ensure that communication is structured, i.e., it occurs only in syntactically restricted code regions. In this survey, we explore concurrency control models and evaluate how their characteristics contribute positively or negatively to the support for structured communication. We focus the evaluation on three properties: reasonability, which is the main property we are interested in and determines how easily programmers can reason about a concurrent program’s execution; performance, which determines whether there are any distinct features which can prevent or facilitate efficient implementations; and composability, which determines whether a model offers constructs that can be used as building blocks for coarser-grained, or higher-level, concurrency abstractions. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jpdc.2013.11.005},
  keywords = {Concurrency, Communication, Survey, Model, Structured },
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731513002323},
}

@InCollection{Samek2009255,
  author    = {Miro Samek},
  title     = {Chapter 6 - Real-Time Framework Concepts},
  booktitle = {Practical \{UML\} Statecharts in C/C++ (2nd Edition)},
  publisher = {Newnes},
  year      = {2009},
  editor    = {Samek, Miro},
  pages     = {255 - 306},
  address   = {Burlington},
  edition   = {2nd Edition},
  isbn      = {978-0-7506-8706-5},
  abstract  = {Publisher Summary This chapter introduces the concepts associated with event-driven, real-time application frameworks. A real-time framework can employ a number of various \{CPU\} management policies, so it is important to understand the basic real-time concepts, starting from simple foreground/background systems through cooperative multitasking to fully preemptive multitasking. Traditionally, these execution models have been used with the blocking paradigm. Blocking is that the program which frequently waits for events, either hanging in tight polling loops or getting efficiently blocked by a multitasking kernel. The blocking model is not compatible with the event-driven paradigm, but it can be adapted. The general strategy is to centralize and encapsulate all the blocking code inside the event-driven infrastructure (the framework) so that the application code never blocks. The active object computing model combines multiple traditional event loops with a multitasking environment. In this model, applications are divided into multiple autonomous active objects, each encapsulating an execution thread (event loop), an event queue, and a state machine. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-7506-8706-5.00006-4},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780750687065000064},
}

@Article{Ritson2012727,
  author   = {Carl G. Ritson and Adam T. Sampson and Frederick R.M. Barnes},
  title    = {Multicore scheduling for lightweight communicating processes},
  journal  = {Science of Computer Programming},
  year     = {2012},
  volume   = {77},
  number   = {6},
  pages    = {727 - 740},
  issn     = {0167-6423},
  note     = {(1) Coordination 2009 (2) \{WCRE\} 2009},
  abstract = {Process-oriented programming is a design methodology in which software applications are constructed from communicating concurrent processes. A typical process-oriented design involves the composition of a large number of small isolated component processes. These concurrent components allow for the scalable parallel execution of the resulting application on both shared-memory and distributed-memory architectures. In this paper we present a runtime designed to support process-oriented programming by providing lightweight processes and communication primitives. The runtime’s scheduler, implemented using lock-free algorithms, automatically executes concurrent components in parallel on multicore systems. Heuristics dynamically group processes into cache-affine work units based on communication patterns. Work units are then distributed via wait-free work-stealing. Initial performance analysis shows that, using the algorithms presented in this paper, process-oriented software can execute with an efficiency approaching that of optimised sequential and coarse-grain threaded designs. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.scico.2011.04.006},
  keywords = {Concurrency, Multicore, Process-oriented, Scheduling },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642311001286},
}

@Article{Oz2012160,
  author   = {Isil Oz and Haluk Rahmi Topcuoglu and Mahmut Kandemir and Oguz Tosun},
  title    = {Reliability-aware core partitioning in chip multiprocessors},
  journal  = {Journal of Systems Architecture},
  year     = {2012},
  volume   = {58},
  number   = {3–4},
  pages    = {160 - 176},
  issn     = {1383-7621},
  abstract = {Executing multiple applications concurrently is an important way of utilizing the computational power provided by emerging chip multiprocessor (CMP) architectures. However, this multiprogramming brings a resource management and partitioning problem, for which one can find numerous examples in the literature. Most of the resource partitioning schemes proposed to date focus on performance or energy centric strategies. In contrast, this paper explores reliability-aware core partitioning strategies targeting CMPs. One of our schemes considers both performance and reliability objectives by maximizing a novel combined metric called the vulnerability-delay product (VDP). The vulnerability component in this metric is represented with Thread Vulnerability Factor (TVF), a recently proposed metric for quantifying thread vulnerability for multicores. Execution time of the given application represents the delay component of the \{VDP\} metric. As part of our experimental analysis, proposed core partitioning schemes are compared with respect to normalized weighted speedup, normalized weighted reliability loss and normalized weighted vulnerability delay product gain metrics for various workloads of benchmark applications. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.sysarc.2012.02.005},
  keywords = {Reliability, Thread vulnerability, Multicores, Core partitioning, Reliability-aware computing },
  url      = {http://www.sciencedirect.com/science/article/pii/S1383762112000070},
}

@Article{Lu2013115,
  author   = {Weiyun Lu and Martin Radetzki},
  title    = {Concurrent and comparative fault simulation in SystemC and its application in robustness evaluation},
  journal  = {Microprocessors and Microsystems},
  year     = {2013},
  volume   = {37},
  number   = {2},
  pages    = {115 - 128},
  issn     = {0141-9331},
  note     = {Digital System Safety and Security},
  abstract = {In this work, we present extensions to the SystemC library and automatable model transformations that enable efficient system-level fault simulation in SystemC. The method is based on extended data types which represent variables or signals as lists of values (instead of one value) consisting of a fault free reference value and any number of faulty values each of which corresponds to one fault. We inject faults (variable level faults as well as bit level faults) into objects declared with the extended data types. These faults are then propagated to other objects during SystemC simulation, until either they are classified and dropped or the simulation ends. The extended SystemC simulator is intended for robustness evaluation of digital and embedded designs, for which we propose a condition-oriented quantitative fault model. Speedups of up to 1905 and 10 are achieved for transient faults in digital circuit simulation and for a custom fault model in software algorithm robustness evaluation, respectively. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.micpro.2012.09.005},
  keywords = {SystemC, Fault simulation, Concurrent comparative simulation, Robustness evaluation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0141933112001676},
}

@InCollection{Larsen201467,
  author    = {Steen Larsen and Ben Lee},
  title     = {Chapter Two - Survey on System I/O Hardware Transactions and Impact on Latency, Throughput, and Other Factors},
  publisher = {Elsevier},
  year      = {2014},
  editor    = {Ali Hurson},
  volume    = {92},
  series    = {Advances in Computers},
  pages     = {67 - 104},
  abstract  = {Abstract Computer system input/output (I/O) has evolved with processor and memory technologies in terms of reducing latency, increasing bandwidth, and other factors. As requirements increase for I/O, such as networking, storage, and video, descriptor-based direct memory access (DMA) transactions have become more important in high-performance systems to move data between I/O adapters and system memory buffers. \{DMA\} transactions are done with hardware engines below the software protocol abstraction layers in all systems other than rudimentary embedded controllers. Central processing unit (CPUs) can switch to other tasks by offloading hardware \{DMA\} transfers to the I/O adapters. Each I/O interface has one or more separately instantiated descriptor-based \{DMA\} engines optimized for a given I/O port. I/O transactions are optimized by accelerator functions to reduce latency, improve throughput, and reduce \{CPU\} overhead. This chapter surveys the current state of high-performance I/O architecture advances and explores benefits and limitations. With the proliferation of \{CPU\} multicores within a system, multi-GB/s ports, and on-die integration of system functions, changes beyond the techniques surveyed may be needed for optimal I/O architecture performance. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-420232-0.00002-7},
  issn      = {0065-2458},
  keywords  = {Input/output, Processors, Controllers, Memory, DMA, Latency, Throughput, Power },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124202320000027},
}

@InCollection{Douglass2014225,
  author    = {Bruce Powel Douglass},
  title     = {Chapter 9 - Concurrency and Resource Architecture},
  booktitle = {Real-Time \{UML\} Workshop for Embedded Systems (Second Edition)},
  publisher = {Newnes},
  year      = {2014},
  editor    = {Douglass, Bruce Powel},
  pages     = {225 - 241},
  address   = {Oxford},
  edition   = {Second Edition},
  isbn      = {978-0-12-407781-2},
  abstract  = {Abstract The concurrency architecture identifies the threads of execution, the allocation of software elements to those threads, specifies how the threads will be scheduled, and defines how resources will be shared among them. Concurrency is a key aspect of almost any real-time and embedded system because it so directly influences its performance. This chapter discusses the definition of concurrency architecture in some detail, and provides a workflow for its full specification. Several design patterns are provided to address different issues that arise in multitasking systems. Exercises are provided for modeling the concurrency and resource architecture for the Roadrunner Traffic Light Control System and the Coyote Unmanned Air Vehicle. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-0-12-407781-2.00009-X},
  keywords  = {Concurrency, task, process, resource, thread, utility function, scheduling patterns, cyclic executive, round robin, priority-based preemption, rate monotonic scheduling (RMS), deadline, period, jitter, blocking, execution time, priority, urgency, criticality, mutual exclusion, resource sharing patterns, critical regions, guarded call, message queuing, priority inversion, priority inheritance, race condition, timeliness, schedulability, synchronization patterns, interrupt },
  url       = {http://www.sciencedirect.com/science/article/pii/B978012407781200009X},
}

@InCollection{Douglass2007141,
  author    = {Bruce Powel Douglass},
  title     = {6 - Architectural Design},
  booktitle = {Real Time \{UML\} Workshop for Embedded Systems},
  publisher = {Newnes},
  year      = {2007},
  editor    = {Douglass, Bruce Powel},
  series    = {Embedded Technology},
  pages     = {141 - 177},
  address   = {Burlington},
  isbn      = {978-0-7506-7906-0},
  abstract  = {Publisher Summary In the Harmony process, architecture is defined to be the set of strategic design decisions that specify how the elements in the system are organized and interact. The key terms in the definition are “strategic” and “design.” In the Harmony process, design is all about optimization. The analysis model is driven primarily by the functional requirements of the system, and design is driven by the quality of service requirements and other optimality characteristics collectively known as “design criteria.” An analysis model may be optimized in almost infinitely different ways to achieve different optimization goals. For example, memory usage can be optimized at the expense of worst-case performance, or reusability can be optimized at the expense of development time. The analysis model specifies what must be present for the solution to be correct; design specifies a solution that is optimal against the criticality-weighted set of design criteria. },
  db        = {ScienceDirect},
  doi       = {https://doi.org/10.1016/B978-075067906-0/50009-6},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780750679060500096},
}

@Article{Cicirelli20071817,
  author   = {Franco Cicirelli and Angelo Furfaro and Libero Nigro},
  title    = {Exploiting agents for modelling and simulation of coverage control protocols in large sensor networks},
  journal  = {Journal of Systems and Software},
  year     = {2007},
  volume   = {80},
  number   = {11},
  pages    = {1817 - 1832},
  issn     = {0164-1212},
  abstract = {A sensor network is composed of low-cost, low-power nodes densely deployable over a (possibly in-hospitable) territory in order to monitor the state of the environment, e.g. temperature, sound, radiation and so forth. Sensors have the ability to self-organize into an interconnected network and to cooperate for collecting, aggregating and disseminating information to end users. Major challenges in dealing with sensor networks are the strong limitations imposed by finite onboard power capacity. This paper proposes a lightweight actor infrastructure that is well-suited to modelling and simulation of complex sensor networks and, more in general, of multi-agent systems. This infrastructure is exploited for designing and implementing an efficient actor-based distributed simulation model for studying specific aspects of large wireless sensor networks. The paper proposes and compares the performances of two protocols for the coverage control problem that achieve their objective as an emergent property. In particular, one of the two protocols adopts a novel approach based on an evolutionary game. Distributed simulation of the achieved actor-based models is characterized by good execution performances witnessed by reported experimental results. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jss.2007.02.015},
  keywords = {Multi-agent systems, Actors, Wireless sensor networks, Evolutionary games, Distributed simulation, Java },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121207000647},
}

@Article{Chouliaras2016466,
  author   = {V.A. Chouliaras and D. Stevens and V.M. Dwyer},
  title    = {VThreads: A novel \{VLIW\} chip multiprocessor with hardware-assisted \{PThreads\}},
  journal  = {Microprocessors and Microsystems},
  year     = {2016},
  volume   = {47, Part B},
  pages    = {466 - 485},
  issn     = {0141-9331},
  abstract = {Abstract We discuss VThreads, a novel \{VLIW\} \{CMP\} with hardware-assisted shared-memory Thread support. \{VThreads\} supports Instruction Level Parallelism via static multiple-issue and Thread Level Parallelism via hardware-assisted \{POSIX\} Threads along with extensive customization. It allows the instantiation of tightly-coupled streaming accelerators and supports up to 7-address Multiple-Input, Multiple-Output instruction extensions. \{VThreads\} is designed in technology-independent Register-Transfer-Level \{VHDL\} and prototyped on 40  nm and 28  nm Field-Programmable gate arrays. It was evaluated against a PThreads-based multiprocessor based on the Sparc-V8 ISA. On a 65  nm \{ASIC\} implementation \{VThreads\} achieves up to x7.2 performance increase on synthetic benchmarks, x5 on a parallel Mandelbrot implementation, 66% better on a threaded \{JPEG\} implementation, 79% better on an edge-detection benchmark and ∼13% improvement on \{DES\} compared to the Leon3MP CMP. In the range of 2 to 8 cores, \{VThreads\} demonstrates a post-route (statistical) power reduction between 65% and 57% at an area increase of 1.2%–10% for 1–8 cores, compared to a similarly-configured Leon3MP CMP. This combination of micro-architectural features, scalability, extensibility, hardware support for low-latency PThreads, power efficiency and area make the processor an attractive proposition for low-power, deeply-embedded applications requiring minimum \{OS\} support. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.micpro.2016.07.010},
  keywords = {\{RTL\} implementation, Embedded microprocessors, Hardware/software interface, Configurable \{VLIW\} architectures, Field-programmable gate array design, Standard-cell design },
  url      = {http://www.sciencedirect.com/science/article/pii/S014193311630093X},
}

@Article{Chang201544,
  author   = {Jen-Chieh Chang and Chia-Jung Chen and Rong-Guey Chang},
  title    = {A virtualization approach to develop middleware for ubiquitous high performance computing},
  journal  = {Computers \& Electrical Engineering},
  year     = {2015},
  volume   = {48},
  pages    = {44 - 59},
  issn     = {0045-7906},
  abstract = {Abstract In ubiquitous high-performance computing (UHPC), performing concurrent services is an important task of middleware. Because a major development effort is not easily achieved, isolating a virtual machine (VM) may be a helpful solution but will likely suffer from additional overhead costs. This challenge can also be resolved by reusing the device driver. However, these solutions are difficult to implement without the \{VM\} technique. In this study, we present an alternative approach to minimizing overhead and develop a middleware called userspace virtualized middleware (Uware). Instead of bypassing the VM, the proposed approach depends on userspace transparency and contention management to shift the \{VM\} concept into middleware. We introduce two strategies to enhance the system adaptively: comprehensive restructuring by simplifying the \{VM\} memory mechanism and implementing zero-copy buffers to reuse devices. The result demonstrates that Uware is feasible and could be applied in a broad variety of UHPC. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.compeleceng.2015.09.008},
  keywords = {Middleware, Ubiquitous high performance computing, Virtualization, Concurrency control },
  url      = {http://www.sciencedirect.com/science/article/pii/S0045790615003158},
}

@Article{Bowles2014190,
  author   = {Marcus Bowles and Jianjun Lu},
  title    = {Removing the blinders: A literature review on the potential of nanoscale technologies for the management of supply chains},
  journal  = {Technological Forecasting and Social Change},
  year     = {2014},
  volume   = {82},
  pages    = {190 - 198},
  issn     = {0040-1625},
  abstract = {Abstract Supply chain management requires more intelligent technology in the future; however, the current sensor technology is causing a bottleneck in the development of an intelligent supply chain. The emergence and development of nanosensors provide a good opportunity to improve the complex technical issues that supply chains need and may bring revolutionary changes to supply chains in the future. This paper reviews the current and potential application of nanosensors to every aspect of supply chains, including the \{SCM\} system, packaging, storage and distribution, supply chain safety, tracking and tracing. The particular focus will be on removing the blinders to the true potential technologies on the nanoscale for the future, not just for the management of supply chains but for firms seeking to become more competitive. This review will shed light on the profound impact nanotechnologies could have in augmenting or replacing the existing radiofrequency identification (RFID) tags or bar-code technologies. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.techfore.2013.10.017},
  keywords = {Supply chain management, Smart supply chain, Nanotechnology, Nanosensor, Smartsensor },
  url      = {http://www.sciencedirect.com/science/article/pii/S0040162513002758},
}

@Article{Andersen201796,
  author   = {Michael P. Andersen and Gabe Fierro and David E. Culler},
  title    = {Enabling synergy in IoT: Platform to service and beyond},
  journal  = {Journal of Network and Computer Applications},
  year     = {2017},
  volume   = {81},
  pages    = {96 - 110},
  issn     = {1084-8045},
  abstract = {Abstract To enable a prosperous Internet of Things (IoT), devices and services must be extensible and adapt to changes in the environment or user interaction patterns. These requirements manifest as a set of design principles for each of the layers in an IoT ecosystem, from hardware to cloud services. This paper gives concrete guidelines learned from implementing and deploying a full-stack synergistic IoT platform. We address hardware design concerns and present a reference platform, Firestorm. Upon this platform, we demonstrate firmware and personal-area networking concerns and solutions. Moving out towards larger scales we address local service discovery and syndication, and show how these principles carry through to global operation where security concerns dominate. },
  db       = {ScienceDirect},
  doi      = {https://doi.org/10.1016/j.jnca.2016.10.017},
  keywords = {Internet of Things, Wireless sensor networks, Sensor motes, Middleware, Security, Trust, Embedded operating systems, Publish-subscribe },
  url      = {http://www.sciencedirect.com/science/article/pii/S1084804516302521},
}

@Conference{Zdenek2007,
  author          = {Zdenek, J.},
  title           = {Efficient scheduler-dispatcher software architecture of the spacepower facility distributed control computer},
  year            = {2007},
  note            = {cited By 3},
  abstract        = {The system software architecture of the distributed control computer (computer network) of the mechatronic scientific facility (crystallizer) for automatic high temperature material processing in a orbital space station in micro-gravitation environment is presented in this paper. The scientific facility consists of the multi-zone high temperature furnace with heating system, PWM controlled heating converters, the precise extra low speed vibration-less electric drives to make possible to manipulate the processed material samples during experiments, very precise temperature measurement module, telemetric channel, crew interface computer, free programmable central controller and several further units. Facility computer network nodes have many user tasks (processes) divided into many threads running in real time environment. Using preemptive real time operating system tends to have unacceptable high overhead therefore the system of table driven coroutines with low system resource requirement (overhead, stack space) was designed. Emphasis is given on the design of efficient, reliable and self documented scheduler-dispatcher of the user tasks with minimized overhead and easily extensible descriptors of table driven user finite state automata. Presented scheduler architecture is used in the distributed network control computer of newly designed facility (Advanced TITUS) intended to be placed in the ISS space station. It is advanced version of the proved software utilized in the distributed control computer of the TITUS scientific equipment which was successfully operated several years in the MIR orbital station especially during ESA missions EUROMIR.},
  affiliation     = {Czech Technical University in Prague, Faculty of Electrical Engineering, Technicka 2, 166 27 Prague 6, Czech Republic},
  art_number      = {4417219},
  author_keywords = {Measurement; Mechatronics; Real time processing; Software; Space},
  db              = {Scopus},
  document_type   = {Conference Paper},
  doi             = {10.1109/EPE.2007.4417219},
  journal         = {2007 European Conference on Power Electronics and Applications, EPE},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51049091406&doi=10.1109%2fEPE.2007.4417219&partnerID=40&md5=50231f281f2419efddf4a253dc552647},
}

@Article{Susilo200949,
  author          = {Susilo, E. and Valdastri, P. and Menciassi, A. and Dario, P.},
  title           = {A miniaturized wireless control platform for robotic capsular endoscopy using advanced pseudokernel approach},
  journal         = {Sensors and Actuators, A: Physical},
  year            = {2009},
  volume          = {156},
  number          = {1},
  pages           = {49-58},
  note            = {cited By 25},
  abstract        = {A ZigBee compliant wireless controller which manages multiple tasks, such as acquiring data from sensors and driving actuators, has been purposely developed for robotic capsular endoscopy applications. Preemptive priority pseudokernel, consisting of state-driven code, coroutine, and pooled-loop algorithm, has been implemented to perform hard, firm and soft real time applications. All the components have been placed on a miniaturized board ready to be integrated in a robotic capsule (max volume of 2 cm3). © 2009 Elsevier B.V. All rights reserved.},
  affiliation     = {CRIM Lab, Polo Sant'Anna Valdera, Scuola Superiore Sant'Anna, Pisa, Italy; Italian Institute of Technology Network, Genova, Italy},
  author_keywords = {Pseudokernel; Real time embedded system; Robotic capsular endoscopy; Wireless miniaturized control board},
  db              = {Scopus},
  document_type   = {Article},
  doi             = {10.1016/j.sna.2009.03.036},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71649092073&doi=10.1016%2fj.sna.2009.03.036&partnerID=40&md5=db6cc20670d440d9932bdca50bf6ba0a},
}

@Article{Liu201146,
  author          = {Liu, W. and Xu, J. and Muppala, J.K. and Zhang, W. and Wu, X. and Ye, Y.},
  title           = {Coroutine-based synthesis of efficient embedded software from SystemC models},
  journal         = {IEEE Embedded Systems Letters},
  year            = {2011},
  volume          = {3},
  number          = {1},
  pages           = {46-49},
  note            = {cited By 0},
  abstract        = {SystemC is a widely used electronic system-level (ESL) design language that can be used to model both hardware and software at different stages of system design. There has been a lot of research on behavior synthesis of hardware from SystemC, but relatively little work on synthesizing embedded software for SystemC designs. In this letter, we present an approach to automatic software synthesis from SystemC-based on coroutines instead of the traditional approaches based on real-time operating system (RTOS) threads. Performance evaluation results on some realistic applications show that our approach results in impressive reduction of runtime overheads compared to the thread-based approaches. © 2010 IEEE.},
  affiliation     = {University of Science and Technology, Hong Kong, Hong Kong; School of Computer Engineering, Nanyang Technological University, Singapore, Singapore},
  art_number      = {5710575},
  author_keywords = {Performance; software synthesis; SystemC},
  db              = {Scopus},
  document_type   = {Article},
  doi             = {10.1109/LES.2011.2112634},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953090043&doi=10.1109%2fLES.2011.2112634&partnerID=40&md5=cda7ca81ba1ad7f9b463aef6ea7de23e},
}

@Article{Ierusalimschy20101,
  author        = {Ierusalimschy, R.},
  title         = {Programming with multiple paradigms in Lua},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2010},
  volume        = {5979 LNCS},
  pages         = {1-12},
  note          = {cited By 4},
  abstract      = {Lua is a scripting language used in many industrial applications, with an emphasis on embedded systems and games. Two key points in the design of the language that led to its widely adoption are flexibility and small size. To achieve these two conflicting goals, the design emphasizes the use of few but powerful mechanisms, such as first-class functions, associative arrays, coroutines, and reflexive capabilities. As a consequence of this design, although Lua is primarily a procedural language, it is frequently used in several different programming paradigms, such as functional, object-oriented, goal-oriented, and concurrent programming, and also for data description. In this paper we discuss what mechanisms Lua features to achieve its flexibility and how programmers use them for different paradigms. © 2010 Springer-Verlag.},
  affiliation   = {PUC-Rio, Rio de Janeiro, Brazil},
  db            = {Scopus},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-642-11999-6_1},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951550556&doi=10.1007%2f978-3-642-11999-6_1&partnerID=40&md5=aca0ecd60ebf4826323db2341c697c29},
}

@Conference{Hannig201148,
  author          = {Hannig, F. and Roloff, S. and Snelting, G. and Teich, J. and Zwinkau, A.},
  title           = {Resource-aware programming and simulation of MPSoC architectures through extension of X10},
  year            = {2011},
  pages           = {48-55},
  note            = {cited By 20},
  abstract        = {The efficient use of future MPSoCs with f 000 or more processor cores requires new means of resource-aware programming to deal with increasing imperfections such as process variation, fault rates, aging effects, and power as well as thermal problems. In this paper, we apply a new approach called invasive computing that enables an application programmer to spread computations to processors deliberately and on purpose at certain points of the program. Such decisions can be made depending on the degree of application parallelism and the state of the underlying resources such as utilization, load, and temperature. The introduced programming constructs for resource-aware programming are embedded into the parallel computing language X10 as developed by IBM using a library-based approach. Moreover, we show how individual heterogeneous MPSoC architectures may be modeled for subsequent functional simulation by defining compute resources such as processors themselves by lightweight threads that are executed in parallel together with the application threads by the X10 run-time system. Thus, the state changes of each hardware resource may be simulated including temperature, aging, and other useful monitor functionality to provide a first high-level programming test-bed for invasive computing. Copyright © 2011 ACM.},
  affiliation     = {Hardware/Software Co-Design, Department of Computer Science, University of Erlangen, Nuremberg, Germany; Programming Paradigms Group, Karlsruhe Institute of Technology - KIT, Germany},
  author_keywords = {MPSoC; Resource-aware programming; Simulation; X10},
  db              = {Scopus},
  document_type   = {Conference Paper},
  doi             = {10.1145/1988932.1988941},
  journal         = {Proceedings of the 14th International Workshop on Software and Compilers for Embedded Systems, SCOPES 2011},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051884920&doi=10.1145%2f1988932.1988941&partnerID=40&md5=3d1519478e4656a28a3cdf2d77e7d51c},
}

@Conference{Cohen2007,
  author        = {Cohen, M. and Ponte, T. and Rossetto, S. and Rodríguez, N.},
  title         = {Using coroutines for RPC in sensor networks},
  year          = {2007},
  note          = {cited By 5},
  abstract      = {This paper proposes a concurrency model which integrates the asynchronous and event-driven nature of wireless sensor networks with higher-level abstractions that provide a more familiar programming style for the developer. As a basis for this proposal, we designed and implemented a cooperative multitasking scheduler, based on coroutines, for the TinyOS operating system. We then used this scheduler to implement RPC-like interfaces that capture different communication patterns common in wireless sensor networks. This allows the programmer to work, when appropriate, with a synchronous style, while maintaining an asynchronous model at the message exchange level. © 2007 IEEE.},
  affiliation   = {Departamento de Informática, PUC-Rio, Rua Marques de Sao Vicente, 225, Gavea, Rio de Janeiro, RJ, 22453-900, Brazil},
  art_number    = {4228186},
  db            = {Scopus},
  document_type = {Conference Paper},
  doi           = {10.1109/IPDPS.2007.370458},
  journal       = {Proceedings - 21st International Parallel and Distributed Processing Symposium, IPDPS 2007; Abstracts and CD-ROM},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548749105&doi=10.1109%2fIPDPS.2007.370458&partnerID=40&md5=7266e484e4d1b8ca39259aea33222880},
}

@Conference{Branco20131318,
  author          = {Branco, A. and Moura, A.L.D. and Rodriguez, N. and Rossetto, S.},
  title           = {Teaching concurrent and distributed computing-Initiatives in Rio de Janeiro ;},
  year            = {2013},
  pages           = {1318-1323},
  note            = {cited By 0},
  abstract        = {In this paper we describe two ongoing initiatives for teaching concurrency and distribution in PUC-Rio and UFRJ. One of them is a new approach for teaching distributed systems. Conventional distributed system courses follow a syllabus in which a list of topics is discussed independently and at different levels of abstractions. In Edupar'2012, we proposed a course with a novel approach, using a wireless sensor network environment to pin all topics down to concrete applications and to maintain issues such as fault tolerance and coordination continuously present. The second initiative is a smaller one, in which we insert a new topic in a Systems Software course to allow students to have a better understanding of what is application-level multitasking and of how it can be implemented. In this paper, we report on the experience of teaching the proposed syllabus and the adjustments that were necessary. We also discuss some plans for the courses in 2013. © 2013 IEEE.},
  affiliation     = {Departamento de Inforḿatica, Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Departamento de Cîencia da Computaç ̃ao (DCC), Universidade Federal Do Rio de Janeiro (UFRJ), Rio de Janeiro, Brazil},
  art_number      = {6651023},
  author_keywords = {application-level multitasking; coroutines; cross-cutting approaches; event-based programming; fault tolerance},
  db              = {Scopus},
  document_type   = {Conference Paper},
  doi             = {10.1109/IPDPSW.2013.33},
  journal         = {Proceedings - IEEE 27th International Parallel and Distributed Processing Symposium Workshops and PhD Forum, IPDPSW 2013},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899759671&doi=10.1109%2fIPDPSW.2013.33&partnerID=40&md5=405fa61faee5d09dd9b12b335e0d43c7},
}

@InBook{Colnarič2008,
  pages     = {107--163},
  title     = {Programming of Embedded Systems},
  publisher = {Springer London},
  year      = {2008},
  address   = {London},
  isbn      = {978-1-84800-052-0},
  abstract  = {Similar to the development in other domains of embedded systems, in practice control applications are often programmed by improper means. For a number of pragmatic reasons, the same methods, techniques, and programming languages as for general-purpose desktop applications are employed. One of the reasons for this is common knowledge of programming: the languages and methods learned can do the job to a certain extent, so most practitioners use them with little concern about the rather specific circumstances of embedded systems},
  booktitle = {Distributed Embedded Control Systems: Improving Dependability with Coherent Design},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-84800-052-0_4},
  url       = {https://doi.org/10.1007/978-1-84800-052-0_4},
}

@InBook{Wang2012,
  pages     = {381--386},
  title     = {Porting Contiki Operating System to RIEST2430},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Wang, Juan and Ma, Wei and Liu, Dan},
  editor    = {Huang, De-Shuang and Gupta, Phalguni and Zhang, Xiang and Premaratne, Prashan},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-31837-5},
  abstract  = {Based on the analysis of the structure and elements of Contiki embedded real-time operating system, this paper presents the experience with implementing the transplantation of Contiki to the CC2430-based and low-power RIEST2430 platform. Lastly, we test the function of the porting modules. The test results show that all modules work correctly.},
  booktitle = {Emerging Intelligent Computing Technology and Applications: 8th International Conference, ICIC 2012, Huangshan, China, July 25-29, 2012. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-31837-5_55},
  url       = {https://doi.org/10.1007/978-3-642-31837-5_55},
}

@Article{Voelter2013,
  author   = {Voelter, Markus and Ratiu, Daniel and Kolb, Bernd and Schaetz, Bernhard},
  title    = {mbeddr: instantiating a language workbench in the embedded software domain},
  journal  = {Automated Software Engineering},
  year     = {2013},
  volume   = {20},
  number   = {3},
  pages    = {339--390},
  month    = {Sep},
  issn     = {1573-7535},
  abstract = {Tools can boost software developer productivity, but building custom tools is prohibitively expensive, especially for small organizations. For example, embedded programmers often have to use low-level C with limited IDE support, and integrated into an off-the-shelf tool chain in an ad-hoc way.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10515-013-0120-4},
  url      = {https://doi.org/10.1007/s10515-013-0120-4},
}

@InBook{Varghese2015,
  pages     = {1--14},
  title     = {Getting Started with Go},
  publisher = {Apress},
  year      = {2015},
  author    = {Varghese, Shiju},
  address   = {Berkeley, CA},
  isbn      = {978-1-4842-1052-9},
  abstract  = {Everything in this world is evolving, including computers and computer programming languages. Ideas and approaches for building applications are also evolving, based on past experience. Although highly evolved modern computers now have many CPU cores (32, 64, 128 and many more), we still cannot leverage the full power of modern computer hardware by using most of our existing programming languages and tools. Our programs still run slowly, even in high-powered servers with many CPU cores.},
  booktitle = {Web Development with Go: Building Scalable Web Apps and RESTful Services},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4842-1052-9_1},
  url       = {https://doi.org/10.1007/978-1-4842-1052-9_1},
}

@InBook{Varga2010,
  pages     = {35--59},
  title     = {OMNeT++},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Varga, Andras},
  editor    = {Wehrle, Klaus and G{\"u}ne{\c{s}}, Mesut and Gross, James},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-12331-3},
  abstract  = {OMNeT++ (                                  www.omnetpp.org                                              ) is an extensible, modular, component-based C++ simulation library and framework which also includes an integrated development and a graphical runtime environment. Domain-specific functionality (support for simulation of communication networks, queuing networks, performance evaluation, etc.) is provided by model frameworks, developed as independent projects. There are extensions for real-time simulation, network emulation, support for alternative programming languages (Java, C{\#}), database integration, SystemC integration, HLA and several other functions.},
  booktitle = {Modeling and Tools for Network Simulation},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-12331-3_3},
  url       = {https://doi.org/10.1007/978-3-642-12331-3_3},
}

@InBook{Vajda2011,
  pages     = {153--173},
  title     = {Introduction to Programming Models},
  publisher = {Springer US},
  year      = {2011},
  author    = {Vajda, Andr{\'a}s},
  address   = {Boston, MA},
  isbn      = {978-1-4419-9739-5},
  abstract  = {In this chapter we introduce the foundations for the programming models we consider most suitable for programming many-core chips: communicating sequential processes (CSP), the Actor model and the task based model. For each of these, we shortly survey and compare the most commonly available programming language implementations: the goal is to lay the groundwork for the more in-depth analysis and presentation in the next chapter. An important part of the chapter will deal with the comparative analysis of thread/process based and task based parallelism, as well as an analysis of shared memory based models.},
  booktitle = {Programming Many-Core Chips},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4419-9739-5_8},
  url       = {https://doi.org/10.1007/978-1-4419-9739-5_8},
}

@Article{Stypka2017,
  author   = {Stypka, Jan and Turek, Wojciech and Byrski, Aleksander and Kisiel-Dorohinicki, Marek and Barwell, Adam D. and Brown, Christopher and Hammond, Kevin and Janjic, Vladimir},
  title    = {The Missing Link! A New Skeleton for Evolutionary Multi-agent Systems in Erlang},
  journal  = {International Journal of Parallel Programming},
  year     = {2017},
  month    = {Apr},
  issn     = {1573-7640},
  abstract = {Evolutionary multi-agent systems (EMAS) play a critical role in many artificial intelligence applications that are in use today. In this paper, we present a new generic skeleton in Erlang for parallel EMAS computations. The skeleton enables us to capture a wide variety of concrete evolutionary computations that can exploit the same underlying parallel implementation. We demonstrate the use of our skeleton on two different evolutionary computing applications: (1) computing the minimum of the Rastrigin function; and (2) solving an urban traffic optimisation problem. We show that we can obtain very good speedups (up to 142.44                                                                  {\$}{\$}{\backslash}times {\$}{\$}                                                      {\texttimes}                                                 the sequential performance) on a variety of different parallel hardware, while requiring very little parallelisation effort.},
  day      = {26},
  db       = {SpringerLink},
  doi      = {10.1007/s10766-017-0503-4},
  url      = {https://doi.org/10.1007/s10766-017-0503-4},
}

@InBook{Strübe2010,
  pages     = {63--76},
  title     = {Stateful Mobile Modules for Sensor Networks},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Str{\"u}be, Moritz and Kapitza, R{\"u}diger and Stengel, Klaus and Daum, Michael and Dressler, Falko},
  editor    = {Rajaraman, Rajmohan and Moscibroda, Thomas and Dunkels, Adam and Scaglione, Anna},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-13651-1},
  abstract  = {Most sensor network applications are dominated by the acquisition of sensor values. Due to energy limitations and high energy costs of communication, in-network processing has been proposed as a means to reduce data transfers. As application demands may change over time and nodes run low on energy, get overloaded, or simply face debasing communication capabilities, runtime adaptation is required. In either case, it is useful to be able to migrate computations between neighboring nodes without losing runtime state that might be costly or even impossible to recompute. We propose stateful mobile modules as a basic infrastructure building block to improve adaptiveness and robustness of in-network processing applications. Stateful mobile modules are binary modules linked on the node itself. Even more importantly, they can be transparently migrated from one node to another, thereby keeping statically as well as dynamically allocated memory. This is achieved by an optimized binary format, a memory-efficient linking process and an advanced programming support.},
  booktitle = {Distributed Computing in Sensor Systems: 6th IEEE International Conference, DCOSS 2010, Santa Barbara, CA, USA, June 21-23, 2010. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-13651-1_5},
  url       = {https://doi.org/10.1007/978-3-642-13651-1_5},
}

@InBook{St-Amour2010,
  pages     = {1--17},
  title     = {PICOBIT: A Compact Scheme System for Microcontrollers},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {St-Amour, Vincent and Feeley, Marc},
  editor    = {Moraz{\'a}n, Marco T. and Scholz, Sven-Bodo},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-16478-1},
  abstract  = {Due to their tight memory constraints, small microcontroller based embedded systems have traditionally been implemented using low-level languages. This paper shows that the Scheme programming language can also be used for such applications, with less than 7 kB of total memory. We present PICOBIT, a very compact implementation of Scheme suitable for memory constrained embedded systems. To achieve a compact system we have tackled the space issue in three ways: the design of a Scheme compiler generating compact bytecode, a small virtual machine, and an optimizing C compiler suited to the compilation of the virtual machine.},
  booktitle = {Implementation and Application of Functional Languages: 21st International Symposium, IFL 2009, South Orange, NJ, USA, September 23-25, 2009, Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-16478-1_1},
  url       = {https://doi.org/10.1007/978-3-642-16478-1_1},
}

@Article{Sprinkle2011,
  author   = {Sprinkle, Jonathan and Eames, Brandon},
  title    = {Time-triggered buffers for event-based middleware systems},
  journal  = {Innovations in Systems and Software Engineering},
  year     = {2011},
  volume   = {7},
  number   = {1},
  pages    = {9--22},
  month    = {Mar},
  issn     = {1614-5054},
  abstract = {Application developers utilizing event-based middleware have sought to leverage domain-specific modeling for the advantages of intuitive specification, code synthesis, and support for design evolution. For legacy and cyber-physical systems, the use of event-based middleware may mean that changes in computational platform can result anomalous system behavior, due to the presence of implicit temporal dependencies. These anomalies are a function not of the component implementation, but of the model of computation employed for supporting system composition. In order to address these behavioral anomalies, the paper presents an approach where time-based blocks are inserted into the system to account for the temporal dependencies. An advantage of capturing the system composition in a domain-specific modeling language is the ability to efficiently refactor an application to include time-triggered, event-based schedulers. This paper describes how an existing event-based component topology can be modified to permit a time-triggered model of computation, with no changes to the existing component software. Further, the time-triggered components can be deployed alongside standard publish/subscribe methodologies. This strategy is beneficial to the maintenance of existing legacy systems upon upgrade, since the current operational mode could be maintained with minimal changes to the legacy software even under changes to the target platform which alter execution speed. These time-triggered layers are discussed in three permutations: fully triggered, start triggered, and release triggered. A discussion is provided regarding the limitations of each approach, and a brief example is given. The example shows how to apply these triggering approaches without the modification of existing components, but instead through the insertion of triggered buffers between legacy components.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s11334-010-0139-7},
  url      = {https://doi.org/10.1007/s11334-010-0139-7},
}

@InBook{Smith2010,
  pages     = {189--248},
  title     = {Game Development with Unity},
  publisher = {Apress},
  year      = {2010},
  author    = {Smith, Ben Britten},
  address   = {Berkeley, CA},
  isbn      = {978-1-4302-2923-0},
  abstract  = {Most of us have built our own game engine in one form or another. If you are a programmer and you build games, then it is like a rite of passage. I have done it. In fact, I have done it a few times. 2D-game engines based on Core Animation, both 2D and 3D engines based on OpenGL and OpenGL ES, the list goes on. I love making my own engines. They do exactly what I need them to do, no more and no less. The downsides: it takes a long time to write your own engine and unless you make the exact same kinds of games over and over again, you will be spending a long time adding features to your engines to match your new game designs. It is often hard to see this happening to yourself because writing game engines is fun!},
  booktitle = {More iPhone Cool Projects: Cool Developers Reveal the Details of Their Cooler Apps and Discuss Their iPad Development Experiences},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4302-2923-0_7},
  url       = {https://doi.org/10.1007/978-1-4302-2923-0_7},
}

@InBook{Shaver2012,
  pages     = {319--334},
  title     = {The Coroutine Model of Computation},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Shaver, Chris and Lee, Edward A.},
  editor    = {France, Robert B. and Kazmeier, J{\"u}rgen and Breu, Ruth and Atkinson, Colin},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-33666-9},
  abstract  = {This paper presents a general denotational formalism called the Coroutine Model of Computation for control-oriented computational models. This formalism characterizes atomic elements with control behavior as Continuation Actors, giving them a static semantics with a functional interface. Coroutine Models are then defined as networks of Continuation Actors, representing a set of control locations between which control traverses during execution. This paper gives both a strict and non-strict denotational semantics for Coroutine Models in terms of compositions of Continuation Actors and their interfaces. In the strict form, the traversal of control locations forms a control path producing output values, whereas in the non-strict form, execution traverses a tree of potential control locations producing partial information about output values. Furthermore, the given non-strict form of these semantics is claimed to have useful monotonicity properties.},
  booktitle = {Model Driven Engineering Languages and Systems: 15th International Conference, MODELS 2012, Innsbruck, Austria, September 30--October 5, 2012. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-33666-9_21},
  url       = {https://doi.org/10.1007/978-3-642-33666-9_21},
}

@InBook{SenthilBabu2014,
  pages     = {607--615},
  title     = {Energy Model for the Configured MSP430F1612 on a TELOSB Mote with the Help of Contiki},
  publisher = {Springer India},
  year      = {2014},
  author    = {Senthil Babu, K. and Virupaksha, Darshan and Mudgal, Shachi P. and Nagaraja, C.},
  editor    = {Sridhar, V. and Sheshadri, Holalu Seenappa and Padma, M C},
  address   = {New Delhi},
  isbn      = {978-81-322-1157-0},
  abstract  = {Wireless sensor networks (WSN) are attracting a wide range of application because of its exponential growth in its performance. However, there are certain drawbacks with respect to the power available in the node. In this paper, we present a hardware configuration of TelosB mote with the help of Contiki OS which improves the performance of the mote by supporting with additional inbuilt flash memory. The paper includes the energy calculation of the new hardware configured. The existing hardware MSP430F1611 provides 48 kB of flash memory which is replaced by MSP430F1612, and Contiki is one such OS which is specifically designed for WSN. In order to provide more flexibility to the application developer, requires of Contiki on a TelosB mote. Contiki support for this modified TELOSB is not available, thereby making an attempt to understand Contiki and port to the modified TELOSB.},
  booktitle = {Emerging Research in Electronics, Computer Science and Technology: Proceedings of International Conference, ICERECT 2012},
  db        = {SpringerLink},
  doi       = {10.1007/978-81-322-1157-0_63},
  url       = {https://doi.org/10.1007/978-81-322-1157-0_63},
}

@Article{Schröder-Preikschat2007,
  author   = {Schr{\"o}der-Preikschat, Wolfgang and Lohmann, Daniel and Scheler, Fabian and Spinczyk, Olaf},
  title    = {Dimensions of variability in embedded operating systems},
  journal  = {Informatik - Forschung und Entwicklung},
  year     = {2007},
  volume   = {22},
  number   = {1},
  pages    = {5--22},
  month    = {Dec},
  issn     = {0949-2925},
  abstract = {Design, implementation, and re-engineering of operating systems are still an ambitious undertaking. Despite, or even because, of the long history of theory and practice in this field, adapting existing systems to environments of different conditions and requirements as originally specified or assumed, in terms of functional and/or non-functional respects, is anything but simple. Especially this is true for the embedded systems domain which, on the one hand, calls for highly specialized and application-aware system abstractions and, on the other hand, cares a great deal for easily reusable implementations of these abstractions. The latter aspect becomes more and more important as embedded systems technology is faced with an innovation cycle decreasing in length. Software for embedded systems needs to be designed for variability, and this is in particular true for the operating systems of this domain. The paper discusses dimensions of variability that need to be considered in the development of embedded operating systems and presents approaches that aid construction and maintenance of evolutionary operating systems.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s00450-007-0037-x},
  url      = {https://doi.org/10.1007/s00450-007-0037-x},
}

@Article{Posse2016,
  author   = {Posse, Ernesto and Dingel, Juergen},
  title    = {An executable formal semantics for UML-RT},
  journal  = {Software {\&} Systems Modeling},
  year     = {2016},
  volume   = {15},
  number   = {1},
  pages    = {179--217},
  month    = {Feb},
  issn     = {1619-1374},
  abstract = {We propose a formal semantics for UML-RT, a UML profile for real-time and embedded systems. The formal semantics is given by mapping UML-RT models into a language called kiltera, a real-time extension of the                                                                           {\$}{\$}{\backslash}pi {\$}{\$}                                                            $\pi$                                                      -calculus. Previous attempts to formalize the semantics of UML-RT have fallen short by considering only a very small subset of the language and providing fundamentally incomplete semantics based on incorrect assumptions, such as a one-to-one correspondence between ``capsules'' and threads. Our semantics is novel in several ways: (1) it deals with both state machine diagrams and capsule diagrams; (2) it deals with aspects of UML-RT that have not been formalized before, such as thread allocation, service provision points, and service access points; (3) it supports an action language; and (4) the translation has been implemented in the form of a transformation from UML-RT models created with IBM's RSA-RTE tool, into kiltera code. To our knowledge, this is the most comprehensive formal semantics for UML-RT to date.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10270-014-0399-z},
  url      = {https://doi.org/10.1007/s10270-014-0399-z},
}

@InBook{Polishchuk2008,
  pages     = {141--150},
  title     = {Optimal Backlog in the Plane},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  author    = {Polishchuk, Valentin and Suomela, Jukka},
  editor    = {Fekete, S{\'a}ndor P.},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-92862-1},
  abstract  = {Suppose that a cup is installed at every point of a planar set P, and that somebody pours water into the cups. The total rate at which the water flows into the cups is 1. A player moves in the plane with unit speed, emptying the cups. At any time, the player sees how much water there is in every cup. The player has no information on how the water will be poured into the cups in the future; in particular, the pouring may depend on the player's motion. The backlog of the player is the maximum amount of water in any cup at any time, and the player's objective is to minimise the backlog. Let D be the diameter of P. If the water is poured at the rate of 1/2 into the cups at the ends of a diameter, the backlog is $\Omega$(D). We show that there is a strategy for the player that guarantees the backlog of O(D), matching the lower bound up to a multiplicative constant. Note that our guarantee is independent of the number of the cups.},
  booktitle = {Algorithmic Aspects of Wireless Sensor Networks: Fourth International Workshop, ALGOSENSORS 2008, Reykjavik, Iceland, July 2008. Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-540-92862-1_12},
  url       = {https://doi.org/10.1007/978-3-540-92862-1_12},
}

@Article{Paul2013,
  author   = {Paul, Bastien and Marcombes, S{\'e}verin and David, Alexandre and Andreasen Struijk, Lotte N. S. and Le Moullec, Yannick},
  title    = {A Context-Aware User Interface for Wireless Personal-Area Network Assistive Environments},
  journal  = {Wireless Personal Communications},
  year     = {2013},
  volume   = {69},
  number   = {1},
  pages    = {427--447},
  month    = {Mar},
  issn     = {1572-834X},
  abstract = {The daily life of people with severe motor system impairments is challenging and thus often subordinated to extensive external help; increasing their level of self-support is thus highly desirable. Recent advances in wireless communications, in particular in wireless personal-area networks, serve as technological enablers well suited for implementing smart and convenient assistive environments which can increase self-support. This paper presents the design and prototyping of a versatile interface for such wireless assistive environments. We propose a modular framework that can accommodate several wireless personal-area network standards. The interface is built upon this framework and is designed in such a way that it can be controlled by various types of input devices such as a touch screen or a tongue-control unit. The interface can automatically discover consumer appliances (e.g. Zigbee and Bluetooth enabled lights and computers) in the user's environment and display the services supported by these devices on a user-friendly graphical user interface. A demonstrator is prototyped and experimental results show that the proposed interface is context-aware, i.e. it successfully detects available appliances, adapts itself to the changes that occur in the user's environment, and automatically informs the user about these changes. The results also show that the proposed interface is versatile and easy to use, i.e. the user can easily control multiple devices by means of a browser menu. Hence, the proposed work illustrates how assistive technology based on wireless personal-area networks can contribute to improving the quality of life of motor system impaired persons.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s11277-012-0582-x},
  url      = {https://doi.org/10.1007/s11277-012-0582-x},
}

@InBook{Parizek2009,
  pages     = {117--132},
  title     = {Platform-Specific Restrictions on Concurrency in Model Checking of Java Programs},
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  author    = {Parizek, Pavel and Kalibera, Tomas},
  editor    = {Alpuente, Mar{\'i}a and Cook, Byron and Joubert, Christophe},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-04570-7},
  abstract  = {The main limitation of software model checking is that, due to state explosion, it does not scale to real-world multi-threaded programs. One of the reasons is that current software model checkers adhere to full semantics of programming languages, which are based on very permissive models of concurrency. Current runtime platforms for programs, however, restrict concurrency in various ways --- it is visible especially in the case of critical embedded systems, which typically involve only a single processor and use a threading model based on limited preemption.},
  booktitle = {Formal Methods for Industrial Critical Systems: 14th International Workshop, FMICS 2009, Eindhoven, The Netherlands, November 2-3, 2009. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-04570-7_10},
  url       = {https://doi.org/10.1007/978-3-642-04570-7_10},
}

@InBook{Ostrowski2010,
  pages     = {452--477},
  title     = {Self-Replicating Objects for Multicore Platforms},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Ostrowski, Krzysztof and Sakoda, Chuck and Birman, Ken},
  editor    = {D'Hondt, Theo},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-14107-2},
  abstract  = {The paper introduces Self-Replicating Objects (SROs), a new concurrent programming abstraction. An SRO is implemented and used much like an ordinary .NET object and can expose arbitrary user-defined APIs, but it is aggressive about automatically exploiting multicore CPUs. It does so by spontaneously and transparently partitioning its state into a set of replicas that handle method calls in parallel and automatically merging replicas before processing calls that cannot execute in the replicated state. Developers need not be concerned about protecting access to shared data; each replica is a monitor and has its own state. The runtime ensures proper synchronization, scheduling, decides when to split/merge, and can transparently migrate replicas to other processes to decrease contention. Compared to threads/locks or toolkits such as .NET Parallel Extensions, SROs offer a simpler, more versatile programming model while delivering comparable, and in some cases even higher performance.},
  booktitle = {ECOOP 2010 -- Object-Oriented Programming: 24th European Conference, Maribor, Slovenia, June 21-25, 2010. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-14107-2_22},
  url       = {https://doi.org/10.1007/978-3-642-14107-2_22},
}

@InBook{Nobakht2014,
  pages     = {37--53},
  title     = {Programming with Actors in Java 8},
  publisher = {Springer Berlin Heidelberg},
  year      = {2014},
  author    = {Nobakht, Behrooz and de Boer, Frank S.},
  editor    = {Margaria, Tiziana and Steffen, Bernhard},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-662-45231-8},
  abstract  = {There exist numerous languages and frameworks that support an implementation of a variety of actor-based programming models in Java using concurrency utilities and threads. Java 8 is released with fundamental new features: lambda expressions and further dynamic invocation support. We show in this paper that such features in Java 8 allow for a high-level actor-based methodology for programming distributed systems which supports the programming to interfaces discipline. The embedding of our actor-based Java API is shallow in the sense that it abstracts from the actual thread-based deployment models. We further discuss different concurrent execution and thread-based deployment models and an extension of the API for its actual parallel and distributed implementation. We present briefly the results of a set of experiments which provide evidence of the potential impact of lambda expressions in Java 8 regarding the adoption of the actor concurrency model in large-scale distributed applications.},
  booktitle = {Leveraging Applications of Formal Methods, Verification and Validation. Specialized Techniques and Applications: 6th International Symposium, ISoLA 2014, Imperial, Corfu, Greece, October 8-11, 2014, Proceedings, Part II},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-662-45231-8_4},
  url       = {https://doi.org/10.1007/978-3-662-45231-8_4},
}

@InBook{Nishimori2012,
  pages     = {119--138},
  title     = {Join Token-Based Event Handling: A Comprehensive Framework for Game Programming},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Nishimori, Taketoshi and Kuno, Yasushi},
  editor    = {Sloane, Anthony and A{\ss}mann, Uwe},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-28830-2},
  abstract  = {In action game programming, programmers have to control multiple concurrent activities on the screen corresponding to multiple game characters. To address this difficulty, many game-oriented scripting languages have been proposed so far. However, current scripting languages seem to lack support for interactions among multiple concurrent activities in a state-dependent manner. To overcome this problem, we propose an event handling framework called ``join token'' in which the states of game characters can be expressed as tokens and interactions can be described as handlers specifying multiple tokens. For the purpose of evaluation, we have developed a game scripting language called ``Mogemoge,'' and wrote several sample games in this language. In this paper, we describe experiences of using join token framework for sample games and compare the code written in Mogemoge against a code written in an existing scripting language.},
  booktitle = {Software Language Engineering: 4th International Conference, SLE 2011, Braga, Portugal, July 3-4, 2011, Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-28830-2_7},
  url       = {https://doi.org/10.1007/978-3-642-28830-2_7},
}

@InBook{Niebert2014,
  pages     = {11--22},
  title     = {Cellular Programming},
  publisher = {Springer International Publishing},
  year      = {2014},
  author    = {Niebert, Peter and Caralp, Mathieu},
  editor    = {Dediu, Adrian-Horia and Lozano, Manuel and Mart{\'i}n-Vide, Carlos},
  address   = {Cham},
  isbn      = {978-3-319-13749-0},
  abstract  = {We present a design approach for ``smart surfaces'' inspired by cellular automata. The aim is to construct and to program scalable distributed realtime interactive systems composed of inexpensive microcontrollers to build surfaces that interact physically with their environment. Our work is both pragmatic and integrated: it covers the entire chain from hardware considerations, a programming model based on a networked locally synchronous virtual machine, dedicated programming language features, a distributed embedded implementation and an integrated programming environment with a simulator implementation of the locally synchronous virtual machine.},
  booktitle = {Theory and Practice of Natural Computing: Third International Conference, TPNC 2014, Granada, Spain, December 9-11, 2014. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-13749-0_2},
  url       = {https://doi.org/10.1007/978-3-319-13749-0_2},
}

@InBook{Neuendorffer2008,
  pages     = {147--156},
  title     = {Streaming Systems in FPGAs},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  author    = {Neuendorffer, Stephen and Vissers, Kees},
  editor    = {Berekovi{\'{c}}, Mladen and Dimopoulos, Nikitas and Wong, Stephan},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-70550-5},
  abstract  = {As FPGA devices have become larger and more capable, they have transitioned from being used primarily as flexible glue logic to being used as central data processing elements in many digital systems. Typically, these systems (including video processing, wired and wireless networking) rely on streaming architectures. These architectures differ significantly from traditional processor architectures and are able to offer unique challenges and benefits for system designers. In particular, streaming architectures in FPGAs are well suited for implementing upcoming digital convergence applications. We summarize how streaming architectures in FPGAs relate to other programmable platforms for embedded applications and focus on key problem areas related to the design tools and platform infrastructure that will drive these new applications.},
  booktitle = {Embedded Computer Systems: Architectures, Modeling, and Simulation: 8th International Workshop, SAMOS 2008, Samos, Greece, July 21-24, 2008. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-540-70550-5_17},
  url       = {https://doi.org/10.1007/978-3-540-70550-5_17},
}

@InBook{Negele2017,
  pages     = {22--45},
  title     = {On the Design and Implementation of an Efficient Lock-Free Scheduler},
  publisher = {Springer International Publishing},
  year      = {2017},
  author    = {Negele, Florian and Friedrich, Felix and Oh, Suwon and Egger, Bernhard},
  editor    = {Desai, Narayan and Cirne, Walfredo},
  address   = {Cham},
  isbn      = {978-3-319-61756-5},
  abstract  = {Schedulers for symmetric multiprocessing (SMP) machines use sophisticated algorithms to schedule processes onto the available processor cores. Hardware-dependent code and the use of locks to protect shared data structures from simultaneous access lead to poor portability, the difficulty to prove correctness, and a myriad of problems associated with locking such as limiting the available parallelism, deadlocks, starvation, interrupt handling, and so on. In this work we explore what can be achieved in terms of portability and simplicity in an SMP scheduler that achieves similar performance to state-of-the-art schedulers. By strictly limiting ourselves to only lock-free data structures in the scheduler, the problems associated with locking vanish altogether. We show that by employing implicit cooperative scheduling, additional guarantees can be made that allow novel and very efficient implementations of memory-efficient unbounded lock-free queues. Cooperative multitasking has the additional benefit that it provides an extensive hardware independence. It even allows the scheduler to be used as a runtime library for applications running on top of standard operating systems. In a comparison against Windows Server and Linux running on up to 64 cores we analyze the performance of the lock-free scheduler and show that it matches or even outperforms the performance of these two state-of-the-art schedulers in a variety of benchmarks.},
  booktitle = {Job Scheduling Strategies for Parallel Processing: 19th and 20th International Workshops, JSSPP 2015, Hyderabad, India, May 26, 2015 and JSSPP 2016, Chicago, IL, USA, May 27, 2016, Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-61756-5_2},
  url       = {https://doi.org/10.1007/978-3-319-61756-5_2},
}

@Article{Motika2015,
  author   = {Motika, Christian and von Hanxleden, Reinhard},
  title    = {Light-weight Synchronous Java (SJL): An approach for programming deterministic reactive systems with Java},
  journal  = {Computing},
  year     = {2015},
  volume   = {97},
  number   = {3},
  pages    = {281--307},
  month    = {Mar},
  issn     = {1436-5057},
  abstract = {A key issue in the development of reliable embedded software is the proper handling of reactive control-flow, which typically involves concurrency. Java and its thread concept have only limited provisions for implementing deterministic concurrency. Thus, as has been observed in the past, it is challenging to develop concurrent Java programs without any deadlocks or race conditions. To alleviate this situation, the Light-weight Synchronous Java (SJL) approach presented here adopts the key concepts that have been established in the world of synchronous programming for handling reactive control-flow. Thus SJL not only provides deterministic concurrency, but also different variants of deterministic preemption. Furthermore SJL allows concurrent threads to communicate with Esterel-style signals. As a case study for an embedded system usage, we also report on how the SJL concepts have been ported to the ARM-based Lego Mindstorms NXT system. We evaluated the SJL approach to be efficient and provide experimental results comparing it to Java threads.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s00607-014-0416-7},
  url      = {https://doi.org/10.1007/s00607-014-0416-7},
}

@InBook{Martorella2014,
  pages     = {121--133},
  title     = {Hardware and Software Platforms for Distributed Computing on Resource Constrained Devices},
  publisher = {Springer International Publishing},
  year      = {2014},
  author    = {Martorella, Gloria and Peri, Daniele and Toscano, Elena},
  editor    = {Gaglio, Salvatore and Lo Re, Giuseppe},
  address   = {Cham},
  isbn      = {978-3-319-03992-3},
  abstract  = {The basic idea of distributed computing is that it is possible to solve a large problem by using the resources of various computing devices connected in a network. Each device interacts with each other in order to process a part of a problem, contributing to the achievement of a global solution. Wireless sensor networks (WSNs) are an example of distributed computing on low resources devices. WSNs encountered a considerable success in many application areas. Due to the constraints related to the small sensor nodes capabilities, distributed computing in WSNs allows to perform complex tasks in a collaborative way, reducing power consumption and increasing battery life. Many hardware platforms compose the ecosystem of WSNs and some lightweight operating systems have also been designed to ease application deployment, to ensure efficient resources management, and to decrease energy consumption. In this chapter we focus on distributed computing from several points of view emphasizing important aspects, ranging from hardware platforms to applications on resource constrained devices.},
  booktitle = {Advances onto the Internet of Things: How Ontologies Make the Internet of Things Meaningful},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-03992-3_9},
  url       = {https://doi.org/10.1007/978-3-319-03992-3_9},
}

@InBook{Martins2014,
  pages     = {244--260},
  title     = {A Web Portal for the Certification of Open Source Software},
  publisher = {Springer Berlin Heidelberg},
  year      = {2014},
  author    = {Martins, Pedro and Fernandes, Jo{\~a}o P. and Saraiva, Jo{\~a}o},
  editor    = {Cerone, Antonio and Persico, Donatella and Fernandes, Sara and Garcia-Perez, Alexeis and Katsaros, Panagiotis and Shaikh, Siraj Ahmed and Stamelos, Ioannis},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-54338-8},
  abstract  = {This paper presents a web portal for the certification of open source software. The portal aims at helping programmers in the internet age, when there are (too) many open source reusable libraries and tools available. Our portal offers programmers a web-based and easy setting to analyze and certify open source software, which is a crucial step to help programmers choosing among many available alternatives, and to get some guarantees before using one piece of software.},
  booktitle = {Information Technology and Open Source: Applications for Education, Innovation, and Sustainability: SEFM 2012 Satellite Events, InSuEdu, MoKMaSD, and OpenCert Thessaloniki, Greece, October 1--2, 2012 Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-54338-8_20},
  url       = {https://doi.org/10.1007/978-3-642-54338-8_20},
}

@InBook{Marròn2011,
  pages     = {19--124},
  title     = {State of the Art in Cooperating Objects Research},
  publisher = {Springer Berlin Heidelberg},
  year      = {2011},
  author    = {Marr{\`o}n, Pedro Jos{\'e} and Karnouskos, Stamatis and Minder, Daniel and Ollero, An{\'i}bal},
  editor    = {Marron, Pedro Jos{\'e} and Karnouskos, Stamatis and Minder, Daniel and Ollero, An{\'i}bal},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-16946-5},
  abstract  = {This chapter provides an overview of the State of the Art in Cooperating Object research and, thus, serves as basis for subsequent examinations of the research gaps. Although it tries to give a broad overview of Cooperating Object research it does not cover aspects that seem to be solved from the point of view of academic or industrial research. Having this in mind, we present the State of the Art in hardware, algorithms, non-functional properties, systems and other aspects of Cooperating Objects.},
  booktitle = {The Emerging Domain of Cooperating Objects},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-16946-5_3},
  url       = {https://doi.org/10.1007/978-3-642-16946-5_3},
}

@Article{Maia2012,
  author   = {Maia, Renato and Cerqueira, Renato and de Souza, Clarisse Sieckenius and Guisasola-Gorham, Tom{\'a}s},
  title    = {A qualitative human-centric evaluation of flexibility in middleware implementations},
  journal  = {Empirical Software Engineering},
  year     = {2012},
  volume   = {17},
  number   = {3},
  pages    = {166--199},
  month    = {Jun},
  issn     = {1573-7616},
  abstract = {Today middleware is much more powerful, more reliable and faster than it used to be. Nevertheless, for the application developer, the complexity of using middleware platforms has increased accordingly. The volume and variety of application contexts that current middleware technologies have to support require that developers be able to anticipate the widest possible range of execution environments, desired and undesired effects of different programming strategies, handling procedures for runtime errors, and so on. This paper shows how a generic framework designed to evaluate the usability of notations (the Cognitive Dimensions of Notations Framework, or CDN) has been instantiated and used to analyze the cognitive challenges involved in adapting middleware platforms. This human-centric perspective allowed us to achieve novel results compared to existing middleware evaluation research, typically centered around system performance metrics. The focus of our study is on the process of adapting middleware implementations, rather than in the end product of this activity. Our main contributions are twofold. First, we describe a qualitative CDN-based method to analyze the cognitive effort made by programmers while adapting middleware implementations. And second, we show how two platforms designed for flexibility have been compared, suggesting that certain programming language design features might be particularly helpful for developers.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10664-011-9167-7},
  url      = {https://doi.org/10.1007/s10664-011-9167-7},
}

@InBook{Ma2015,
  pages     = {137--143},
  title     = {Implementation of Dijkstra's Token Circulation on Sensor Network},
  publisher = {Springer Berlin Heidelberg},
  year      = {2015},
  author    = {Ma, Zhiqiang and Wang, Achuan and Guo, Jifeng},
  editor    = {Wang, Hongzhi and Qi, Haoliang and Che, Wanxiang and Qiu, Zhaowen and Kong, Leilei and Han, Zhongyuan and Lin, Junyu and Lu, Zeguang},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-662-46248-5},
  abstract  = {Sensor networks can consist of large number of sensors. Often, sensors networks use low cost units and thus a subject to malfunctions that can bring the system to inconsistent states. After deployment, the system can be situated in places that are hard to reach and therefore manual reboot operations are undesirable and even unfeasible. Therefore, it is imperative to consider the eventual recovery of arbitrary fault when designing sensor networks. Dijkstra's algorithm is an important foundation of self-managing computer system and fault-tolerance computing system in distributed systems, since it allows a distributed system to recover from arbitrary starting state within a finite time. The arbitrary starting state ca model arbitrary failure (as long as the code segment stays correct). Another key advantage of Dijkstra's asynchronous algorithm is that no global clock is needed. This project tests an implementation of Dijkstra's algorithm using snapshotting techniques that we developed in an earlier work. These sensors can initiate from any state but they come into a consistent one after several cycles of running. We demonstrate the usefulness of our testing technique.},
  booktitle = {Intelligent Computation in Big Data Era: International Conference of Young Computer Scientists, Engineers and Educators, ICYCSEE 2015, Harbin, China, January 10-12, 2015. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-662-46248-5_17},
  url       = {https://doi.org/10.1007/978-3-662-46248-5_17},
}

@InBook{Lopes2009,
  pages     = {25--41},
  title     = {Programming Wireless Sensor Networks},
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  author    = {Lopes, Lu{\'i}s and Martins, Francisco and Barros, Jo{\~a}o},
  editor    = {Garbinato, Beno{\^i}t and Miranda, Hugo and Rodrigues, Lu{\'i}s},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-89707-1},
  abstract  = {Sensor networks can be viewed as a collection of tiny, low-cost devices programmed to sense the physical world and that communicate over radio links [12]. The devices are commonly called motes or smart dust [676], in allusion to their computational and sensing capabilities, as well as their increasingly small size.},
  booktitle = {Middleware for Network Eccentric and Mobile Applications},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-540-89707-1_2},
  url       = {https://doi.org/10.1007/978-3-540-89707-1_2},
}

@InBook{Lohmann2012,
  pages     = {168--215},
  title     = {The Aspect-Aware Design and Implementation of the CiAO Operating-System Family},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Lohmann, Daniel and Spinczyk, Olaf and Hofer, Wanja and Schr{\"o}der-Preikschat, Wolfgang},
  editor    = {Leavens, Gary T. and Chiba, Shigeru and Haupt, Michael and Ostermann, Klaus and Wohlstadter, Eric},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-35551-6},
  abstract  = {CiAO is the first operating-system family that has been developed with AOP concepts from the very beginning. By its aspect-aware design and implementation, CiAO reaches excellent configurability, separation of concerns, and low footprints in the resulting systems that outperform leading commercial implementations. CiAO implements the automotive operating-system standard OSEK/AUTOSAR OS and provides configurability of all fundamental system properties by means of AOP.},
  booktitle = {Transactions on Aspect-Oriented Software Development IX},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-35551-6_5},
  url       = {https://doi.org/10.1007/978-3-642-35551-6_5},
}

@InBook{Lilius2010,
  pages     = {7--18},
  title     = {Rialto 2.0: A Language for Heterogeneous Computations},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Lilius, Johan and Dahlin, Andreas and Morel, Lionel},
  editor    = {Hinchey, Mike and Kleinjohann, Bernd and Kleinjohann, Lisa and Lindsay, Peter A. and Rammig, Franz J. and Timmis, Jon and Wolf, Marilyn},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-15234-4},
  abstract  = {Modern embedded systems are often heterogeneous in that their design requires several description paradigms, based on different models of computation and concurrency (MoCCs). In this paper we present Rialto, a formal language intended at expressing computations in several MoCCs. The distinguishing features of Rialto and its implementation are 1) A formal semantics: the language is formalized using SOS (structured operational semantics) rules; 2) Encapsulation of models of computation into policies: we thus distinguish between the syntactic elements of the language (parallelism, interrupts) and its semantics; 3) efficient implementation algorithms. Policies are expressed in the language itself, which allows for more expressive power and a sounder semantics.},
  booktitle = {Distributed, Parallel and Biologically Inspired Systems: 7th IFIP TC 10 Working Conference, DIPES 2010 and 3rd IFIP TC 10 International Conference, BICC 2010, Held as Part of WCC 2010, Brisbane, Australia, September 20-23, 2010. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-15234-4_3},
  url       = {https://doi.org/10.1007/978-3-642-15234-4_3},
}

@InBook{Lee2010,
  pages     = {273--287},
  title     = {Disciplined Heterogeneous Modeling},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Lee, Edward A.},
  editor    = {Petriu, Dorina C. and Rouquette, Nicolas and Haugen, {\O}ystein},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-16129-2},
  abstract  = {Complex systems demand diversity in the modeling mechanisms. One way to deal with a diversity of requirements is to create flexible modeling frameworks that can be adapted to cover the field of interest. The downside of this approach is a weakening of the semantics of the modeling frameworks that compromises interoperability, understandability, and analyzability of the models. An alternative approach is to embrace heterogeneity and to provide mechanisms for a diversity of models to interact. This paper reviews an approach that achieves such interaction between diverse models using an abstract semantics, which is a deliberately incomplete semantics that cannot by itself define a useful modeling framework. It instead focuses on the interactions between diverse models, reducing the nature of those interactions to a minimum that achieves a well-defined composition. An example of such an abstract semantics is the actor semantics, which can handle many heterogeneous models that are built today, and some that are not common today. The actor abstract semantics and many concrete semantics have been implemented in Ptolemy II, an open-source software framework distributed under a BSD-style license.},
  booktitle = {Model Driven Engineering Languages and Systems: 13th International Conference, MODELS 2010, Oslo, Norway, October 3-8, 2010, Proceedings, Part II},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-16129-2_20},
  url       = {https://doi.org/10.1007/978-3-642-16129-2_20},
}

@Article{Kuan2014,
  author   = {Kuan, Chi-Bang and Li, Jia-Jhe and Chen, Chung-Kai and Lee, Jenq-Kuen},
  title    = {C++ Support and Applications for Embedded Multicore DSP Systems},
  journal  = {Journal of Signal Processing Systems},
  year     = {2014},
  volume   = {75},
  number   = {2},
  pages    = {109--122},
  month    = {May},
  issn     = {1939-8115},
  abstract = {In recent years embedded systems have entered the multicore era. As the number of cores keeps growing in embedded systems, it becomes more important to provide programming support which considers embedded system constraints and in the meanwhile helps utilize multicore systems. So far though C still dominates embedded programming, C++ is gaining in importance in parallel programming. It is promising to support C++ for embedded multicore systems. However, embedded systems usually have tight resource budgets, and C++ is commonly considered having huge code size that embedded systems can not afford. Therefore, in this paper we investigate the code size requirement of a C++ library and propose a layered design to provide a code size aware library support. On the other hand, to utilize embedded multicore systems, we employ C++ linguistic features to facilitate embedded multicore programming. With C++, we incorporate high-level abstractions and design patterns into the programming support to enhance low-level programming APIs that can be used to exploit DSPs, SIMD instructions, and DMAs on embedded multicore systems. At last, we evaluate our C++ support with a Blur and a JPEG program. Our result on a dual-DSP platform shows that we can obtain speedups of 3.32 and 3.09 for the Blur and JPEG program, respectively.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s11265-013-0750-6},
  url      = {https://doi.org/10.1007/s11265-013-0750-6},
}

@Article{Kriaa2008,
  author   = {Kriaa, Lobna and Bouchhima, Aimen and Gligor, Marius and Fouillart, Anne-Marie and P{\'e}trot, Fr{\'e}deric and Jerraya, Ahmed-Amine},
  title    = {Parallel Programming of Multi-processor SoC: A HW--SW Interface Perspective},
  journal  = {International Journal of Parallel Programming},
  year     = {2008},
  volume   = {36},
  number   = {1},
  pages    = {68--92},
  month    = {Feb},
  issn     = {1573-7640},
  abstract = {For the design of classic computers the parallel programming concept is used to abstract HW/SW interfaces during high level specification of application software. The software is then adapted to existing multiprocessor platforms using a low level software layer that implements the programming model. Unlike classic computers, the design of heterogeneous MPSoC includes also building the processors and other kind of hardware components required to execute the software. In this case, the programming model hides both hardware and software refinements. This paper deals with parallel programming models to abstract both hardware and software interfaces in the case of heterogeneous MPSoC design. Different abstraction levels will be needed. For the long term, the use of higher level programming models will open new vistas for optimization and architecture exploration like CPU/RTOS tradeoffs.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10766-007-0042-5},
  url      = {https://doi.org/10.1007/s10766-007-0042-5},
}

@InBook{Kokkonen2015,
  pages     = {254--267},
  title     = {Analysis of Approaches to Internet Traffic Generation for Cyber Security Research and Exercise},
  publisher = {Springer International Publishing},
  year      = {2015},
  author    = {Kokkonen, Tero and H{\"a}m{\"a}l{\"a}inen, Timo and Silokunnas, Marko and Siltanen, Jarmo and Zolotukhin, Mikhail and Neijonen, Mikko},
  editor    = {Balandin, Sergey and Andreev, Sergey and Koucheryavy, Yevgeni},
  address   = {Cham},
  isbn      = {978-3-319-23126-6},
  abstract  = {Because of the severe global security threat of malwares, vulnerabilities and attacks against networked systems cyber-security research, training and exercises are required for achieving cyber resilience of organizations. Especially requirement for organizing cyber security exercises has become more and more relevant for companies or government agencies. Cyber security research, training and exercise require closed Internet like environment and generated Internet traffic. JAMK University of Applied Sciences has built a closed Internet-like network called Realistic Global Cyber Environment (RGCE). The traffic generation software for the RGCE is introduced in this paper. This paper describes different approaches and use cases to Internet traffic generation. Specific software for traffic generation is created, to which no existing traffic generation solutions were suitable.},
  booktitle = {Internet of Things, Smart Spaces, and Next Generation Networks and Systems: 15th International Conference, NEW2AN 2015, and 8th Conference, ruSMART 2015, St. Petersburg, Russia, August 26-28, 2015, Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-23126-6_23},
  url       = {https://doi.org/10.1007/978-3-319-23126-6_23},
}

@InBook{Jungck2011,
  pages     = {205--214},
  title     = {Descriptor Type and Operations},
  publisher = {Apress},
  year      = {2011},
  author    = {Jungck, Peder and Duncan, Ralph and Mulcahy, Dwight},
  address   = {Berkeley, CA},
  isbn      = {978-1-4302-4159-1},
  abstract  = {packetC provides data types that do not appear in standard C but do provide significant support for packet-processing applications. These data types are often extensions of familiar C types. The extended data type described in this chapter is descriptors. This chapter is divided into two different approaches. The first part of this chapter is focused on simply covering examples of descriptors and the packetC standard include file protocols.ph. The second part of this chapter covers an in-depth view into the background of the descriptors and how they operate under the hood as these are new to packetC.},
  booktitle = {packetC Programming},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4302-4159-1_19},
  url       = {https://doi.org/10.1007/978-1-4302-4159-1_19},
}

@InBook{Jackson2013,
  pages     = {335--347},
  title     = {Formalism and Intuition in Software Engineering},
  publisher = {Springer Berlin Heidelberg},
  year      = {2013},
  author    = {Jackson, Michael},
  editor    = {M{\"u}nch, J{\"u}rgen and Schmid, Klaus},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-37395-4},
  abstract  = {A major and so far unmet challenge in software engineering is to achieve and act upon a clear and sound understanding of the relationship between formalism and intuition in the development process. The challenge is salient in the development of cyber-physical systems, in which the computer interacts with the human and physical world to ensure a behaviour there that satisfies the requirements of the system's stakeholders. The nature of the computer as a formally defined symbol-processing engine invites a formal mathematical approach to software development. Contrary considerations militate against excessive reliance on formalism. The non-formal nature of the human and physical world, the complexity of system function, and the need for human comprehension at every level demand application of non-formal and intuitional knowledge, of insight and technique rather than calculation. The challenge, then, is to determine how these two facets of the development process---formalism and intuition---can work together most productively. This short essay describes some origins and aspects of the challenge and offers a perspective for addressing it.},
  booktitle = {Perspectives on the Future of Software Engineering: Essays in Honor of Dieter Rombach},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-37395-4_20},
  url       = {https://doi.org/10.1007/978-3-642-37395-4_20},
}

@Article{Jackson2009,
  author   = {Jackson, Ethan and Sztipanovits, Janos},
  title    = {Formalizing the structural semantics of domain-specific modeling languages},
  journal  = {Software {\&} Systems Modeling},
  year     = {2009},
  volume   = {8},
  number   = {4},
  pages    = {451--478},
  month    = {Sep},
  issn     = {1619-1374},
  abstract = {Model-based approaches to system design are now widespread and successful. These approaches make extensive use of model structure to describe systems using domain-specific abstractions, to specify and implement model transformations, and to analyze structural properties of models. In spite of its general importance the structural semantics of modeling languages are not well-understood. In this paper we develop the formal foundations for the structural semantics of domain-specific modeling languages (DSML), including the mechanisms by which metamodels specify the structural semantics of DSMLs. Additionally, we show how our formalization can complement existing tools, and how it yields algorithms for the analysis of DSMLs and model transformations.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10270-008-0105-0},
  url      = {https://doi.org/10.1007/s10270-008-0105-0},
}

@InBook{Ierusalimschy2010,
  pages     = {1--12},
  title     = {Programming with Multiple Paradigms in Lua},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Ierusalimschy, Roberto},
  editor    = {Escobar, Santiago},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-11999-6},
  abstract  = {Lua is a scripting language used in many industrial applications, with an emphasis on embedded systems and games. Two key points in the design of the language that led to its widely adoption are flexibility and small size. To achieve these two conflicting goals, the design emphasizes the use of few but powerful mechanisms, such as first-class functions, associative arrays, coroutines, and reflexive capabilities. As a consequence of this design, although Lua is primarily a procedural language, it is frequently used in several different programming paradigms, such as functional, object-oriented, goal-oriented, and concurrent programming, and also for data description.},
  booktitle = {Functional and Constraint Logic Programming: 18th International Workshop, WFLP 2009, Brasilia, Brazil, June 28, 2009, Revised Selected Papers},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-11999-6_1},
  url       = {https://doi.org/10.1007/978-3-642-11999-6_1},
}

@Article{Huang2009,
  author   = {Huang, Kai and Yan, Xiao-lang and Han, Sang-il and Chae, Soo-ik and Jerraya, Ahmed A. and Popovici, Katalin and Guerin, Xavier and Brisolara, Lisane and Carro, Luigi},
  title    = {Gradual refinement for application-specific MPSoC design from Simulink model to RTL implementation},
  journal  = {Journal of Zhejiang University-SCIENCE A},
  year     = {2009},
  volume   = {10},
  number   = {2},
  pages    = {151--164},
  month    = {Feb},
  issn     = {1862-1775},
  abstract = {The application-specific multiprocessor system-on-chip (MPSoC) architecture is becoming an attractive solution to deal with increasingly complex embedded applications, which require both high performance and flexible programmability. As an effective method for MPSoC development, we present a gradual refinement flow starting from a high-level Simulink model to a synthesizable and executable hardware and software specification. The proposed methodology consists of five different abstract levels: Simulink combined algorithm and architecture model (CAAM), virtual architecture (VA), transactional accurate architecture (TA), virtual prototype (VP) and field-programmable gate array (FPGA) emulation. Experimental results of Motion-JPEG and H.264 show that the proposed gradual refinement flow can generate various MPSoC architectures from an original Simulink model, allowing processor, communication and tasks design space exploration.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1631/jzus.A0820085},
  url      = {https://doi.org/10.1631/jzus.A0820085},
}

@InBook{Hölzl2016,
  pages     = {201--224},
  title     = {Continuous Collaboration for Changing Environments},
  publisher = {Springer International Publishing},
  year      = {2016},
  author    = {H{\"o}lzl, Matthias and Gabor, Thomas},
  editor    = {Steffen, Bernhard},
  address   = {Cham},
  isbn      = {978-3-319-46508-1},
  abstract  = {Collective autonomic systems (CAS) are distributed collections of agents that collaborate to achieve the system's goals but autonomously adapt their behavior. We present the teacher/student architecture for locally coordinated distributed learning and show that in certain scenarios the performance of a swarm using teacher/student learning can be significantly better than that of agents learning individually. Teacher/student learning serves as foundation for the continuous collaboration (CC) development approach. We introduce CC, relate it to the EDLC, a life cycle model for CAS, and show that CC embodies many of the principles proposed for developing CAS.},
  booktitle = {Transactions on Foundations for Mastering Change I},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-46508-1_11},
  url       = {https://doi.org/10.1007/978-3-319-46508-1_11},
}

@InBook{Herdt2016,
  pages     = {177--183},
  title     = {ParCoSS: Efficient Parallelized Compiled Symbolic Simulation},
  publisher = {Springer International Publishing},
  year      = {2016},
  author    = {Herdt, Vladimir and Le, Hoang M. and Gro{\ss}e, Daniel and Drechsler, Rolf},
  editor    = {Chaudhuri, Swarat and Farzan, Azadeh},
  address   = {Cham},
  isbn      = {978-3-319-41540-6},
  abstract  = {We present the tool ParCoSS for verification of cooperative multithreading programs. Our tool is based on the recently proposed Compiled Symbolic Simulation (CSS) technique. Additionally, we employ parallelization to further speed-up the verification. The potential of our tool is shown by evaluation.},
  booktitle = {Computer Aided Verification: 28th International Conference, CAV 2016, Toronto, ON, Canada, July 17-23, 2016, Proceedings, Part II},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-41540-6_10},
  url       = {https://doi.org/10.1007/978-3-319-41540-6_10},
}

@Article{Han2007,
  author   = {Han, Sang-Il and Chae, Soo-Ik and Brisolara, Lisane and Carro, Luigi and Reis, Ricardo and Gu{\'e}rin, Xavier and Jerraya, Ahmed Amine},
  title    = {Memory-efficient multithreaded code generation from Simulink for heterogeneous MPSoC},
  journal  = {Design Automation for Embedded Systems},
  year     = {2007},
  volume   = {11},
  number   = {4},
  pages    = {249--283},
  month    = {Dec},
  issn     = {1572-8080},
  abstract = {Emerging embedded systems require heterogeneous multiprocessor SoC architectures that can satisfy both high-performance and programmability. However, as the complexity of embedded systems increases, software programming on an increasing number of multiprocessors faces several critical problems, such as multithreaded code generation, heterogeneous architecture adaptation, short design time, and low cost implementation. In this paper, we present a software code generation flow based on Simulink to address these problems. We propose a functional modeling style to capture data-intensive and control-dependent target applications, and a system architecture modeling style to seamlessly transform the functional model into the target architecture. Both models are described using Simulink. From a system architecture Simulink model, a code generator produces a multithreaded code, inserting thread and communication primitives to abstract the heterogeneity of the target architecture. In addition, the multithread code generator called LESCEA applies the extensions of dataflow based memory optimization techniques, considering both data and control dependency. Experimental results on a Motion-JPEG decoder and an H.264 decoder show that the proposed multithread code generator enables easy software programming on different multiprocessor architectures with substantially reduced data memory size (up to 68.0{\%}) and code memory size (up to 15.9{\%}).},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10617-007-9009-4},
  url      = {https://doi.org/10.1007/s10617-007-9009-4},
}

@Article{Hall2008,
  author   = {Hall, Robert J.},
  title    = {A method and tools for large scale scenarios},
  journal  = {Automated Software Engineering},
  year     = {2008},
  volume   = {15},
  number   = {2},
  pages    = {113--148},
  month    = {Jun},
  issn     = {1573-7535},
  abstract = {Formal scenarios have many uses in requirements engineering, validation, performance modeling, and test generation. Many tools and methodologies can handle scenarios when the number of steps (interleaved inputs and outputs of the target system) is reasonably small. However, scenario based techniques do not scale well with the number of steps, number of actors, and complexity of behaviors and system interactions to be specified in the scenario. First, it is impractically tedious and error-prone to specify thousands of input steps and corresponding expected outputs. Second, even if one can write down such large scale scenarios, confidence in their correctness is naturally low. Third, complex systems requiring large scale scenarios tend to require many such scenarios to adequately cover the behavior space. This paper describes the motivations for and problems of large scale scenarios, as well as the LSS method, which uses automated and semi-automated techniques in describing, maintaining, communicating, and using large scale scenarios in requirements engineering. The method is illustrated in two widely divergent application domains: military live training instrumentation and electronic mail servers. A case study demonstrates the practical and beneficial use of LSS in architectural modeling of a complex, real-world system design.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10515-008-0026-8},
  url      = {https://doi.org/10.1007/s10515-008-0026-8},
}

@InBook{Grune2012,
  pages     = {313--362},
  title     = {Code Generation},
  publisher = {Springer New York},
  year      = {2012},
  author    = {Grune, Dick and van Reeuwijk, Kees and Bal, Henri E. and Jacobs, Ceriel J. H. and Langendoen, Koen},
  address   = {New York, NY},
  isbn      = {978-1-4614-4699-6},
  abstract  = {We will now turn to the generation of target code from the AST. Although simple code generation is possible, the generation of good code is a field full of snags and snares, and it requires considerable care.We will therefore start with a discussion of the desired properties of generated code.},
  booktitle = {Modern Compiler Design},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4614-4699-6_7},
  url       = {https://doi.org/10.1007/978-1-4614-4699-6_7},
}

@InBook{Grune2012,
  pages     = {463--507},
  title     = {Explicit and Implicit Memory Management},
  publisher = {Springer New York},
  year      = {2012},
  author    = {Grune, Dick and van Reeuwijk, Kees and Bal, Henri E. and Jacobs, Ceriel J. H. and Langendoen, Koen},
  address   = {New York, NY},
  isbn      = {978-1-4614-4699-6},
  abstract  = {All compilers and many run-time systems use dynamically sized data. The size of such data is not known in advance and room for it must be found at run time. Examples inside the compiler are symbol tables, strings from the source program, ASTs, register interference graphs for graph coloring, and many others. The examples in run-time systems derive from the nature of the source language: strings, dynamically sized arrays in imperative languages, closures in functional languages, tentative unifications in logic languages, and incoming messages in distributed languages are a few that come to mind.},
  booktitle = {Modern Compiler Design},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4614-4699-6_10},
  url       = {https://doi.org/10.1007/978-1-4614-4699-6_10},
}

@Article{Grover2017,
  author   = {Grover, Purva and Kar, Arpan Kumar},
  title    = {Big Data Analytics: A Review on Theoretical Contributions and Tools Used in Literature},
  journal  = {Global Journal of Flexible Systems Management},
  year     = {2017},
  volume   = {18},
  number   = {3},
  pages    = {203--229},
  month    = {Sep},
  issn     = {0974-0198},
  abstract = {The importance of data science and big data analytics is growing very fast as organizations are gearing up to leverage their information assets to gain competitive advantage. The flexibility offered through big data analytics empowers functional as well as firm-level performance. In the first phase of the study, we attempt to analyze the research on big data published in high-quality business management journals. The analysis was visualized using tools for big data and text mining to understand the dominant themes and how they are connected. Subsequently, an industry-specific categorization of the studies was done to understand the key use cases. It was found that most of the existing research focuses majorly on consumer discretionary, followed by public administration. Methodologically, a major focus in such exploration is in social media analytics, text mining and machine learning applications for meeting objectives in marketing and supply chain management. However, it was found that not much focus was highlighted in these studies to demonstrate the tools used for the analysis. To address this gap, this study also discusses the evolution, types and usage of big data tools. The brief overview of big data technologies grouped by the services they enable and some of their applications are presented. The study categorizes these tools into big data analysis platforms, databases and data warehouses, programming languages, search tools, and data aggregation and transfer tools. Finally, based on the review, future directions for exploration in big data has been provided for academic and practice.              },
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s40171-017-0159-3},
  url      = {https://doi.org/10.1007/s40171-017-0159-3},
}

@InBook{Gong2012,
  pages     = {610--617},
  title     = {Retracted: Modeling and Verifying the Kernel of RTOS},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Gong, ShengWen},
  editor    = {Liu, Chunfeng and Wang, Leizhen and Yang, Aimin},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-34038-3},
  abstract  = {This paper presents a study on modeling and verifying the kernel of Real-Time Operating Systems (RTOS). Advances in formally verifying such an RTOS both by refinement and by model checking approaches will be shown in this paper. The focus of the paper will be on verifying FreeRTOS. A number of ways to verify this operating system are investigated in the paper. At last, a preliminary set-up of verifying FreeRTOS using model checking is presented.},
  booktitle = {Information Computing and Applications: Third International Conference, ICICA 2012, Chengde, China, September 14-16, 2012. Proceedings, Part I},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-34038-3_84},
  url       = {https://doi.org/10.1007/978-3-642-34038-3_84},
}

@InBook{Geilen2010,
  pages     = {967--1006},
  title     = {Kahn Process Networks and a Reactive Extension},
  publisher = {Springer US},
  year      = {2010},
  author    = {Geilen, Marc and Basten, Twan},
  editor    = {Bhattacharyya, Shuvra S. and Deprettere, Ed F. and Leupers, Rainer and Takala, Jarmo},
  address   = {Boston, MA},
  isbn      = {978-1-4419-6345-1},
  abstract  = {Kahn andMacQueen have introduced a generic class of determinate asynchronous data-flow applications, called Kahn Process Networks (KPNs) with an elegant mathematical model and semantics in terms of Scott-continuous functions on data streams together with an implementation model of independent asynchronous sequential programs communicating through FIFO buffers with blocking read and non-blocking write operations. The two are related by the Kahn Principle which states that a realization according to the implementationmodel behaves as predicted by the mathematical function. Additional steps are required to arrive at an actual implementation of a KPN to take care of scheduling of independent processes on a single processor and to manage communication buffers. Because of the expressiveness of the KPN model, buffer sizes and schedules cannot be determined at design time in general and require dynamic run-time system support. Constraints are discussed that need to be placed on such system support so as to maintain the Kahn Principle. We then discuss a possible extension of the KPN model to include the possibility for sporadic, reactive behavior which is not possible in the standard model. The extended model is called Reactive Process Networks. We introduce its semantics, look at analyzability and at more constrained data-flowmodels combined with reactive behavior.},
  booktitle = {Handbook of Signal Processing Systems},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4419-6345-1_34},
  url       = {https://doi.org/10.1007/978-1-4419-6345-1_34},
}

@InBook{Gabbrielli2010,
  pages     = {413--432},
  title     = {A Short Historical Perspective},
  publisher = {Springer London},
  year      = {2010},
  author    = {Gabbrielli, Maurizio and Martini, Simone},
  address   = {London},
  isbn      = {978-1-84882-914-5},
  abstract  = {Even if the first computers in the modern sense, and therefore the first programming languages, appeared only at the end of the 1940s, since then there have many hundreds (if not thousands) of languages have been defined. In the previous chapters of this book we have sought to identify the most important design and implementation characteristics that are common to large classes of contemporary languages. In this last chapter, we seek to understand what were the reasons that lead, in the last sixty years, to the affirmation of these characteristics and, therefore, to the success of some languages and the disappearance of many others.},
  booktitle = {Programming Languages: Principles and Paradigms},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-84882-914-5_13},
  url       = {https://doi.org/10.1007/978-1-84882-914-5_13},
}

@Article{Ferreira2014,
  author   = {Ferreira, Jo{\~a}o F. and Gherghina, Cristian and He, Guanhua and Qin, Shengchao and Chin, Wei-Ngan},
  title    = {Automated verification of the FreeRTOS scheduler in Hip/Sleek},
  journal  = {International Journal on Software Tools for Technology Transfer},
  year     = {2014},
  volume   = {16},
  number   = {4},
  pages    = {381--397},
  month    = {Aug},
  issn     = {1433-2787},
  abstract = {Automated verification of operating system kernels is a challenging problem, partly due to the use of shared mutable data structures. In this paper, we show how we can automatically verify memory safety and functional correctness properties of the task scheduler component of the FreeRTOS kernel using the verification system Hip/Sleek. We show how some of Hip/Sleek features such as user-defined predicates and lemmas make the specifications highly expressive and the verification process viable. To the best of our knowledge, this is the first code-level verification of memory safety and functional correctness properties of the FreeRTOS scheduler. The outcome of our experiment confirms that Hip/Sleek can indeed be used to verify code that is used in production. Moreover, since the properties that we verify are quite general, we envisage that the same approach can be adopted to verify components of other operating systems.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10009-014-0307-4},
  url      = {https://doi.org/10.1007/s10009-014-0307-4},
}

@InBook{Feautrier2014,
  pages     = {113--132},
  title     = {Improving the Performance of X10 Programs by Clock Removal},
  publisher = {Springer Berlin Heidelberg},
  year      = {2014},
  author    = {Feautrier, Paul and Violard, {\'E}ric and Ketterlin, Alain},
  editor    = {Cohen, Albert},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-54807-9},
  abstract  = {X10 is a promising recent parallel language designed specifically to address the challenges of productively programming a wide variety of target platforms. The sequential core of X10 is an object-oriented language in the Java family. This core is augmented by a few parallel constructs that create activities as a generalization of the well known fork/join model. Clocks are a generalization of the familiar barriers. Synchronization on a clock is specified by the Clock.advanceAll() method call. Activities that execute advances stall until all existent activities have done the same, and then are released at the same (logical) time.},
  booktitle = {Compiler Construction: 23rd International Conference, CC 2014, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014, Grenoble, France, April 5-13, 2014. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-54807-9_7},
  url       = {https://doi.org/10.1007/978-3-642-54807-9_7},
}

@InBook{DiSaverio2007,
  pages     = {281--288},
  title     = {Distributed Real-Time Computing with Harness},
  publisher = {Springer Berlin Heidelberg},
  year      = {2007},
  author    = {Di Saverio, Emanuele and Cesati, Marco and Di Biagio, Christian and Pennella, Guido and Engelmann, Christian},
  editor    = {Cappello, Franck and Herault, Thomas and Dongarra, Jack},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-75416-9},
  abstract  = {Modern parallel and distributed computing solutions are often built onto a ``middleware'' software layer providing a higher and common level of service between computational nodes. Harness is an adaptable, plugin-based middleware framework for parallel and distributed computing. This paper reports recent research and development results of using Harness for real-time distributed computing applications in the context of an industrial environment with the needs to perform several safety critical tasks. The presented work exploits the modular architecture of Harness in conjunction with a lightweight threaded implementation to resolve several real-time issues by adding three new Harness plug-ins to provide a prioritized lightweight execution environment, low latency communication facilities, and local timestamped event logging.},
  booktitle = {Recent Advances in Parallel Virtual Machine and Message Passing Interface: 14th European PVM/MPI User's Group Meeting, Paris, France, September 30 - October 3, 2007. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-540-75416-9_39},
  url       = {https://doi.org/10.1007/978-3-540-75416-9_39},
}

@InBook{Ćulibrk2014,
  pages     = {1--52},
  title     = {Wireless Sensor Network Technology for Precision Agriculture},
  publisher = {Springer New York},
  year      = {2014},
  author    = {{\'{C}}ulibrk, Dubravko and Vukobratovic, Dejan and Minic, Vladan and Fernandez, Marta Alonso and Osuna, Javier Alvarez and Crnojevic, Vladimir},
  address   = {New York, NY},
  isbn      = {978-1-4614-8329-8},
  abstract  = {Precision agriculture demands intensive field data acquisition. One of the keys to understanding productivity variability lays in frequent data acquisition and interpretation. Wireless sensor networks (WSN) are a relatively new and rapidly developing class of wireless communication networks which can provide processed real time field data from sensors distributed in the field. The sensor nodes deployed on the field measure various atmospheric and soil parameters. These measurements can help in making decision on irrigation (automating, semi automating), fertilizer and pesticide applications, intruder detection, pest detection, yield prediction, plant disease prediction, fire detection, etc. The first part of this brief is devoted to Wireless Sensor Network technology with particular focus on its application in precision agriculture.},
  booktitle = {Sensing Technologies For Precision Irrigation},
  db        = {SpringerLink},
  doi       = {10.1007/978-1-4614-8329-8_1},
  url       = {https://doi.org/10.1007/978-1-4614-8329-8_1},
}

@InBook{Costa2009,
  pages     = {245--264},
  title     = {Tuple Space Middleware for Wireless Networks},
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  author    = {Costa, Paolo and Mottola, Luca and Murphy, Amy L. and Picco, Gian Pietro},
  editor    = {Garbinato, Beno{\^i}t and Miranda, Hugo and Rodrigues, Lu{\'i}s},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-89707-1},
  abstract  = {Wireless networks define a very challenging scenario for the application programmer. Indeed, the fluidity inherent in the wireless media cannot be entirely masked at the communication layer: issues such as disconnection and a continuously changing execution context most often must be dealt with according to the application logic. Appropriate abstractions, usually provided as part of a middleware, are therefore required to support and simplify the programming task.},
  booktitle = {Middleware for Network Eccentric and Mobile Applications},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-540-89707-1_11},
  url       = {https://doi.org/10.1007/978-3-540-89707-1_11},
}

@Article{Chapman2013,
  author   = {Chapman, Barbara and Eachempati, Deepak and Hernandez, Oscar},
  title    = {Experiences Developing the OpenUH Compiler and Runtime Infrastructure},
  journal  = {International Journal of Parallel Programming},
  year     = {2013},
  volume   = {41},
  number   = {6},
  pages    = {825--854},
  month    = {Dec},
  issn     = {1573-7640},
  abstract = {The OpenUH compiler is a branch of the open source Open64 compiler suite for C, C++, and Fortran 95/2003, with support for a variety of targets including x86{\_}64, IA-64, and IA-32. For the past several years, we have used OpenUH to conduct research in parallel programming models and their implementation, static and dynamic analysis of parallel applications, and compiler integration with external tools. In this paper, we describe the evolution of the OpenUH infrastructure and how we've used it to carry out our research and teaching efforts.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s10766-012-0230-9},
  url      = {https://doi.org/10.1007/s10766-012-0230-9},
}

@InBook{Bouillaguet2010,
  pages     = {203--218},
  title     = {Fast Exhaustive Search for Polynomial Systems in {\$}{\{}{\backslash}mathbb{\{}F{\}}{\_}2{\}}{\$}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Bouillaguet, Charles and Chen, Hsieh-Chung and Cheng, Chen-Mou and Chou, Tung and Niederhagen, Ruben and Shamir, Adi and Yang, Bo-Yin},
  editor    = {Mangard, Stefan and Standaert, Fran{\c{c}}ois-Xavier},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-15031-9},
  abstract  = {We analyze how fast we can solve general systems of multivariate equations of various low degrees over                                                                           {\$}{\{}{\backslash}mathbb{\{}F{\}}{\_}{\{}2{\}}{\}}{\$}                ; this is a well known hard problem which is important both in itself and as part of many types of algebraic cryptanalysis. Compared to the standard exhaustive search technique, our improved approach is more efficient both asymptotically and practically. We implemented several optimized versions of our techniques on CPUs and GPUs. Our technique runs more than 10 times faster on modern graphic cards than on the most powerful CPU available. Today, we can solve 48+ quadratic equations in 48 binary variables on a 500-dollar NVIDIA GTX 295 graphics card in 21 minutes. With this level of performance, solving systems of equations supposed to ensure a security level of 64 bits turns out to be feasible in practice with a modest budget. This is a clear demonstration of the computational power of GPUs in solving many types of combinatorial and cryptanalytic problems.},
  booktitle = {Cryptographic Hardware and Embedded Systems, CHES 2010: 12th International Workshop, Santa Barbara, USA, August 17-20, 2010. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-15031-9_14},
  url       = {https://doi.org/10.1007/978-3-642-15031-9_14},
}

@Article{Boers2010,
  author   = {Boers, Nicholas M. and Gburzy{\'{n}}ski, Pawe{\l} and Nikolaidis, Ioanis and Olesi{\'{n}}ski, W{\l}odek},
  title    = {Developing wireless sensor network applications in a virtual environment},
  journal  = {Telecommunication Systems},
  year     = {2010},
  volume   = {45},
  number   = {2},
  pages    = {165--176},
  month    = {Oct},
  issn     = {1572-9451},
  abstract = {We describe our ``holistic'' platform for developing wireless ad hoc sensor networks and focus on its most representative and essential virtualization component: VUE2 (the Virtual Underlay Emulation Engine). Its role is to provide a vehicle for the authoritative emulation of complete networked applications before physically deploying any wireless nodes. The goal is to be able to verify those applications exhaustively before programming the hardware, such that no further (field) tests are necessary. We explain how VUE2 achieves this goal owing to several facilitating factors, most notably the powerful programming paradigm that our platform adopts. As implied by the holistic nature of the discussed system, our work touches upon operating systems, simulation, network protocols, real-time systems, and programming methodology.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s11235-009-9246-x},
  url      = {https://doi.org/10.1007/s11235-009-9246-x},
}

@Article{Bjørk2013,
  author   = {Bj{\o}rk, Joakim and de Boer, Frank S. and Johnsen, Einar Broch and Schlatte, Rudolf and Tapia Tarifa, S. Lizeth},
  title    = {User-defined schedulers for real-time concurrent objects},
  journal  = {Innovations in Systems and Software Engineering},
  year     = {2013},
  volume   = {9},
  number   = {1},
  pages    = {29--43},
  month    = {Mar},
  issn     = {1614-5054},
  abstract = {Scheduling concerns the allocation of processors to processes, and is traditionally associated with low-level tasks in operating systems and embedded devices. However, modern software applications with soft real-time requirements need to control application-level performance. High-level scheduling control at the application level may complement general purpose OS level scheduling to fine-tune performance of a specific application, by allowing the application to adapt to changes in client traffic on the one hand and to low-level scheduling on the other hand. This paper presents an approach to express and analyze application-specific scheduling decisions during the software design stage. For this purpose, we integrate support for application-level scheduling control in a high-level object-oriented modeling language, Real-Time ABS, in which executable specifications of method calls are given deadlines and real-time computational constraints. In Real-Time ABS, flexible application-specific schedulers may be specified by the user, i.e., developer, at the abstraction level of the high-level modeling language itself and associated with concurrent objects at creation time. Tool support for Real-Time ABS is based on an abstract interpreter that supports simulations and measurements of systems at the design stage.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s11334-012-0184-5},
  url      = {https://doi.org/10.1007/s11334-012-0184-5},
}

@InBook{Bierman2012,
  pages     = {233--257},
  title     = {Pause 'n' Play: Formalizing Asynchronous C {\$}^{\backslash}sharp{\$}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Bierman, Gavin and Russo, Claudio and Mainland, Geoffrey and Meijer, Erik and Torgersen, Mads},
  editor    = {Noble, James},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-31057-7},
  abstract  = {Writing applications that connect to external services and yet remain responsive and resource conscious is a difficult task. With the rise of web programming this has become a common problem. The solution lies in using asynchronous operations that separate issuing a request from waiting for its completion. However, doing so in common object-oriented languages is difficult and error prone. Asynchronous operations rely on callbacks, forcing the programmer to cede control. This inversion of control-flow impedes the use of structured control constructs, the staple of sequential code. In this paper, we describe the language support for asynchronous programming in the upcoming version of C                                                                          {\$}^{\backslash}sharp{\$}                . The feature enables asynchronous programming using structured control constructs. Our main contribution is a precise mathematical description that is abstract (avoiding descriptions of compiler-generated state machines) and yet sufficiently concrete to allow important implementation properties to be identified and proved correct.},
  booktitle = {ECOOP 2012 -- Object-Oriented Programming: 26th European Conference, Beijing, China, June 11-16, 2012. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-31057-7_12},
  url       = {https://doi.org/10.1007/978-3-642-31057-7_12},
}

@InBook{Berry2014,
  pages     = {1--13},
  title     = {Hop and HipHop: Multitier Web Orchestration},
  publisher = {Springer International Publishing},
  year      = {2014},
  author    = {Berry, G{\'e}rard and Serrano, Manuel},
  editor    = {Natarajan, Raja},
  address   = {Cham},
  isbn      = {978-3-319-04483-5},
  abstract  = {Rich applications merge classical computing, client-server concurrency, web-based interfaces, and the complex time- and event-based reactive programming found in embedded systems. To handle them, we extend the Hop web programming platform by HipHop, a domain-specific language dedicated to event-based process orchestration. Borrowing the synchronous reactive model of Esterel, HipHop is based on synchronous concurrency and preemption primitives that are known to be key components for the modular design of complex reactive behaviors. HipHop departs from Esterel by its ability to handle the dynamicity of Web applications, thanks to the reflexivity of Hop. Using a music player example, we show how to modularly build a non-trivial Hop application using HipHop orchestration code.},
  booktitle = {Distributed Computing and Internet Technology: 10th International Conference, ICDCIT 2014, Bhubaneswar, India, February 6-9, 2014. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-319-04483-5_1},
  url       = {https://doi.org/10.1007/978-3-319-04483-5_1},
}

@InBook{Baudisch2010,
  pages     = {169--180},
  title     = {Dependency-Driven Distribution of Synchronous Programs},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  author    = {Baudisch, Daniel and Brandt, Jens and Schneider, Klaus},
  editor    = {Hinchey, Mike and Kleinjohann, Bernd and Kleinjohann, Lisa and Lindsay, Peter A. and Rammig, Franz J. and Timmis, Jon and Wolf, Marilyn},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-15234-4},
  abstract  = {In this paper, we describe an automatic synthesis procedure that distributes synchronous programs on a set of desynchronized processing elements. Our distribution procedure consists of three steps: First, we translate the given synchronous program to synchronous guarded actions. Second, we analyze their data dependencies and represent them in a so-called action dependency graph (ADG). Third, the ADG is subsequently partitioned into of sub-graphs where cuts can be made horizontal (for a pipelined execution) or vertical (for a concurrent execution). Finally, we generate for each sub-graph a corresponding component and automatically synthesize a communication infrastructure between these components.},
  booktitle = {Distributed, Parallel and Biologically Inspired Systems: 7th IFIP TC 10 Working Conference, DIPES 2010 and 3rd IFIP TC 10 International Conference, BICC 2010, Held as Part of WCC 2010, Brisbane, Australia, September 20-23, 2010. Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-15234-4_17},
  url       = {https://doi.org/10.1007/978-3-642-15234-4_17},
}

@InBook{Amaricai2012,
  pages     = {213--224},
  title     = {Using Cycle-Approximate Simulation for Bus Based Multi-Processor System-On Chip Analysis},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Amaricai, Alexandru and Dobre, Alin and Boncalo, Oana and Tanase, Andrei and Valuch, Camelia},
  editor    = {Precup, Radu-Emil and Kov{\'a}cs, Szilveszter and Preitl, Stefan and Petriu, Emil M.},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-28305-5},
  abstract  = {In this chapter, a cycle approximate simulator for multi-processor system-on chip is presented. The aim of this simulation tool is to enable an enhanced software/hardware analysis capability for bus based systems. The most important contributions are represented by its high flexibility (easy configuration of a SoC using dedicated libraries for generic and specific components and easy integration of other simulators and models), accurate modeling of features specific to multiprocessor systems (busses, inter processor communication mechanisms, etc), accurate implementation of a wide range of performance metrics and power consumption estimates (for processors that support this) and high simulation speed. This way, the proposed simulator can be used for both hardware architecture design exploration and software development.},
  booktitle = {Applied Computational Intelligence in Engineering and Information Technology: Revised and Selected Papers from the 6th IEEE International Symposium on Applied Computational Intelligence and Informatics SACI 2011},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-28305-5_17},
  url       = {https://doi.org/10.1007/978-3-642-28305-5_17},
}

@InBook{Ahrens2009,
  pages     = {200--221},
  title     = {The Challenges of Using SDL for the Development of Wireless Sensor Networks},
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  author    = {Ahrens, Klaus and Eveslage, Ingmar and Fischer, Joachim and K{\"u}hnlenz, Frank and Weber, Dorian},
  editor    = {Reed, Rick and Bilgic, Attila and Gotzhein, Reinhard},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-04554-7},
  abstract  = {In recent years, Wireless Sensor Networks (WSNs) have been primarily used to build ad-hoc telecommunication infrastructures from scratch or as low-cost alternatives to traditional networks. But the diversity of applications with typically narrow node resources and requirements of already existing information infrastructures sets hard constraints to WSN. The software development process becomes even more complicated when real-time constraints have to be taken into account. This is the case when the physical processes of the WSN environment have to be observed and are realized in space and time. For the development of such WSN we present a model-based framework (GAF4WSN), where the well-known techniques SDL, UML and ASN.1 are involved. The framework was already successfully used for the development of a new generation of Earthquake Early Warning Systems (EEWS). An Earthquake Synthesizer (ES) and an Experiment Management System (EMS) complete the framework, which supports the modelling, simulation, installation and administration of different EEWS approaches in combination with a Geographic Information System (GIS).},
  booktitle = {SDL 2009: Design for Motes and Mobiles: 14th International SDL Forum Bochum, Germany, September 22-24, 2009 Proceedings},
  db        = {SpringerLink},
  doi       = {10.1007/978-3-642-04554-7_13},
  url       = {https://doi.org/10.1007/978-3-642-04554-7_13},
}

@Article{Aguado2015,
  author   = {Aguado, Joaqu{\'i}n and Mendler, Michael and von Hanxleden, Reinhard and Fuhrmann, Insa},
  title    = {Denotational fixed-point semantics for constructive scheduling of synchronous concurrency},
  journal  = {Acta Informatica},
  year     = {2015},
  volume   = {52},
  number   = {4},
  pages    = {393--442},
  month    = {Jun},
  issn     = {1432-0525},
  abstract = {The synchronous model of concurrent computation (SMoCC) is well established for programming languages in the domain of safety-critical reactive and embedded systems. Translated into mainstream C/Java programming, the SMoCC corresponds to a cyclic execution model in which concurrent threads are synchronised on a logical clock that cuts system computation into a sequence of macro-steps. A causality analysis verifies the existence of a schedule on memory accesses to ensure each macro-step is deadlock-free and determinate. We introduce an abstract semantic domain                                                                           {\$}{\$}I({\backslash}mathbb {\{}D{\}}, {\backslash}mathbb {\{}P{\}}){\$}{\$}                                                                                    I                        (                        D                        ,                        P                        )                                                                             and an associated denotational fixed-point semantics for reasoning about concurrent and sequential variable accesses within a synchronous cycle-based model of computation. We use this domain for a new and extended behavioural definition of Berry's causality analysis in terms of approximation intervals. The domain                                                                           {\$}{\$}I({\backslash}mathbb {\{}D{\}}, {\backslash}mathbb {\{}P{\}}){\$}{\$}                                                                                    I                        (                        D                        ,                        P                        )                                                                             extends the domain                                                                           {\$}{\$}I({\backslash}mathbb {\{}D{\}}){\$}{\$}                                                                                    I                        (                        D                        )                                                                             from our previous work and fixes a mistake in the treatment of initialisations. Based on this fixed-point semantics we propose the notion of Input Berry-constructiveness (IBC) for synchronous programs. This new IBC class lies properly between strong (SBC) and normal Berry-constructiveness (BC) defined in previous work. SBC and BC are two ways to interpret the standard constructive semantics of synchronous programming, as exemplified by imperative SMoCC languages such as Esterel or Quartz. SBC is often too restrictive as it requires all variables to be initialised by the program. BC can be too permissive because it initialises all variables to a fixed value, by default. Where the initialisation happens through the memory, e.g., when carrying values from one synchronous tick to the next, then IBC is more appropriate. IBC links two levels of execution, the macro-step level and the micro-step level. We prove that the denotational fixed-point analysis for IBC, and hence Berry's causality analysis, is sound with respect to operational micro-level scheduling. The denotational model can thus be viewed as a compositional presentation of a synchronous scheduling strategy that ensures reactiveness and determinacy for imperative concurrent programming.},
  day      = {01},
  db       = {SpringerLink},
  doi      = {10.1007/s00236-015-0238-x},
  url      = {https://doi.org/10.1007/s00236-015-0238-x},
}

@InProceedings{ISI:000392002600037,
  author       = {Saeedloei, Neda},
  title        = {LOGIC PROGRAMMING FOUNDATIONS OF CYBER-PHYSICAL SYSTEMS},
  booktitle    = {TECHNICAL COMMUNICATIONS OF THE 26TH INTERNATIONAL CONFERENCE ON LOGIC PROGRAMMING (ICLP'10)},
  year         = {2010},
  editor       = {Hermenegildo, M and Schaub, T},
  volume       = {7},
  series       = {Leibniz International Proceedings in Informatics},
  pages        = {289-293},
  organization = {Assoc Log Programming, Execut Comm; Log Programming Comm; EPSRC; NSF; Microsoft Res; Assoc Symbol Log; Google; HP; Intel},
  note         = {26th International Conference on Logic Programming (ICLP), Univ Edinburgh, Sch Informat, Edinburgh, SCOTLAND, JUL 16-19, 2010},
  abstract     = {Cyber-physical systems (CPS) are becoming ubiquitous. Almost every
   device today has a controller that reads inputs through sensors, does
   some processing and then performs actions through actuators. These
   controllers are discrete digital systems whose inputs are continuous
   physical quantities and whose outputs control physical (analog) devices.
   Thus, CPS involve both digital and analog data. In addition, CPS are
   assumed to run forever, and many CPS may run concurrently with each
   other. we will develop techniques for faithfully and elegantly modeling
   CPS. Our approach is based on using constraint logic programming over
   reals, co-induction, and coroutining.},
  db           = {WebOfScience},
  doi          = {10.4230/LIPIcs.ICLP.2010.289},
  isbn         = {978-3-939897-17-0},
  issn         = {1868-8969},
  unique-id    = {ISI:000392002600037},
}

@InProceedings{ISI:000278047600001,
  author    = {Ierusalimschy, Roberto},
  title     = {Programming with Multiple Paradigms in Lua},
  booktitle = {FUNCTIONAL AND CONSTRAINT LOGIC PROGRAMMING},
  year      = {2010},
  editor    = {Escobar, S},
  volume    = {5979},
  series    = {Lecture Notes in Computer Science},
  pages     = {1-12},
  note      = {18th International Workshop on Functional and Constraint Logic Programming, Brasilia, BRAZIL, JUN 28, 2009},
  abstract  = {Lua is a scripting language used in many industrial applications, with
   an emphasis on embedded systems and games. Two key points in the design
   of the language that led to its widely adoption are flexibility and
   small size. To achieve these two conflicting goals, the design
   emphasizes the use of few but powerful mechanisms, such as first-class
   functions, associative arrays, coroutines, and reflexive capabilities.
   As a consequence of this design, although Lua is primarily a procedural
   language, it is frequently used in several different programming
   paradigms, such as functional, object-oriented, goal-oriented, and
   concurrent programming, and also for data description.
   In this paper we discuss what mechanisms Lua features to achieve its
   flexibility and how programmers use them for different paradigms.},
  db        = {WebOfScience},
  isbn      = {978-3-642-11998-9},
  issn      = {0302-9743},
  unique-id = {ISI:000278047600001},
}

@Comment{jabref-meta: databaseType:bibtex;}
